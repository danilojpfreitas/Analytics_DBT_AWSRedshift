

============================== 2023-04-27 14:20:22.755312 | 021c42db-53c6-4023-845e-12f7a658ee1f ==============================
[0m14:20:22.755312 [info ] [MainThread]: Running with dbt=1.4.6
[0m14:20:22.756064 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m14:20:22.756178 [debug] [MainThread]: Tracking: tracking
[0m14:20:22.762026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456c8760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456c87c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456bf3a0>]}
[0m14:20:22.855466 [debug] [MainThread]: Executing "git --help"
[0m14:20:22.859670 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:20:22.859976 [debug] [MainThread]: STDERR: "b''"
[0m14:20:22.861211 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m14:20:22.861404 [debug] [MainThread]: Using redshift connection "debug"
[0m14:20:22.861514 [debug] [MainThread]: On debug: select 1 as id
[0m14:20:22.861622 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:20:22.861734 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m14:20:24.756287 [debug] [MainThread]: SQL status: SELECT in 2 seconds
[0m14:20:24.758563 [debug] [MainThread]: On debug: Close
[0m14:20:24.759481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396b280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396b370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396bc70>]}
[0m14:20:24.760241 [debug] [MainThread]: Flushing usage events
[0m14:20:25.578677 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 15:39:15.176339 | 4979f67a-62bf-4e85-9dfb-a1eee0a87608 ==============================
[0m15:39:15.176339 [info ] [MainThread]: Running with dbt=1.4.6
[0m15:39:15.177238 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m15:39:15.177336 [debug] [MainThread]: Tracking: tracking
[0m15:39:15.184923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cfdaac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76cd0>]}
[0m15:39:15.205666 [debug] [MainThread]: Executing "git --help"
[0m15:39:15.208918 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:39:15.209238 [debug] [MainThread]: STDERR: "b''"
[0m15:39:15.209515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cfdaac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cecd280>]}
[0m15:39:15.209799 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 15:54:31.661747 | 51c7cc85-e2c4-41be-a76f-474783680ae0 ==============================
[0m15:54:31.661747 [info ] [MainThread]: Running with dbt=1.4.6
[0m15:54:31.662680 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m15:54:31.662810 [debug] [MainThread]: Tracking: tracking
[0m15:54:31.670387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6bd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6bb50>]}
[0m15:54:31.692679 [debug] [MainThread]: Executing "git --help"
[0m15:54:31.698222 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:54:31.698536 [debug] [MainThread]: STDERR: "b''"
[0m15:54:31.698821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d5007400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f9a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f9a4f0>]}
[0m15:54:31.699089 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:20:17.897885 | d4f5cbc9-e604-41be-97ac-67082a04eb1b ==============================
[0m17:20:17.897885 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:20:17.898650 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:20:17.898780 [debug] [MainThread]: Tracking: tracking
[0m17:20:17.905095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43b50>]}
[0m17:20:17.927073 [debug] [MainThread]: Executing "git --help"
[0m17:20:17.932155 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:20:17.932464 [debug] [MainThread]: STDERR: "b''"
[0m17:20:17.932736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5ee0400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e4deb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e4d1f0>]}
[0m17:20:17.932995 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:23:23.707320 | 1f7e2706-d759-4d1b-a6d6-843e8988a2db ==============================
[0m17:23:23.707320 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:23:23.708041 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:23:23.708138 [debug] [MainThread]: Tracking: tracking
[0m17:23:23.714357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923bb0>]}
[0m17:23:23.717054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fb820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fb4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fbee0>]}
[0m17:23:23.717396 [debug] [MainThread]: Flushing usage events
[0m17:23:24.568963 [error] [MainThread]: Encountered an error:
Runtime Error
  
  dbt encountered an error while trying to read your profiles.yml file.
  
  Runtime Error
    Syntax error near line 2
    ------------------------------
    1  | analytics_dbt:
    2  | 	company-name:
    3  | 	  target: dev
    4  | 	  outputs:
    5  | 	    dev:
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 2, column 1
  


============================== 2023-04-27 17:26:39.941346 | 3804fab7-1f6b-42c7-920e-3d8d99bd4c2b ==============================
[0m17:26:39.941346 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:26:39.942125 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:26:39.942260 [debug] [MainThread]: Tracking: tracking
[0m17:26:39.948626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183ed30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183e730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183e880>]}
[0m17:26:40.042440 [debug] [MainThread]: Executing "git --help"
[0m17:26:40.047104 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:26:40.047482 [debug] [MainThread]: STDERR: "b''"
[0m17:26:40.049090 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:26:40.049374 [debug] [MainThread]: Using redshift connection "debug"
[0m17:26:40.049527 [debug] [MainThread]: On debug: select 1 as id
[0m17:26:40.049724 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:26:40.049877 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:26:50.390719 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:27:00.402903 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:27:00.403386 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:27:00.403826 [debug] [MainThread]: On debug: No close available on handle
[0m17:27:00.404785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf32e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf3d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf38e0>]}
[0m17:27:00.405760 [debug] [MainThread]: Flushing usage events
[0m17:27:01.260457 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:28:37.372815 | 421e8c34-8a73-4881-a311-7f5ff44828a4 ==============================
[0m17:28:37.372815 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:28:37.373548 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:28:37.373651 [debug] [MainThread]: Tracking: tracking
[0m17:28:37.380193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16880>]}
[0m17:28:37.475958 [debug] [MainThread]: Executing "git --help"
[0m17:28:37.480410 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:28:37.480723 [debug] [MainThread]: STDERR: "b''"
[0m17:28:37.481989 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:28:37.482204 [debug] [MainThread]: Using redshift connection "debug"
[0m17:28:37.482340 [debug] [MainThread]: On debug: select 1 as id
[0m17:28:37.482511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:28:37.482647 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:28:47.506205 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:28:57.523279 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:28:57.523765 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:28:57.524247 [debug] [MainThread]: On debug: No close available on handle
[0m17:28:57.524999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fdea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fded00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fde580>]}
[0m17:28:57.525714 [debug] [MainThread]: Flushing usage events
[0m17:28:58.411557 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:30:43.295927 | 32106c69-73b5-4df2-9551-40fe0e01611e ==============================
[0m17:30:43.295927 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:30:43.296662 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:30:43.296755 [debug] [MainThread]: Tracking: tracking
[0m17:30:43.303010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849fb50>]}
[0m17:30:43.396799 [debug] [MainThread]: Executing "git --help"
[0m17:30:43.400948 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:30:43.401266 [debug] [MainThread]: STDERR: "b''"
[0m17:30:43.402595 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:30:43.402848 [debug] [MainThread]: Using redshift connection "debug"
[0m17:30:43.402983 [debug] [MainThread]: On debug: select 1 as id
[0m17:30:43.403105 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:30:43.403237 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:30:53.423575 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:31:03.440926 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:31:03.441468 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:31:03.441989 [debug] [MainThread]: On debug: No close available on handle
[0m17:31:03.442859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676da30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676d8e0>]}
[0m17:31:03.443705 [debug] [MainThread]: Flushing usage events
[0m17:31:04.114914 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:32:29.586977 | d030800b-829a-43fd-b290-6be646cb1b91 ==============================
[0m17:32:29.586977 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:32:29.587701 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:32:29.587793 [debug] [MainThread]: Tracking: tracking
[0m17:32:29.594117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d84460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d7b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d7b8e0>]}
[0m17:32:29.686770 [debug] [MainThread]: Executing "git --help"
[0m17:32:29.690697 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:32:29.691013 [debug] [MainThread]: STDERR: "b''"
[0m17:32:29.692353 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:32:29.692597 [debug] [MainThread]: Using redshift connection "debug"
[0m17:32:29.692726 [debug] [MainThread]: On debug: select 1 as id
[0m17:32:29.692852 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:32:29.692976 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:32:31.510657 [debug] [MainThread]: SQL status: SELECT in 2 seconds
[0m17:32:31.513089 [debug] [MainThread]: On debug: Close
[0m17:32:31.513977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c5e0>]}
[0m17:32:31.514259 [debug] [MainThread]: Flushing usage events
[0m17:32:32.334485 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:33:26.838571 | 6d2ceb85-77f5-4616-8594-fb7d6522eea7 ==============================
[0m17:33:26.838571 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:33:26.839408 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:33:26.839534 [debug] [MainThread]: Tracking: tracking
[0m17:33:26.846388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf19d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf19df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf31040>]}
[0m17:33:26.861569 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:33:26.861911 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:33:26.862092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf93ee0>]}
[0m17:33:27.292064 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m17:33:27.300820 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m17:33:27.352840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c0470d0>]}
[0m17:33:27.357240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8ce58df0>]}
[0m17:33:27.357502 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:33:27.357660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7fdfc9a0>]}
[0m17:33:27.358597 [info ] [MainThread]: 
[0m17:33:27.359581 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:33:27.360424 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:33:27.370954 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:33:27.371287 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:33:27.371422 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:33:27.371557 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:28.959247 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:33:28.962022 [debug] [ThreadPool]: On list_dev: Close
[0m17:33:28.965181 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:33:28.978998 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:33:28.979403 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:33:28.979675 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:33:28.979927 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:30.802252 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:33:30.803135 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:33:30.803723 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:33:31.006859 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:33:31.009759 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:33:31.211278 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:33:31.224088 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:31.224553 [debug] [MainThread]: On master: BEGIN
[0m17:33:31.224863 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:33:31.225142 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:32.952799 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:33:32.953326 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:32.954703 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:33:33.157296 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:33:33.159462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7fd6e880>]}
[0m17:33:33.160114 [debug] [MainThread]: On master: ROLLBACK
[0m17:33:33.363708 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:33.364217 [debug] [MainThread]: On master: BEGIN
[0m17:33:33.702389 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:33:33.703047 [debug] [MainThread]: On master: COMMIT
[0m17:33:33.703530 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:33.703844 [debug] [MainThread]: On master: COMMIT
[0m17:33:33.874560 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:33:33.875248 [debug] [MainThread]: On master: Close
[0m17:33:33.876576 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:33:33.877125 [info ] [MainThread]: 
[0m17:33:33.887493 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.888119 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:33:33.889132 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:33:33.889491 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.892792 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.893354 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:33:33.889693 => 2023-04-27 17:33:33.893269
[0m17:33:33.893574 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.927746 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.928177 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.928320 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:33.928412 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:33:33.928500 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:35.513029 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:33:35.513522 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:35.513888 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:33:36.024366 [debug] [Thread-1  ]: SQL status: SELECT in 1 seconds
[0m17:33:36.034919 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.035224 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:33:36.229049 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:33:36.253425 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.253621 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.253717 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.536451 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:33:36.537273 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.537620 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:36.741234 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:33:36.752007 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.752447 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:33:36.946579 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:33:36.948455 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.948871 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.949165 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:37.150624 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:33:37.151145 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:37.151434 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:37.355399 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:33:37.356817 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:33:33.893671 => 2023-04-27 17:33:37.356711
[0m17:33:37.357187 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:33:37.560403 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:33:37.561972 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7f510520>]}
[0m17:33:37.562819 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.67s]
[0m17:33:37.565265 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:33:37.566807 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.567637 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:33:37.569044 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:33:37.569528 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.574700 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.575363 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:33:37.569769 => 2023-04-27 17:33:37.575256
[0m17:33:37.575775 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.632030 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.632489 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.632636 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:37.632753 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:33:37.632860 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:39.265797 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:33:39.266335 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.266771 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:33:39.408454 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:33:39.414037 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.414436 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:33:39.555672 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:33:39.558918 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:39.559328 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.559662 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:39.719930 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:33:39.720809 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.721180 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:39.915584 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:33:39.921536 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.921965 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:33:40.060778 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:33:40.062541 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:40.062889 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:40.063156 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:40.218416 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:33:40.219085 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:40.219437 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:40.427538 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:33:40.428749 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:33:37.576010 => 2023-04-27 17:33:40.428655
[0m17:33:40.429082 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:33:40.632657 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:33:40.634210 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7c45d820>]}
[0m17:33:40.635064 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.07s]
[0m17:33:40.635751 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:33:40.638451 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:33:40.639011 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:40.639348 [debug] [MainThread]: On master: BEGIN
[0m17:33:40.639645 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:33:40.639942 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:42.475914 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:33:42.476445 [debug] [MainThread]: On master: COMMIT
[0m17:33:42.476769 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:42.477048 [debug] [MainThread]: On master: COMMIT
[0m17:33:42.680528 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:33:42.681073 [debug] [MainThread]: On master: Close
[0m17:33:42.682234 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:33:42.682592 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m17:33:42.682817 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m17:33:42.683136 [info ] [MainThread]: 
[0m17:33:42.683596 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 15.32 seconds (15.32s).
[0m17:33:42.684274 [debug] [MainThread]: Command end result
[0m17:33:42.695490 [info ] [MainThread]: 
[0m17:33:42.696008 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:33:42.696322 [info ] [MainThread]: 
[0m17:33:42.696592 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:33:42.697037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7c455c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c038a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c047190>]}
[0m17:33:42.697439 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:57:37.853061 | c2e3be63-a391-430d-b566-d85f613d9fc3 ==============================
[0m17:57:37.853061 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:57:37.854163 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['views/vw_sales.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:57:37.854437 [debug] [MainThread]: Tracking: tracking
[0m17:57:37.861077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae25160>]}
[0m17:57:37.874595 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:57:37.890853 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m17:57:37.891168 [debug] [MainThread]: Partial parsing: added file: analytics_dbt://models/views/vw_sales.sql
[0m17:57:37.904785 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m17:57:37.919555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad0cc10>]}
[0m17:57:37.924392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad79970>]}
[0m17:57:37.924669 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:57:37.924845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad79bb0>]}
[0m17:57:37.925536 [warn ] [MainThread]: The selection criterion 'views/vw_sales.sql' does not match any nodes
[0m17:57:37.926159 [info ] [MainThread]: 
[0m17:57:37.926433 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m17:57:37.926626 [debug] [MainThread]: Command end result
[0m17:57:37.930943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad70f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad70fa0>]}
[0m17:57:37.931321 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:58:20.358922 | 5a28ecbc-3d07-4248-b10d-a5178776f20d ==============================
[0m17:58:20.358922 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:58:20.359744 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:58:20.359870 [debug] [MainThread]: Tracking: tracking
[0m17:58:20.366786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a066f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a0872e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a087190>]}
[0m17:58:20.381670 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:58:20.397704 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:58:20.397930 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:58:20.402782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0679f77b20>]}
[0m17:58:20.408175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c5b0>]}
[0m17:58:20.408500 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:58:20.408687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c6d0>]}
[0m17:58:20.409756 [info ] [MainThread]: 
[0m17:58:20.410797 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:58:20.411573 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:58:20.420174 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:58:20.420380 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:58:20.420541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:20.420683 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:22.381089 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:58:22.383815 [debug] [ThreadPool]: On list_dev: Close
[0m17:58:22.387225 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:58:22.401406 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:58:22.401759 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:58:22.402028 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:58:22.402263 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:24.007412 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:58:24.007998 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:58:24.008394 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:58:24.224081 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:58:24.226938 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:58:24.428927 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:58:24.441639 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:24.442077 [debug] [MainThread]: On master: BEGIN
[0m17:58:24.442406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:58:24.442677 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:26.067202 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:58:26.067780 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.068135 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:58:26.272739 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:58:26.275343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0679f77e20>]}
[0m17:58:26.275985 [debug] [MainThread]: On master: ROLLBACK
[0m17:58:26.476900 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.477610 [debug] [MainThread]: On master: BEGIN
[0m17:58:26.887187 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:58:26.888104 [debug] [MainThread]: On master: COMMIT
[0m17:58:26.888697 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.889096 [debug] [MainThread]: On master: COMMIT
[0m17:58:27.091297 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:58:27.091892 [debug] [MainThread]: On master: Close
[0m17:58:27.093103 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:58:27.093578 [info ] [MainThread]: 
[0m17:58:27.099465 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.099773 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:58:27.100273 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:58:27.100465 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.103310 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.104085 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:58:27.100554 => 2023-04-27 17:58:27.103969
[0m17:58:27.104450 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.139142 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.139744 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.139968 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:27.140072 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:58:27.140165 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:28.934545 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:58:28.935026 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:28.935308 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:58:29.241784 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m17:58:29.254616 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.254965 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:58:29.446604 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:29.451928 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.452237 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:58:29.651610 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:29.680539 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:29.680726 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.680815 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:29.857157 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:58:29.858039 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.858452 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:30.061894 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:58:30.073255 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.073676 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:58:30.227975 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:58:30.229642 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:30.230019 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.230286 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:30.470535 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:58:30.471120 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.471449 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:30.678454 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:58:30.679916 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:58:27.104604 => 2023-04-27 17:58:30.679804
[0m17:58:30.680312 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:58:30.883181 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:58:30.884902 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06796f9820>]}
[0m17:58:30.885940 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.78s]
[0m17:58:30.889089 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:58:30.891002 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.891801 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:58:30.893129 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:58:30.893585 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.898745 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.899447 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:58:30.893827 => 2023-04-27 17:58:30.899328
[0m17:58:30.899817 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.916798 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.917173 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.917313 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:30.917412 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:58:30.917507 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:32.723987 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:58:32.724534 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:32.724848 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:58:32.928028 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:58:32.933532 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:32.933920 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:58:33.133289 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:33.135312 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.135558 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.135752 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.337777 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:58:33.338902 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.339462 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:33.542641 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:58:33.547044 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.547431 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:58:33.747550 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:58:33.749156 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.749492 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.749729 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.956068 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:58:33.956774 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.957214 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:34.156775 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:58:34.158087 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:58:30.899980 => 2023-04-27 17:58:34.157981
[0m17:58:34.158476 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:58:34.361621 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:58:34.363216 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06796f9670>]}
[0m17:58:34.364022 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.47s]
[0m17:58:34.364633 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:58:34.367313 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:58:34.367941 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:34.368345 [debug] [MainThread]: On master: BEGIN
[0m17:58:34.368707 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:58:34.369071 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:36.205151 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:58:36.205774 [debug] [MainThread]: On master: COMMIT
[0m17:58:36.206173 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:36.206550 [debug] [MainThread]: On master: COMMIT
[0m17:58:36.410523 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:58:36.411184 [debug] [MainThread]: On master: Close
[0m17:58:36.412430 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:36.412844 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m17:58:36.413236 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m17:58:36.413743 [info ] [MainThread]: 
[0m17:58:36.414407 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.00 seconds (16.00s).
[0m17:58:36.415463 [debug] [MainThread]: Command end result
[0m17:58:36.427697 [info ] [MainThread]: 
[0m17:58:36.428141 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:58:36.428440 [info ] [MainThread]: 
[0m17:58:36.428788 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:58:36.429271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a0e7b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06797396a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c460>]}
[0m17:58:36.429722 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:59:45.433573 | 3689fd6f-e47b-46d9-8e41-8d8765e929c9 ==============================
[0m17:59:45.433573 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:59:45.434362 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:59:45.434475 [debug] [MainThread]: Tracking: tracking
[0m17:59:45.441144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531a7d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531a7dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531bf070>]}
[0m17:59:45.453847 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:59:45.469352 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:59:45.469569 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:59:45.473614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f530b0a00>]}
[0m17:59:45.478787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f53191490>]}
[0m17:59:45.479113 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:59:45.479276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531915b0>]}
[0m17:59:45.480217 [info ] [MainThread]: 
[0m17:59:45.481195 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:59:45.482008 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:59:45.490506 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:59:45.490705 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:59:45.490830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:45.490941 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:47.373882 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:59:47.376936 [debug] [ThreadPool]: On list_dev: Close
[0m17:59:47.379045 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:59:47.386742 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:59:47.386884 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:59:47.386983 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:59:47.387144 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:49.217377 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:59:49.217909 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:59:49.218287 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:59:49.421504 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:59:49.424406 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:59:49.626512 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:59:49.639354 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:49.639826 [debug] [MainThread]: On master: BEGIN
[0m17:59:49.640153 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:59:49.640447 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:51.469772 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:59:51.470352 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:51.470822 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:59:51.674538 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:59:51.678669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5310fdf0>]}
[0m17:59:51.679338 [debug] [MainThread]: On master: ROLLBACK
[0m17:59:51.879407 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:51.879960 [debug] [MainThread]: On master: BEGIN
[0m17:59:52.288881 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:59:52.289412 [debug] [MainThread]: On master: COMMIT
[0m17:59:52.289739 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:52.290021 [debug] [MainThread]: On master: COMMIT
[0m17:59:52.493835 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:59:52.494462 [debug] [MainThread]: On master: Close
[0m17:59:52.495742 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:59:52.496273 [info ] [MainThread]: 
[0m17:59:52.503603 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.504479 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:59:52.505065 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:59:52.505221 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.507240 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.507662 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:59:52.505303 => 2023-04-27 17:59:52.507581
[0m17:59:52.507860 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.540260 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.540622 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.540766 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:52.540881 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:59:52.540986 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:54.336758 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:59:54.337258 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.337576 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:59:54.548703 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m17:59:54.562525 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.562963 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:59:54.746959 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:54.753059 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.753526 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:59:54.951522 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:54.969152 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:54.969318 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.969427 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.258581 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:59:55.259468 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.259852 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:55.463543 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:59:55.470539 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.470669 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:59:55.668435 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:59:55.670520 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.670992 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.671389 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.874117 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:59:55.874739 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.875113 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:56.077454 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:59:56.079112 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:59:52.507955 => 2023-04-27 17:59:56.078988
[0m17:59:56.079579 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:59:56.283543 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:59:56.285250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f52832700>]}
[0m17:59:56.286143 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.78s]
[0m17:59:56.288188 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:59:56.288848 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.289064 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:59:56.289470 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:59:56.289617 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.292688 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.293631 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:59:56.289696 => 2023-04-27 17:59:56.293424
[0m17:59:56.294164 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.310260 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.310662 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.310817 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:56.310987 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:59:56.311112 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:58.125537 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:59:58.126070 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.126497 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:59:58.330428 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:59:58.335774 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.335882 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:59:58.535527 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:58.539006 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:58.539385 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.539678 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:58.740646 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:59:58.741500 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.741848 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:58.945430 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:59:58.949906 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.950325 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:59:59.102693 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:59:59.104661 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:59.105064 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:59.105375 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:59.457232 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:59:59.457804 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:59.458135 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:59.661885 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:59:59.663356 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:59:56.294392 => 2023-04-27 17:59:59.663246
[0m17:59:59.663733 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:59:59.866416 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:59:59.867942 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f52887250>]}
[0m17:59:59.868856 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.58s]
[0m17:59:59.869657 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:59:59.873018 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:59:59.873568 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:59.873929 [debug] [MainThread]: On master: BEGIN
[0m17:59:59.874276 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:59:59.874665 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:00:01.813179 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:00:01.813750 [debug] [MainThread]: On master: COMMIT
[0m18:00:01.814162 [debug] [MainThread]: Using redshift connection "master"
[0m18:00:01.814532 [debug] [MainThread]: On master: COMMIT
[0m18:00:01.955250 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:00:01.955781 [debug] [MainThread]: On master: Close
[0m18:00:01.956964 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:00:01.957302 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:00:01.957571 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:00:01.957902 [info ] [MainThread]: 
[0m18:00:01.958327 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.48 seconds (16.48s).
[0m18:00:01.959079 [debug] [MainThread]: Command end result
[0m18:00:01.975388 [info ] [MainThread]: 
[0m18:00:01.975892 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:00:01.976213 [info ] [MainThread]: 
[0m18:00:01.976500 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:00:01.976901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5288e100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5285b700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531bf910>]}
[0m18:00:01.977163 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:02:58.049672 | e3e2cf48-ba4e-49d2-9976-c7d95369db1e ==============================
[0m18:02:58.049672 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:02:58.050502 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:02:58.050640 [debug] [MainThread]: Tracking: tracking
[0m18:02:58.057064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317cfcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c2b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c2b190>]}
[0m18:02:58.069398 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:02:58.084667 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:02:58.084846 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:02:58.089036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317b1bb20>]}
[0m18:02:58.095148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc5b0>]}
[0m18:02:58.095486 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:02:58.095671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc6d0>]}
[0m18:02:58.096604 [info ] [MainThread]: 
[0m18:02:58.097576 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:02:58.098356 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:02:58.106892 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:02:58.107070 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:02:58.107180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:02:58.107293 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:02:59.989478 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:02:59.992228 [debug] [ThreadPool]: On list_dev: Close
[0m18:02:59.993675 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:03:00.001076 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:03:00.001228 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:03:00.001328 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:03:00.001423 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:01.832933 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:03:01.833517 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:03:01.833896 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:03:02.037486 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:03:02.040413 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:03:02.242703 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:03:02.255858 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:02.256305 [debug] [MainThread]: On master: BEGIN
[0m18:03:02.256652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:02.256971 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:03.928801 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:03:03.929448 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:03.929874 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:03:04.188540 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:03:04.191522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c8d970>]}
[0m18:03:04.192216 [debug] [MainThread]: On master: ROLLBACK
[0m18:03:04.376104 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:04.376700 [debug] [MainThread]: On master: BEGIN
[0m18:03:04.749001 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:03:04.749693 [debug] [MainThread]: On master: COMMIT
[0m18:03:04.750177 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:04.750593 [debug] [MainThread]: On master: COMMIT
[0m18:03:04.905854 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:03:04.906495 [debug] [MainThread]: On master: Close
[0m18:03:04.908008 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:03:04.908525 [info ] [MainThread]: 
[0m18:03:04.915636 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.916406 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:03:04.917558 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:03:04.918000 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.923705 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.924563 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:03:04.918257 => 2023-04-27 18:03:04.924391
[0m18:03:04.925023 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.962910 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.963370 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.963575 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:04.963678 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:03:04.963768 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:06.748961 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:03:06.749516 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:06.749855 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:03:07.055343 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:03:07.063080 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.063219 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:03:07.260151 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:07.266266 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.266701 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:03:07.465602 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:07.496323 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:07.496486 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.496570 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:07.772376 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:03:07.773263 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.773628 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:07.977880 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:03:07.984917 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.985039 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:03:08.182288 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:03:08.184139 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:08.184511 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:08.184791 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:08.488875 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:03:08.489411 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:08.489749 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:08.693824 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:03:08.695404 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:03:04.925256 => 2023-04-27 18:03:08.695280
[0m18:03:08.695791 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:03:08.898908 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:03:08.900578 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f831729c820>]}
[0m18:03:08.901434 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.98s]
[0m18:03:08.904186 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:03:08.904989 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.905265 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:03:08.905705 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:03:08.905852 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.911094 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.911966 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:03:08.905928 => 2023-04-27 18:03:08.911831
[0m18:03:08.912379 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.928306 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.928665 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.928820 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:08.928918 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:03:08.929009 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:10.742600 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m18:03:10.743125 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:10.743487 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:03:11.048760 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:03:11.054021 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.054143 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:03:11.253890 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:11.257400 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.257776 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.258076 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.458184 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m18:03:11.459004 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.459315 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:11.663352 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m18:03:11.667206 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.667312 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:03:11.868063 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m18:03:11.869988 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.870386 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.870696 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:12.072643 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m18:03:12.073154 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:12.073489 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:12.277395 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m18:03:12.278823 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:03:08.912633 => 2023-04-27 18:03:12.278715
[0m18:03:12.279222 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:03:12.482912 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:03:12.484599 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c8d9a0>]}
[0m18:03:12.485467 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.58s]
[0m18:03:12.486173 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:03:12.488998 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:03:12.489566 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:12.489983 [debug] [MainThread]: On master: BEGIN
[0m18:03:12.490402 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:03:12.490819 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:14.220648 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:03:14.221271 [debug] [MainThread]: On master: COMMIT
[0m18:03:14.221689 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:14.222064 [debug] [MainThread]: On master: COMMIT
[0m18:03:14.370989 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:03:14.371588 [debug] [MainThread]: On master: Close
[0m18:03:14.372760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:03:14.373088 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:03:14.373355 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:03:14.373720 [info ] [MainThread]: 
[0m18:03:14.374140 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.28 seconds (16.28s).
[0m18:03:14.374969 [debug] [MainThread]: Command end result
[0m18:03:14.383334 [info ] [MainThread]: 
[0m18:03:14.383780 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:03:14.384025 [info ] [MainThread]: 
[0m18:03:14.384228 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:03:14.384552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83172cc6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83172cc670>]}
[0m18:03:14.384791 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:06:53.584481 | 36aec465-99df-41c8-b1ef-6dd35efad6a4 ==============================
[0m18:06:53.584481 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:06:53.585275 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:06:53.585390 [debug] [MainThread]: Tracking: tracking
[0m18:06:53.591896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777bd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876775e1f0>]}
[0m18:06:53.604572 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:06:53.610744 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m18:06:53.611042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777d700>]}
[0m18:06:54.011258 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m18:06:54.019632 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m18:06:54.021790 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m18:06:54.068152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87677359a0>]}
[0m18:06:54.072097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777d430>]}
[0m18:06:54.072326 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:06:54.072489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87666741c0>]}
[0m18:06:54.073412 [info ] [MainThread]: 
[0m18:06:54.074399 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:06:54.075290 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:06:54.084153 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:06:54.084374 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:06:54.084495 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:06:54.084605 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:55.763542 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:06:55.766365 [debug] [ThreadPool]: On list_dev: Close
[0m18:06:55.767640 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:06:55.774403 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:06:55.774567 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:06:55.774708 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:06:55.774826 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:57.661801 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:06:57.662377 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:06:57.662734 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:06:57.867424 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:06:57.870443 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:06:58.071481 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:06:58.084287 [debug] [MainThread]: Using redshift connection "master"
[0m18:06:58.084836 [debug] [MainThread]: On master: BEGIN
[0m18:06:58.085206 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:06:58.085544 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:59.914820 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:06:59.915415 [debug] [MainThread]: Using redshift connection "master"
[0m18:06:59.915796 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:07:00.119533 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:07:00.122180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8767735ee0>]}
[0m18:07:00.122839 [debug] [MainThread]: On master: ROLLBACK
[0m18:07:00.267957 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:00.268577 [debug] [MainThread]: On master: BEGIN
[0m18:07:00.631350 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:07:00.631924 [debug] [MainThread]: On master: COMMIT
[0m18:07:00.632291 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:00.632628 [debug] [MainThread]: On master: COMMIT
[0m18:07:00.837501 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:07:00.838090 [debug] [MainThread]: On master: Close
[0m18:07:00.839401 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:07:00.839907 [info ] [MainThread]: 
[0m18:07:00.847790 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.849297 [debug] [Thread-2  ]: Began running node model.analytics_dbt.vw_sales
[0m18:07:00.848596 [info ] [Thread-1  ]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:07:00.850367 [info ] [Thread-2  ]: 2 of 3 START sql view model public.vw_sales .................................... [RUN]
[0m18:07:00.851995 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:07:00.854829 [debug] [Thread-2  ]: Acquiring new redshift connection 'model.analytics_dbt.vw_sales'
[0m18:07:00.855514 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.856027 [debug] [Thread-2  ]: Began compiling node model.analytics_dbt.vw_sales
[0m18:07:00.898469 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.899572 [debug] [Thread-2  ]: Writing injected SQL for node "model.analytics_dbt.vw_sales"
[0m18:07:00.900072 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (compile): 2023-04-27 18:07:00.898705 => 2023-04-27 18:07:00.900018
[0m18:07:00.900239 [debug] [Thread-2  ]: Began executing node model.analytics_dbt.vw_sales
[0m18:07:00.905586 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:07:00.856446 => 2023-04-27 18:07:00.905514
[0m18:07:00.910925 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.935297 [debug] [Thread-2  ]: Writing runtime sql for node "model.analytics_dbt.vw_sales"
[0m18:07:00.943749 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.944064 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.944195 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:00.944314 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:07:00.944445 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:00.944773 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:00.944908 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:00.944999 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:07:00.945091 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:02.781671 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:07:02.782263 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m18:07:02.782830 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:02.783338 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:02.783922 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:07:02.784480 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */


  create view "dev"."public"."vw_sales__dbt_tmp" as (
    with source_sales as (
    select *
    from sales
),

renamed as (
    select 
        SALESID AS ID_VENDA,
        SELLERID AS ID_LISTA,
        BUYERID AS ID_COMPRADOR,
        EVENTID AS ID_EVENTO,
        DATEID AS ID_DATE,
        QTYSOLD AS QUANTIDADE_VENDIDA,
        PRICEPAID AS VALOR_PAGO,
        COMMISSION AS COMISSÃO,
        SALETIME AS DATA_VENDA
    from source_sales
)

select * from renamed
  ) ;

[0m18:07:02.987621 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:07:02.993418 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:07:03.001270 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.001416 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales__dbt_tmp" rename to "vw_sales"
[0m18:07:03.002928 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.003546 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:07:03.191369 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.197869 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.213783 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.219292 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:07:03.226371 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.226508 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.226598 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.384193 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.401058 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:03.401382 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.401619 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:03.403013 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:07:03.403416 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.403602 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:03.601048 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:07:03.602008 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:07:03.608739 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.608859 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
drop view if exists "dev"."public"."vw_sales__dbt_backup" cascade
[0m18:07:03.805843 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0 seconds
[0m18:07:03.807706 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.808093 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.808378 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:04.012332 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:07:04.012862 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:04.013201 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:04.216591 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:07:04.218047 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (execute): 2023-04-27 18:07:00.900314 => 2023-04-27 18:07:04.217936
[0m18:07:04.218471 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: ROLLBACK
[0m18:07:04.218962 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.219401 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:04.393073 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: Close
[0m18:07:04.393765 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:07:04.395323 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765dab190>]}
[0m18:07:04.400007 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.400553 [info ] [Thread-2  ]: 2 of 3 OK created sql view model public.vw_sales ............................... [[32mCREATE VIEW[0m in 3.54s]
[0m18:07:04.400796 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:07:04.401634 [debug] [Thread-2  ]: Finished running node model.analytics_dbt.vw_sales
[0m18:07:04.625133 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:07:04.627006 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:04.627380 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.627667 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:04.786624 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:07:04.787219 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.787557 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:05.034841 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:07:05.036348 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:07:00.916234 => 2023-04-27 18:07:05.036207
[0m18:07:05.036775 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:07:05.175997 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:07:05.177603 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8766649e50>]}
[0m18:07:05.178483 [info ] [Thread-1  ]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 4.33s]
[0m18:07:05.179206 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:07:05.180769 [debug] [Thread-4  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.181460 [info ] [Thread-4  ]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:07:05.182815 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:07:05.183279 [debug] [Thread-4  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.186899 [debug] [Thread-4  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.187243 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:07:05.183519 => 2023-04-27 18:07:05.187185
[0m18:07:05.187451 [debug] [Thread-4  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.190574 [debug] [Thread-4  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.190984 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.191122 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:05.191214 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:07:05.191307 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:06.980984 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m18:07:06.981535 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:06.981905 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:07:07.185098 [debug] [Thread-4  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:07:07.190527 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.190652 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:07:07.389945 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:07.393358 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:07.393727 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.394031 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:07.594931 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:07:07.595767 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.596111 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:07.799822 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:07:07.804759 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.804954 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:07:08.004746 [debug] [Thread-4  ]: SQL status: DROP VIEW in 0 seconds
[0m18:07:08.006654 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:08.007061 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:08.007399 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:08.209214 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:07:08.209765 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:08.210095 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:08.414163 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:07:08.415816 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:07:05.187552 => 2023-04-27 18:07:08.415695
[0m18:07:08.416906 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:07:08.721353 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:07:08.722909 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765d5bf40>]}
[0m18:07:08.723702 [info ] [Thread-4  ]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.54s]
[0m18:07:08.724311 [debug] [Thread-4  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:07:08.725976 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:07:08.726170 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:08.726278 [debug] [MainThread]: On master: BEGIN
[0m18:07:08.726390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:07:08.726492 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:10.564856 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:07:10.565422 [debug] [MainThread]: On master: COMMIT
[0m18:07:10.565803 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:10.566160 [debug] [MainThread]: On master: COMMIT
[0m18:07:10.769594 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:07:10.770214 [debug] [MainThread]: On master: Close
[0m18:07:10.771507 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:07:10.771849 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:07:10.772101 [debug] [MainThread]: Connection 'model.analytics_dbt.vw_sales' was properly closed.
[0m18:07:10.772348 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:07:10.772739 [info ] [MainThread]: 
[0m18:07:10.773168 [info ] [MainThread]: Finished running 2 view models, 1 table model in 0 hours 0 minutes and 16.70 seconds (16.70s).
[0m18:07:10.774025 [debug] [MainThread]: Command end result
[0m18:07:10.788104 [info ] [MainThread]: 
[0m18:07:10.788555 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:07:10.788839 [info ] [MainThread]: 
[0m18:07:10.789148 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:07:10.789657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765dab190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8764522100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8764522bb0>]}
[0m18:07:10.790109 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:18:47.764862 | f3b2e508-3306-46c2-a902-558e02dee631 ==============================
[0m18:18:47.764862 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:18:47.765712 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['/models/views/vw_sales.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:18:47.765830 [debug] [MainThread]: Tracking: tracking
[0m18:18:47.772450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8f70>]}
[0m18:18:47.786143 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:18:47.803031 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:18:47.803429 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://models/views/vw_sales.sql
[0m18:18:47.817602 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m18:18:47.833469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b523feee0>]}
[0m18:18:47.837990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459d30>]}
[0m18:18:47.838267 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:18:47.838454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52444250>]}
[0m18:18:47.838878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524598e0>]}
[0m18:18:47.839080 [debug] [MainThread]: Flushing usage events
[0m18:18:48.736698 [error] [MainThread]: Encountered an error:
Non-relative patterns are unsupported
[0m18:18:48.740971 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 136, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 206, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 253, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 169, in _runtime_initialize
    self.job_queue = self.get_graph_queue()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 162, in get_graph_queue
    return selector.get_graph_queue(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 295, in get_graph_queue
    selected_nodes = self.get_selected(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 286, in get_selected
    selected_nodes, indirect_only = self.select_nodes(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 153, in select_nodes
    direct_nodes, indirect_nodes = self.select_nodes_recursively(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 123, in select_nodes_recursively
    direct_nodes, indirect_nodes = self.get_nodes_from_criteria(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 80, in get_nodes_from_criteria
    collected = self.select_included(nodes, spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 66, in select_included
    return set(method.search(included_nodes, spec.value))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in search
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in <genexpr>
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/lib/python3.8/pathlib.py", line 1138, in glob
    raise NotImplementedError("Non-relative patterns are unsupported")
NotImplementedError: Non-relative patterns are unsupported



============================== 2023-04-27 18:19:36.195245 | 04b26429-e16b-4cf3-9815-bb1a9098ad2a ==============================
[0m18:19:36.195245 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:19:36.196075 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:19:36.196228 [debug] [MainThread]: Tracking: tracking
[0m18:19:36.202818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424562af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424570ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424572100>]}
[0m18:19:36.215971 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:19:36.232202 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:19:36.232523 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:19:36.238007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424465b80>]}
[0m18:19:36.242606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d6a0>]}
[0m18:19:36.242902 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:19:36.243102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d790>]}
[0m18:19:36.244095 [info ] [MainThread]: 
[0m18:19:36.245094 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:19:36.245957 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:19:36.256284 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:19:36.256516 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:19:36.256661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:19:36.256787 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:38.193941 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:19:38.196744 [debug] [ThreadPool]: On list_dev: Close
[0m18:19:38.200045 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:19:38.214722 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:19:38.215182 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:19:38.215529 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:19:38.215805 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:40.036760 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:19:40.037342 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:19:40.039375 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:19:40.241712 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:19:40.244518 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:19:40.446451 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:19:40.458605 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:40.458965 [debug] [MainThread]: On master: BEGIN
[0m18:19:40.459384 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:19:40.459700 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:42.187316 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:19:42.187829 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:42.188177 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:19:42.392343 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:19:42.395342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d3a0>]}
[0m18:19:42.396200 [debug] [MainThread]: On master: ROLLBACK
[0m18:19:42.596989 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:42.597618 [debug] [MainThread]: On master: BEGIN
[0m18:19:43.006619 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:19:43.007167 [debug] [MainThread]: On master: COMMIT
[0m18:19:43.007530 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:43.007838 [debug] [MainThread]: On master: COMMIT
[0m18:19:43.212090 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:19:43.212641 [debug] [MainThread]: On master: Close
[0m18:19:43.213828 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:19:43.214384 [info ] [MainThread]: 
[0m18:19:43.221653 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.222457 [info ] [Thread-1  ]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:19:43.223372 [debug] [Thread-2  ]: Began running node model.analytics_dbt.vw_sales
[0m18:19:43.224751 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:19:43.225473 [info ] [Thread-2  ]: 2 of 3 START sql view model public.vw_sales .................................... [RUN]
[0m18:19:43.225858 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.226500 [debug] [Thread-2  ]: Acquiring new redshift connection 'model.analytics_dbt.vw_sales'
[0m18:19:43.228801 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.229209 [debug] [Thread-2  ]: Began compiling node model.analytics_dbt.vw_sales
[0m18:19:43.231577 [debug] [Thread-2  ]: Writing injected SQL for node "model.analytics_dbt.vw_sales"
[0m18:19:43.232137 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:19:43.226725 => 2023-04-27 18:19:43.232020
[0m18:19:43.232467 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.232615 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (compile): 2023-04-27 18:19:43.229536 => 2023-04-27 18:19:43.232564
[0m18:19:43.242998 [debug] [Thread-2  ]: Began executing node model.analytics_dbt.vw_sales
[0m18:19:43.303419 [debug] [Thread-2  ]: Writing runtime sql for node "model.analytics_dbt.vw_sales"
[0m18:19:43.304756 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.305194 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.305346 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:43.305472 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:43.305589 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:43.305697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:19:43.305800 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:19:43.305903 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:43.306000 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:45.054527 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m18:19:45.055009 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.055297 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */


  create view "dev"."public"."vw_sales__dbt_tmp" as (
    with source_sales as (
    select *
    from sales
),

renamed as (
    select 
        SALESID AS ID_VENDA,
        SELLERID AS ID_LISTA,
        BUYERID AS ID_COMPRADOR,
        EVENTID AS ID_EVENTO,
        DATEID AS ID_DATE,
        QTYSOLD AS QUANTIDADE_VENDIDA,
        PRICEPAID AS VALOR_PAGO,
        COMMISSION AS COMISSÃO,
        TO_CHAR(SALETIME, 'dd/mm/yyyy HH24:MI:SS') AS DATA_HORA_VENDA,
        TO_CHAR(SALETIME, 'HH24:MI:SS') AS HORA_VENDA,
        cast(SALETIME as date) AS DATA_VENDA
    from source_sales
)

select * from renamed
  ) ;

[0m18:19:45.055699 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:19:45.056074 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.056351 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:19:45.259428 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:19:45.270273 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:19:45.278936 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.279396 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales" rename to "vw_sales__dbt_backup"
[0m18:19:45.284046 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.284521 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:19:45.463940 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.464526 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.470740 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.476143 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.476626 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales__dbt_tmp" rename to "vw_sales"
[0m18:19:45.477048 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:19:45.668909 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.669442 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.724986 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:45.725219 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.725344 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:45.726724 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:45.726903 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.727032 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:45.976296 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:19:45.976780 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:19:45.977629 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.978495 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:46.180826 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:19:46.192550 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.192993 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
drop view if exists "dev"."public"."vw_sales__dbt_backup" cascade
[0m18:19:46.385539 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0 seconds
[0m18:19:46.387273 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:46.387674 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.387940 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:46.551632 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:19:46.552134 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.552418 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:46.795370 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:19:46.797260 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (execute): 2023-04-27 18:19:43.248976 => 2023-04-27 18:19:46.797139
[0m18:19:46.797659 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: ROLLBACK
[0m18:19:46.798069 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:46.798840 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:47.000713 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: Close
[0m18:19:47.001283 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:19:47.005890 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.006457 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:19:47.007659 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2423be6d60>]}
[0m18:19:47.008471 [info ] [Thread-2  ]: 2 of 3 OK created sql view model public.vw_sales ............................... [[32mCREATE VIEW[0m in 3.78s]
[0m18:19:47.010992 [debug] [Thread-2  ]: Finished running node model.analytics_dbt.vw_sales
[0m18:19:47.164352 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:19:47.166485 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:47.166888 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.167164 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:47.409446 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:19:47.409918 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.410180 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:47.614244 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:19:47.615682 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:19:43.232723 => 2023-04-27 18:19:47.615571
[0m18:19:47.616114 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:19:47.819144 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:19:47.820691 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2420bafe80>]}
[0m18:19:47.821475 [info ] [Thread-1  ]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 4.60s]
[0m18:19:47.822072 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:19:47.823609 [debug] [Thread-4  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.824275 [info ] [Thread-4  ]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:19:47.825572 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:19:47.826000 [debug] [Thread-4  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.831844 [debug] [Thread-4  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.832783 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:19:47.826220 => 2023-04-27 18:19:47.832634
[0m18:19:47.833411 [debug] [Thread-4  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.841025 [debug] [Thread-4  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.841476 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.841663 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:47.841812 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:19:47.841945 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:49.662314 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m18:19:49.662791 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:49.663083 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:19:49.867088 [debug] [Thread-4  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:19:49.875246 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:49.875567 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:19:50.072710 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:50.076100 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.076499 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.076785 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.276922 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:19:50.277716 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.278046 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:50.481502 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:19:50.486039 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.486472 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:19:50.686570 [debug] [Thread-4  ]: SQL status: DROP VIEW in 0 seconds
[0m18:19:50.688347 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.688687 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.688944 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.891213 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:19:50.891713 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.891992 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:51.068460 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:19:51.069804 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:19:47.833814 => 2023-04-27 18:19:51.069703
[0m18:19:51.070173 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:19:51.301028 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:19:51.302602 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2423be6df0>]}
[0m18:19:51.303397 [info ] [Thread-4  ]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.48s]
[0m18:19:51.304061 [debug] [Thread-4  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:19:51.306653 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:19:51.307154 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:51.307504 [debug] [MainThread]: On master: BEGIN
[0m18:19:51.307792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:19:51.308076 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:52.985779 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:19:52.986266 [debug] [MainThread]: On master: COMMIT
[0m18:19:52.986649 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:52.986933 [debug] [MainThread]: On master: COMMIT
[0m18:19:53.246835 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:19:53.247506 [debug] [MainThread]: On master: Close
[0m18:19:53.248924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:19:53.249270 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:19:53.249519 [debug] [MainThread]: Connection 'model.analytics_dbt.vw_sales' was properly closed.
[0m18:19:53.249737 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:19:53.250114 [info ] [MainThread]: 
[0m18:19:53.250619 [info ] [MainThread]: Finished running 2 view models, 1 table model in 0 hours 0 minutes and 17.01 seconds (17.01s).
[0m18:19:53.251579 [debug] [MainThread]: Command end result
[0m18:19:53.259977 [info ] [MainThread]: 
[0m18:19:53.260376 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:19:53.260577 [info ] [MainThread]: 
[0m18:19:53.260745 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:19:53.261063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424473910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424562af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2420ad6400>]}
[0m18:19:53.261390 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 21:14:14.643942 | b18360f1-278b-4884-9af0-17b2e8e00145 ==============================
[0m21:14:14.643942 [info ] [MainThread]: Running with dbt=1.4.6
[0m21:14:14.644770 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:14:14.644889 [debug] [MainThread]: Tracking: tracking
[0m21:14:14.651705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366798c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366798f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366798f40>]}
[0m21:14:14.665896 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m21:14:14.672477 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:14:14.672751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366821b50>]}
[0m21:14:15.101666 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m21:14:15.110734 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m21:14:15.113156 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m21:14:15.115417 [debug] [MainThread]: 1699: static parser successfully parsed tables/tb_10_compradores.sql
[0m21:14:15.165140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13655e19a0>]}
[0m21:14:15.169492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366798e20>]}
[0m21:14:15.169781 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m21:14:15.169974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1365610d30>]}
[0m21:14:15.171114 [info ] [MainThread]: 
[0m21:14:15.172175 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:14:15.173128 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:14:15.182511 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:14:15.182765 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m21:14:15.182920 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:15.183068 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:16.985887 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m21:14:16.989020 [debug] [ThreadPool]: On list_dev: Close
[0m21:14:16.992453 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m21:14:17.006696 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m21:14:17.007044 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m21:14:17.007285 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:17.007499 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:18.644223 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m21:14:18.644694 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m21:14:18.645038 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m21:14:18.810840 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m21:14:18.813811 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m21:14:18.964120 [debug] [ThreadPool]: On list_dev_public: Close
[0m21:14:18.977190 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:18.977694 [debug] [MainThread]: On master: BEGIN
[0m21:14:18.978056 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:14:18.978417 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:20.672141 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m21:14:20.672653 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:20.672973 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:14:20.877144 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m21:14:20.879990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13655e1ca0>]}
[0m21:14:20.880772 [debug] [MainThread]: On master: ROLLBACK
[0m21:14:21.082424 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:21.082920 [debug] [MainThread]: On master: BEGIN
[0m21:14:21.491544 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m21:14:21.492063 [debug] [MainThread]: On master: COMMIT
[0m21:14:21.492370 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:21.492643 [debug] [MainThread]: On master: COMMIT
[0m21:14:21.695886 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m21:14:21.696140 [debug] [MainThread]: On master: Close
[0m21:14:21.696731 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:14:21.697038 [info ] [MainThread]: 
[0m21:14:21.700470 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m21:14:21.700712 [debug] [Thread-2  ]: Began running node model.analytics_dbt.vw_sales
[0m21:14:21.700956 [info ] [Thread-1  ]: 1 of 4 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m21:14:21.701252 [info ] [Thread-2  ]: 2 of 4 START sql view model public.vw_sales .................................... [RUN]
[0m21:14:21.738397 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m21:14:21.738939 [debug] [Thread-2  ]: Acquiring new redshift connection 'model.analytics_dbt.vw_sales'
[0m21:14:21.739227 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m21:14:21.739389 [debug] [Thread-2  ]: Began compiling node model.analytics_dbt.vw_sales
[0m21:14:21.741308 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m21:14:21.742432 [debug] [Thread-2  ]: Writing injected SQL for node "model.analytics_dbt.vw_sales"
[0m21:14:21.742798 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (compile): 2023-04-27 21:14:21.741476 => 2023-04-27 21:14:21.742745
[0m21:14:21.742924 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 21:14:21.739508 => 2023-04-27 21:14:21.742877
[0m21:14:21.743086 [debug] [Thread-2  ]: Began executing node model.analytics_dbt.vw_sales
[0m21:14:21.743228 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m21:14:21.792349 [debug] [Thread-2  ]: Writing runtime sql for node "model.analytics_dbt.vw_sales"
[0m21:14:21.800727 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m21:14:21.801121 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:21.801330 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:21.801459 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m21:14:21.801610 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m21:14:21.801741 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m21:14:21.801868 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:14:21.802004 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:21.802134 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:23.437346 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m21:14:23.437909 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m21:14:23.438520 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:23.439024 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:23.439536 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */


  create view "dev"."public"."vw_sales__dbt_tmp" as (
    with source_sales as (
    select *
    from sales
),

renamed as (
    select 
        SALESID AS ID_VENDA,
        SELLERID AS ID_LISTA,
        BUYERID AS ID_COMPRADOR,
        EVENTID AS ID_EVENTO,
        DATEID AS ID_DATE,
        QTYSOLD AS QUANTIDADE_VENDIDA,
        PRICEPAID AS VALOR_PAGO,
        COMMISSION AS COMISSAO,
        TO_CHAR(SALETIME, 'dd/mm/yyyy HH24:MI:SS') AS DATA_HORA_VENDA,
        TO_CHAR(SALETIME, 'HH24:MI:SS') AS HORA_VENDA,
        cast(SALETIME as date) AS DATA_VENDA
    from source_sales
)

select * from renamed
  ) ;

[0m21:14:23.440000 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:14:23.641978 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0 seconds
[0m21:14:23.642548 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m21:14:23.655651 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:23.659115 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:23.659373 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales" rename to "vw_sales__dbt_backup"
[0m21:14:23.659550 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:14:23.846822 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:23.847296 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:23.855070 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:23.858505 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:23.858742 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:14:23.858954 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales__dbt_tmp" rename to "vw_sales"
[0m21:14:24.051587 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:24.052103 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:24.085873 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m21:14:24.087971 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m21:14:24.088383 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:24.088668 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:24.088904 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m21:14:24.089127 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m21:14:24.358999 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m21:14:24.359836 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:24.360181 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m21:14:24.360607 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m21:14:24.540411 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m21:14:24.554221 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:24.554545 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m21:14:24.768462 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m21:14:24.770521 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m21:14:24.770929 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:24.771189 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m21:14:24.973404 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m21:14:24.973907 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m21:14:24.974231 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m21:14:25.177986 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m21:14:25.179436 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 21:14:21.753581 => 2023-04-27 21:14:25.179331
[0m21:14:25.179811 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:25.180130 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m21:14:25.180517 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m21:14:25.382662 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m21:14:25.383161 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m21:14:25.387572 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:25.388978 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366869df0>]}
[0m21:14:25.389332 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
drop view if exists "dev"."public"."vw_sales__dbt_backup" cascade
[0m21:14:25.390192 [info ] [Thread-1  ]: 1 of 4 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.69s]
[0m21:14:25.393069 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m21:14:25.394230 [debug] [Thread-4  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m21:14:25.395162 [info ] [Thread-4  ]: 3 of 4 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m21:14:25.396935 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m21:14:25.397578 [debug] [Thread-4  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m21:14:25.404628 [debug] [Thread-4  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m21:14:25.405317 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 21:14:25.397915 => 2023-04-27 21:14:25.405188
[0m21:14:25.405726 [debug] [Thread-4  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m21:14:25.410019 [debug] [Thread-4  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m21:14:25.410459 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:25.410589 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m21:14:25.410679 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m21:14:25.410767 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:25.587752 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0 seconds
[0m21:14:25.590242 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m21:14:25.590738 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:25.591013 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m21:14:25.792418 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m21:14:25.792921 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m21:14:25.793202 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m21:14:25.997390 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m21:14:25.998757 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (execute): 2023-04-27 21:14:21.743316 => 2023-04-27 21:14:25.998658
[0m21:14:25.999141 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: ROLLBACK
[0m21:14:26.201939 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: Close
[0m21:14:26.203582 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366869f10>]}
[0m21:14:26.204496 [info ] [Thread-2  ]: 2 of 4 OK created sql view model public.vw_sales ............................... [[32mCREATE VIEW[0m in 4.46s]
[0m21:14:26.205415 [debug] [Thread-2  ]: Finished running node model.analytics_dbt.vw_sales
[0m21:14:26.206546 [debug] [Thread-1  ]: Began running node model.analytics_dbt.tb_10_compradores
[0m21:14:26.207158 [info ] [Thread-1  ]: 4 of 4 START sql table model public.tb_10_compradores .......................... [RUN]
[0m21:14:26.208317 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.tb_10_compradores'
[0m21:14:26.208744 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.tb_10_compradores
[0m21:14:26.214474 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.tb_10_compradores"
[0m21:14:26.215188 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.tb_10_compradores (compile): 2023-04-27 21:14:26.208964 => 2023-04-27 21:14:26.215072
[0m21:14:26.215539 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.tb_10_compradores
[0m21:14:26.222603 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.tb_10_compradores"
[0m21:14:26.223068 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:26.223207 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: BEGIN
[0m21:14:26.223297 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:14:26.223383 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:27.226492 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m21:14:27.226973 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:27.227269 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m21:14:27.431207 [debug] [Thread-4  ]: SQL status: CREATE VIEW in 0 seconds
[0m21:14:27.436771 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:27.437150 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:14:27.636036 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:27.639789 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m21:14:27.640223 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:27.640513 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m21:14:27.840616 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m21:14:27.841384 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:27.841712 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m21:14:27.981155 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m21:14:27.984801 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:27.985153 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m21:14:27.985453 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m21:14:27.985609 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:27.985725 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_10_compradores"} */

  
    

  create  table
    "dev"."public"."tb_10_compradores__dbt_tmp"
    
    
    
  as (
    with sales as  (
    select * from "dev"."public"."vw_sales"
),

compradores as (
    SELECT
        (firstname ||' '|| lastname) as Nome_Completo, userid
    FROM users
),

top_10_compradores as (

        SELECT
            compradores.Nome_Completo as Nome_Completo,
            sum(sales.quantidade_vendida) as Vendas_totais,
            sales.comissao as Comissao 
        FROM sales INNER JOIN compradores
        ON sales.id_comprador = compradores.userid
        GROUP BY compradores.userid, compradores.Nome_Completo, sales.comissao
        ORDER BY Vendas_totais DESC
        LIMIT 10

)

select * from top_10_compradores
  );
  
[0m21:14:28.125657 [debug] [Thread-4  ]: SQL status: DROP VIEW in 0 seconds
[0m21:14:28.127408 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m21:14:28.127786 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:28.128055 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m21:14:28.352637 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m21:14:28.353129 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m21:14:28.353403 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m21:14:28.557359 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m21:14:28.558692 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 21:14:25.405901 => 2023-04-27 21:14:28.558588
[0m21:14:28.559063 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m21:14:28.697461 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m21:14:28.699017 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1364525fd0>]}
[0m21:14:28.699834 [info ] [Thread-4  ]: 3 of 4 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.30s]
[0m21:14:28.700443 [debug] [Thread-4  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m21:14:38.286286 [debug] [Thread-1  ]: SQL status: SELECT in 10 seconds
[0m21:14:38.292155 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:38.292599 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_10_compradores"} */
alter table "dev"."public"."tb_10_compradores__dbt_tmp" rename to "tb_10_compradores"
[0m21:14:38.490914 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m21:14:38.495169 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: COMMIT
[0m21:14:38.495574 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:38.495863 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: COMMIT
[0m21:14:38.696019 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m21:14:38.696874 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:38.697227 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: BEGIN
[0m21:14:38.901252 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m21:14:38.905846 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:38.906247 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_10_compradores"} */
drop table if exists "dev"."public"."tb_10_compradores__dbt_backup" cascade
[0m21:14:39.105332 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m21:14:39.107255 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: COMMIT
[0m21:14:39.107624 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:39.107884 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: COMMIT
[0m21:14:39.310120 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m21:14:39.310892 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_10_compradores"
[0m21:14:39.311357 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: BEGIN
[0m21:14:39.514939 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m21:14:39.516320 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.tb_10_compradores (execute): 2023-04-27 21:14:26.215708 => 2023-04-27 21:14:39.516219
[0m21:14:39.516690 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: ROLLBACK
[0m21:14:39.719687 [debug] [Thread-1  ]: On model.analytics_dbt.tb_10_compradores: Close
[0m21:14:39.721342 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b18360f1-278b-4884-9af0-17b2e8e00145', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1366869dc0>]}
[0m21:14:39.722121 [info ] [Thread-1  ]: 4 of 4 OK created sql table model public.tb_10_compradores ..................... [[32mSELECT[0m in 13.51s]
[0m21:14:39.722814 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.tb_10_compradores
[0m21:14:39.725684 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:14:39.726457 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:39.727036 [debug] [MainThread]: On master: BEGIN
[0m21:14:39.727559 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:14:39.728101 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m21:14:41.460650 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m21:14:41.461180 [debug] [MainThread]: On master: COMMIT
[0m21:14:41.461511 [debug] [MainThread]: Using redshift connection "master"
[0m21:14:41.461792 [debug] [MainThread]: On master: COMMIT
[0m21:14:41.665517 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m21:14:41.666060 [debug] [MainThread]: On master: Close
[0m21:14:41.667215 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:14:41.667530 [debug] [MainThread]: Connection 'model.analytics_dbt.tb_10_compradores' was properly closed.
[0m21:14:41.667766 [debug] [MainThread]: Connection 'model.analytics_dbt.vw_sales' was properly closed.
[0m21:14:41.667980 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m21:14:41.668362 [info ] [MainThread]: 
[0m21:14:41.668772 [info ] [MainThread]: Finished running 2 table models, 2 view models in 0 hours 0 minutes and 26.50 seconds (26.50s).
[0m21:14:41.669649 [debug] [MainThread]: Command end result
[0m21:14:41.681237 [info ] [MainThread]: 
[0m21:14:41.681657 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:14:41.681914 [info ] [MainThread]: 
[0m21:14:41.682161 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m21:14:41.682562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13655dd4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13656223a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1364dc16d0>]}
[0m21:14:41.682856 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 22:15:13.284106 | 70419947-5b0f-4c36-a620-d492e59fdda1 ==============================
[0m22:15:13.284106 [info ] [MainThread]: Running with dbt=1.4.6
[0m22:15:13.284887 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['/models/tables/tb_vendas_primeiro_trimestre.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:15:13.285001 [debug] [MainThread]: Tracking: tracking
[0m22:15:13.291781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3c61d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3c61fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3c61fd0>]}
[0m22:15:13.303459 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m22:15:13.319295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:15:13.319597 [debug] [MainThread]: Partial parsing: added file: analytics_dbt://models/tables/tb_vendas_primeiro_trimestre.sql
[0m22:15:13.332269 [debug] [MainThread]: 1603: static parser failed on tables/tb_vendas_primeiro_trimestre.sql
[0m22:15:13.341627 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tables/tb_vendas_primeiro_trimestre.sql
[0m22:15:13.348231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70419947-5b0f-4c36-a620-d492e59fdda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3a643d0>]}
[0m22:15:13.352457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70419947-5b0f-4c36-a620-d492e59fdda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3ae1f10>]}
[0m22:15:13.352710 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m22:15:13.352931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70419947-5b0f-4c36-a620-d492e59fdda1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3ae1fa0>]}
[0m22:15:13.353412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3b44af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3b448e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45d3b44a90>]}
[0m22:15:13.353585 [debug] [MainThread]: Flushing usage events
[0m22:15:14.196414 [error] [MainThread]: Encountered an error:
Non-relative patterns are unsupported
[0m22:15:14.199430 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 136, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 206, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 253, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 169, in _runtime_initialize
    self.job_queue = self.get_graph_queue()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 162, in get_graph_queue
    return selector.get_graph_queue(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 295, in get_graph_queue
    selected_nodes = self.get_selected(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 286, in get_selected
    selected_nodes, indirect_only = self.select_nodes(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 153, in select_nodes
    direct_nodes, indirect_nodes = self.select_nodes_recursively(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 123, in select_nodes_recursively
    direct_nodes, indirect_nodes = self.get_nodes_from_criteria(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 80, in get_nodes_from_criteria
    collected = self.select_included(nodes, spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 66, in select_included
    return set(method.search(included_nodes, spec.value))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in search
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in <genexpr>
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/lib/python3.8/pathlib.py", line 1138, in glob
    raise NotImplementedError("Non-relative patterns are unsupported")
NotImplementedError: Non-relative patterns are unsupported



============================== 2023-04-27 22:15:26.531916 | 390b1287-99b4-43c4-b823-9c36cd2e34c7 ==============================
[0m22:15:26.531916 [info ] [MainThread]: Running with dbt=1.4.6
[0m22:15:26.532800 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['models/tables/tb_vendas_primeiro_trimestre.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:15:26.532914 [debug] [MainThread]: Tracking: tracking
[0m22:15:26.539436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a60ec70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a60efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a60efa0>]}
[0m22:15:26.551140 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m22:15:26.566662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:15:26.566841 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:15:26.570931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '390b1287-99b4-43c4-b823-9c36cd2e34c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a525220>]}
[0m22:15:26.575510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '390b1287-99b4-43c4-b823-9c36cd2e34c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a5f1ca0>]}
[0m22:15:26.575783 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m22:15:26.575948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '390b1287-99b4-43c4-b823-9c36cd2e34c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a5f1a90>]}
[0m22:15:26.577053 [info ] [MainThread]: 
[0m22:15:26.578049 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:15:26.578804 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:15:26.587940 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:15:26.588131 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m22:15:26.588244 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:15:26.588373 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m22:15:28.647093 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m22:15:28.650051 [debug] [ThreadPool]: On list_dev: Close
[0m22:15:28.653800 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m22:15:28.661974 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m22:15:28.662137 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m22:15:28.662261 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:28.662412 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m22:15:30.490650 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m22:15:30.491247 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m22:15:30.491683 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m22:15:30.657752 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m22:15:30.660898 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m22:15:30.900416 [debug] [ThreadPool]: On list_dev_public: Close
[0m22:15:30.911772 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:30.911927 [debug] [MainThread]: On master: BEGIN
[0m22:15:30.912025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:15:30.912142 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m22:15:32.743166 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m22:15:32.743712 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:32.744059 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:15:32.947815 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m22:15:32.950587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '390b1287-99b4-43c4-b823-9c36cd2e34c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a5f1a60>]}
[0m22:15:32.951181 [debug] [MainThread]: On master: ROLLBACK
[0m22:15:33.152473 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:33.152979 [debug] [MainThread]: On master: BEGIN
[0m22:15:33.562601 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m22:15:33.563179 [debug] [MainThread]: On master: COMMIT
[0m22:15:33.563546 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:33.563868 [debug] [MainThread]: On master: COMMIT
[0m22:15:33.767449 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m22:15:33.768023 [debug] [MainThread]: On master: Close
[0m22:15:33.769261 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:15:33.769780 [info ] [MainThread]: 
[0m22:15:33.777150 [debug] [Thread-1  ]: Began running node model.analytics_dbt.tb_vendas_primeiro_trimestre
[0m22:15:33.777965 [info ] [Thread-1  ]: 1 of 1 START sql table model public.tb_vendas_primeiro_trimestre ............... [RUN]
[0m22:15:33.779353 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.tb_vendas_primeiro_trimestre'
[0m22:15:33.779855 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.tb_vendas_primeiro_trimestre
[0m22:15:33.786975 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:33.787716 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.tb_vendas_primeiro_trimestre (compile): 2023-04-27 22:15:33.780122 => 2023-04-27 22:15:33.787527
[0m22:15:33.788255 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.tb_vendas_primeiro_trimestre
[0m22:15:33.824233 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:33.824590 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:33.824720 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: BEGIN
[0m22:15:33.824814 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:15:33.824912 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m22:15:35.405241 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m22:15:35.405751 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:35.406141 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_vendas_primeiro_trimestre"} */

  
    

  create  table
    "dev"."public"."tb_vendas_primeiro_trimestre__dbt_tmp"
    
    
    
  as (
    


with source_date as (
    select dateid as id_date,
    month as mes,
    year as ano
    from date
),
sales_date as (
    select source_date.mes,
        sum(quantidade_vendida)
    from "dev"."public"."vw_sales" sales
    inner join source_date
    on sales.id_date = source_date.id_date
    where source_date.mes in ('JAN', 'FEB', 'MAR')
    and source_date.ano = '2008'
    group by source_date.mes
)
select * from sales_date
  );
  
[0m22:15:49.025070 [debug] [Thread-1  ]: SQL status: SELECT in 14 seconds
[0m22:15:49.037423 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:49.037773 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_vendas_primeiro_trimestre"} */
alter table "dev"."public"."tb_vendas_primeiro_trimestre__dbt_tmp" rename to "tb_vendas_primeiro_trimestre"
[0m22:15:49.229078 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m22:15:49.254277 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: COMMIT
[0m22:15:49.254495 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:49.254581 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: COMMIT
[0m22:15:50.560622 [debug] [Thread-1  ]: SQL status: COMMIT in 1 seconds
[0m22:15:50.561480 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:50.561831 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: BEGIN
[0m22:15:50.765172 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m22:15:50.778694 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:50.779266 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.tb_vendas_primeiro_trimestre"} */
drop table if exists "dev"."public"."tb_vendas_primeiro_trimestre__dbt_backup" cascade
[0m22:15:50.970055 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m22:15:50.971844 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: COMMIT
[0m22:15:50.972205 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:50.972512 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: COMMIT
[0m22:15:51.174895 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m22:15:51.175403 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.tb_vendas_primeiro_trimestre"
[0m22:15:51.175722 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: BEGIN
[0m22:15:51.482118 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m22:15:51.483417 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.tb_vendas_primeiro_trimestre (execute): 2023-04-27 22:15:33.788543 => 2023-04-27 22:15:51.483316
[0m22:15:51.483790 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: ROLLBACK
[0m22:15:51.686608 [debug] [Thread-1  ]: On model.analytics_dbt.tb_vendas_primeiro_trimestre: Close
[0m22:15:51.688268 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '390b1287-99b4-43c4-b823-9c36cd2e34c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1009cb5d30>]}
[0m22:15:51.689151 [info ] [Thread-1  ]: 1 of 1 OK created sql table model public.tb_vendas_primeiro_trimestre .......... [[32mSELECT[0m in 17.91s]
[0m22:15:51.692251 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.tb_vendas_primeiro_trimestre
[0m22:15:51.695270 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:15:51.695810 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:51.696176 [debug] [MainThread]: On master: BEGIN
[0m22:15:51.696645 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:15:51.697181 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m22:15:53.330797 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m22:15:53.331398 [debug] [MainThread]: On master: COMMIT
[0m22:15:53.331790 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:53.332143 [debug] [MainThread]: On master: COMMIT
[0m22:15:53.530977 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m22:15:53.531595 [debug] [MainThread]: On master: Close
[0m22:15:53.532674 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:15:53.532982 [debug] [MainThread]: Connection 'model.analytics_dbt.tb_vendas_primeiro_trimestre' was properly closed.
[0m22:15:53.533347 [info ] [MainThread]: 
[0m22:15:53.533775 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 26.96 seconds (26.96s).
[0m22:15:53.534450 [debug] [MainThread]: Command end result
[0m22:15:53.542185 [info ] [MainThread]: 
[0m22:15:53.542657 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:15:53.542894 [info ] [MainThread]: 
[0m22:15:53.543094 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:15:53.543371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a584ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a584cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100a5f1d90>]}
[0m22:15:53.543680 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 00:34:38.465944 | 3f18dc57-0d72-4a53-88b4-5207dd7272f5 ==============================
[0m00:34:38.465944 [info ] [MainThread]: Running with dbt=1.4.6
[0m00:34:38.467199 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m00:34:38.467315 [debug] [MainThread]: Tracking: tracking
[0m00:34:38.475702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c7cca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c7cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c7cf70>]}
[0m00:34:38.491789 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m00:34:38.511504 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:34:38.511708 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:34:38.516479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f18dc57-0d72-4a53-88b4-5207dd7272f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8b94280>]}
[0m00:34:38.521348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f18dc57-0d72-4a53-88b4-5207dd7272f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c5fd00>]}
[0m00:34:38.521618 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m00:34:38.521808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f18dc57-0d72-4a53-88b4-5207dd7272f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c5faf0>]}
[0m00:34:38.522858 [info ] [MainThread]: 
[0m00:34:38.523904 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:34:38.524905 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m00:34:38.535368 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:34:38.535672 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m00:34:38.535816 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:38.535939 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:40.587167 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m00:34:40.587681 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:34:40.587991 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m00:34:40.754753 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m00:34:40.757863 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m00:34:40.909498 [debug] [ThreadPool]: On list_dev_public: Close
[0m00:34:40.923079 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:40.923621 [debug] [MainThread]: On master: BEGIN
[0m00:34:40.923992 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:34:40.924335 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:42.789274 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:34:42.789754 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:42.790047 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:34:42.993927 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m00:34:42.996607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f18dc57-0d72-4a53-88b4-5207dd7272f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c5fa90>]}
[0m00:34:42.997217 [debug] [MainThread]: On master: ROLLBACK
[0m00:34:43.199578 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:43.200222 [debug] [MainThread]: On master: BEGIN
[0m00:34:43.608728 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m00:34:43.609323 [debug] [MainThread]: On master: COMMIT
[0m00:34:43.609678 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:43.609984 [debug] [MainThread]: On master: COMMIT
[0m00:34:43.813211 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:34:43.813829 [debug] [MainThread]: On master: Close
[0m00:34:43.815613 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:34:43.816167 [info ] [MainThread]: 
[0m00:34:43.822911 [debug] [Thread-1  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:34:43.823624 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:34:43.824608 [debug] [Thread-3  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:34:43.825178 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:34:43.825701 [info ] [Thread-1  ]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m00:34:43.826614 [info ] [Thread-2  ]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m00:34:43.827347 [info ] [Thread-3  ]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m00:34:43.828392 [info ] [Thread-4  ]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m00:34:43.830199 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m00:34:43.831406 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m00:34:43.832589 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m00:34:43.833844 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m00:34:43.834452 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:34:43.834880 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:34:43.835277 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:34:43.835637 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:34:43.848449 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:34:43.851683 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:34:43.856557 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:34:43.859499 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:34:43.860042 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 00:34:43.848657 => 2023-04-28 00:34:43.859970
[0m00:34:43.860160 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 00:34:43.835958 => 2023-04-28 00:34:43.860127
[0m00:34:43.860394 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:34:43.860507 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 00:34:43.852003 => 2023-04-28 00:34:43.860461
[0m00:34:43.860670 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:34:43.860807 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 00:34:43.856727 => 2023-04-28 00:34:43.860755
[0m00:34:43.871305 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:34:43.871574 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:34:43.873781 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:34:43.874025 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:34:43.875773 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:34:43.877520 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:34:43.877732 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:34:43.877894 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:34:43.878112 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m00:34:43.878253 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m00:34:43.878376 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:34:43.878506 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:34:43.878634 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m00:34:43.878741 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:34:43.878856 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m00:34:43.878987 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m00:34:43.879116 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:43.879217 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:43.879322 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m00:34:43.879429 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m00:34:43.879748 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:43.879883 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:45.656971 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m00:34:45.657490 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m00:34:45.657906 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m00:34:45.658323 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:34:45.658635 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m00:34:45.658994 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:34:45.659461 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:34:45.659973 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:34:45.660465 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:34:45.660852 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:34:45.661282 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:34:45.661888 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:34:45.827076 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m00:34:45.832012 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 00:34:43.860902 => 2023-04-28 00:34:45.831875
[0m00:34:45.832500 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m00:34:45.973257 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m00:34:45.974957 [info ] [Thread-2  ]: 2 of 4 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.14s]
[0m00:34:45.977824 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:34:46.168564 [debug] [Thread-1  ]: SQL status: SELECT in 1 seconds
[0m00:34:46.171437 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 00:34:43.871705 => 2023-04-28 00:34:46.171308
[0m00:34:46.171888 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m00:34:46.174739 [debug] [Thread-4  ]: SQL status: SELECT in 1 seconds
[0m00:34:46.177350 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 00:34:43.876055 => 2023-04-28 00:34:46.177229
[0m00:34:46.177795 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m00:34:46.178230 [debug] [Thread-3  ]: SQL status: SELECT in 1 seconds
[0m00:34:46.181024 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 00:34:43.874230 => 2023-04-28 00:34:46.180880
[0m00:34:46.181587 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m00:34:46.332056 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m00:34:46.332692 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m00:34:46.333151 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m00:34:46.334584 [error] [Thread-1  ]: 1 of 4 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.50s]
[0m00:34:46.335322 [info ] [Thread-3  ]: 3 of 4 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.50s]
[0m00:34:46.335821 [info ] [Thread-4  ]: 4 of 4 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.50s]
[0m00:34:46.336110 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:34:46.336290 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:34:46.336462 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:34:46.337534 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:34:46.337729 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:46.337844 [debug] [MainThread]: On master: BEGIN
[0m00:34:46.337947 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:34:46.338048 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:34:48.011903 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:34:48.012453 [debug] [MainThread]: On master: COMMIT
[0m00:34:48.014854 [debug] [MainThread]: Using redshift connection "master"
[0m00:34:48.015366 [debug] [MainThread]: On master: COMMIT
[0m00:34:48.216410 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:34:48.217112 [debug] [MainThread]: On master: Close
[0m00:34:48.218524 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:34:48.218867 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m00:34:48.219087 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m00:34:48.219354 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m00:34:48.219603 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m00:34:48.219993 [info ] [MainThread]: 
[0m00:34:48.220522 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 9.70 seconds (9.70s).
[0m00:34:48.221386 [debug] [MainThread]: Command end result
[0m00:34:48.232443 [info ] [MainThread]: 
[0m00:34:48.232782 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:34:48.232965 [info ] [MainThread]: 
[0m00:34:48.233170 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m00:34:48.233330 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:34:48.233508 [info ] [MainThread]: 
[0m00:34:48.233704 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m00:34:48.233905 [info ] [MainThread]: 
[0m00:34:48.234111 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m00:34:48.234419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c5fdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e8c5fd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63e829a2b0>]}
[0m00:34:48.234637 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 00:45:47.623439 | c8a31c59-4589-44c0-abb7-814bf6a5070a ==============================
[0m00:45:47.623439 [info ] [MainThread]: Running with dbt=1.4.6
[0m00:45:47.624321 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m00:45:47.624451 [debug] [MainThread]: Tracking: tracking
[0m00:45:47.631025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab914fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab914ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab914ffa0>]}
[0m00:45:47.645121 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m00:45:47.660914 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m00:45:47.661223 [debug] [MainThread]: Partial parsing: added file: analytics_dbt://tests/test_singular_nao_negativo.sql
[0m00:45:47.689710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8a31c59-4589-44c0-abb7-814bf6a5070a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab8f593a0>]}
[0m00:45:47.694359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8a31c59-4589-44c0-abb7-814bf6a5070a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab903fc40>]}
[0m00:45:47.694653 [info ] [MainThread]: Found 5 models, 5 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m00:45:47.694819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8a31c59-4589-44c0-abb7-814bf6a5070a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab903ff70>]}
[0m00:45:47.695860 [info ] [MainThread]: 
[0m00:45:47.696829 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:45:47.697774 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m00:45:47.707369 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:45:47.707621 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m00:45:47.707755 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:45:47.707879 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:49.588845 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m00:45:49.589423 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:45:49.589808 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m00:45:49.793577 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m00:45:49.796666 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m00:45:49.949770 [debug] [ThreadPool]: On list_dev_public: Close
[0m00:45:49.962752 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:49.963209 [debug] [MainThread]: On master: BEGIN
[0m00:45:49.963515 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:45:49.963834 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:51.636927 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:45:51.637465 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:51.637871 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:45:51.837597 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m00:45:51.840831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8a31c59-4589-44c0-abb7-814bf6a5070a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab903fd00>]}
[0m00:45:51.841524 [debug] [MainThread]: On master: ROLLBACK
[0m00:45:52.046344 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:52.046876 [debug] [MainThread]: On master: BEGIN
[0m00:45:52.455844 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m00:45:52.456599 [debug] [MainThread]: On master: COMMIT
[0m00:45:52.458791 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:52.459286 [debug] [MainThread]: On master: COMMIT
[0m00:45:52.660905 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:45:52.661429 [debug] [MainThread]: On master: Close
[0m00:45:52.662695 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:45:52.663202 [info ] [MainThread]: 
[0m00:45:52.671691 [debug] [Thread-1  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:45:52.672615 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:45:52.673488 [debug] [Thread-3  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m00:45:52.674678 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:45:52.674117 [info ] [Thread-1  ]: 1 of 5 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m00:45:52.675362 [info ] [Thread-2  ]: 2 of 5 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m00:45:52.675954 [info ] [Thread-3  ]: 3 of 5 START test test_singular_nao_negativo ................................... [RUN]
[0m00:45:52.676586 [info ] [Thread-4  ]: 4 of 5 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m00:45:52.677872 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m00:45:52.678727 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m00:45:52.679754 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m00:45:52.680422 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m00:45:52.680735 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:45:52.681068 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:45:52.681377 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m00:45:52.681599 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:45:52.696116 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:45:52.697678 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:45:52.698846 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m00:45:52.703627 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:45:52.704091 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 00:45:52.692019 => 2023-04-28 00:45:52.704018
[0m00:45:52.704405 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:45:52.709760 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 00:45:52.681749 => 2023-04-28 00:45:52.709653
[0m00:45:52.715160 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 00:45:52.698993 => 2023-04-28 00:45:52.715084
[0m00:45:52.715354 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:45:52.715935 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:45:52.716282 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 00:45:52.697909 => 2023-04-28 00:45:52.716229
[0m00:45:52.716422 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:45:52.718056 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:45:52.718380 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m00:45:52.719877 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:45:52.722154 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m00:45:52.722340 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:45:52.722661 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:45:52.722778 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m00:45:52.722936 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:45:52.723020 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m00:45:52.723130 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m00:45:52.723251 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m00:45:52.723376 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m00:45:52.723496 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:45:52.723604 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m00:45:52.723713 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:52.723825 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m00:45:52.723931 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:52.724034 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m00:45:52.724264 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:52.724558 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:54.504406 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m00:45:54.504973 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m00:45:54.505454 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m00:45:54.505876 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:45:54.506269 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m00:45:54.506692 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:45:54.507074 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:45:54.507531 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:45:54.507945 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m00:45:54.508250 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:45:54.508726 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:45:54.509239 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m00:45:54.666004 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m00:45:54.670822 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 00:45:52.716522 => 2023-04-28 00:45:54.670685
[0m00:45:54.671298 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m00:45:54.671678 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m00:45:54.672127 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m00:45:54.675073 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 00:45:52.718541 => 2023-04-28 00:45:54.674953
[0m00:45:54.677786 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 00:45:52.704503 => 2023-04-28 00:45:54.677663
[0m00:45:54.678599 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m00:45:54.679089 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m00:45:54.746944 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m00:45:54.749657 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 00:45:52.720111 => 2023-04-28 00:45:54.749511
[0m00:45:54.750053 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m00:45:54.817365 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m00:45:54.818014 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m00:45:54.819626 [info ] [Thread-2  ]: 2 of 5 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.14s]
[0m00:45:54.823762 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:45:54.826098 [debug] [Thread-2  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:45:54.825234 [info ] [Thread-4  ]: 4 of 5 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.14s]
[0m00:45:54.827375 [info ] [Thread-2  ]: 5 of 5 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m00:45:54.828294 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:45:54.829560 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m00:45:54.829979 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m00:45:54.830651 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:45:54.833898 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:45:54.834357 [error] [Thread-1  ]: 1 of 5 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.16s]
[0m00:45:54.834733 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:45:54.835084 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 00:45:54.830935 => 2023-04-28 00:45:54.835020
[0m00:45:54.835304 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:45:54.837010 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:45:54.837381 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:45:54.837513 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m00:45:54.837635 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m00:45:54.837741 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:54.889852 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m00:45:54.891547 [info ] [Thread-3  ]: 3 of 5 PASS test_singular_nao_negativo ......................................... [[32mPASS[0m in 2.21s]
[0m00:45:54.892343 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m00:45:56.551769 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m00:45:56.552480 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:45:56.552951 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:45:56.757878 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m00:45:56.760618 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 00:45:54.835406 => 2023-04-28 00:45:56.760495
[0m00:45:56.760995 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m00:45:56.902282 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m00:45:56.903942 [info ] [Thread-2  ]: 5 of 5 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.07s]
[0m00:45:56.904733 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:45:56.907255 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:45:56.907661 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:56.907784 [debug] [MainThread]: On master: BEGIN
[0m00:45:56.907892 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:45:56.907995 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:45:58.599782 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:45:58.600358 [debug] [MainThread]: On master: COMMIT
[0m00:45:58.600697 [debug] [MainThread]: Using redshift connection "master"
[0m00:45:58.600985 [debug] [MainThread]: On master: COMMIT
[0m00:45:58.804531 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:45:58.805155 [debug] [MainThread]: On master: Close
[0m00:45:58.806398 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:45:58.806810 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m00:45:58.807112 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m00:45:58.807364 [debug] [MainThread]: Connection 'test.analytics_dbt.test_singular_nao_negativo' was properly closed.
[0m00:45:58.807617 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m00:45:58.807966 [info ] [MainThread]: 
[0m00:45:58.808461 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 11.11 seconds (11.11s).
[0m00:45:58.809444 [debug] [MainThread]: Command end result
[0m00:45:58.818566 [info ] [MainThread]: 
[0m00:45:58.819094 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:45:58.819303 [info ] [MainThread]: 
[0m00:45:58.819515 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m00:45:58.819673 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:45:58.819842 [info ] [MainThread]: 
[0m00:45:58.819986 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m00:45:58.820152 [info ] [MainThread]: 
[0m00:45:58.820307 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m00:45:58.820593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab8623160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab8632f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab8ef65b0>]}
[0m00:45:58.820784 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 00:46:42.297260 | 723f1ca3-bb82-4f92-9f42-9c6bd05c2d86 ==============================
[0m00:46:42.297260 [info ] [MainThread]: Running with dbt=1.4.6
[0m00:46:42.298088 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m00:46:42.298224 [debug] [MainThread]: Tracking: tracking
[0m00:46:42.305029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be7f7c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be7f7fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be7f7fa0>]}
[0m00:46:42.317973 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m00:46:42.334155 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m00:46:42.334689 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://tests/test_singular_nao_negativo.sql
[0m00:46:42.362096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '723f1ca3-bb82-4f92-9f42-9c6bd05c2d86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be702640>]}
[0m00:46:42.366756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '723f1ca3-bb82-4f92-9f42-9c6bd05c2d86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be76b880>]}
[0m00:46:42.367151 [info ] [MainThread]: Found 5 models, 5 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m00:46:42.367443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '723f1ca3-bb82-4f92-9f42-9c6bd05c2d86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be7911c0>]}
[0m00:46:42.368801 [info ] [MainThread]: 
[0m00:46:42.369903 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:46:42.370995 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m00:46:42.379980 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:46:42.380208 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m00:46:42.380366 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:46:42.380508 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:44.267772 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m00:46:44.268351 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m00:46:44.268710 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m00:46:44.472488 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m00:46:44.475687 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m00:46:44.677006 [debug] [ThreadPool]: On list_dev_public: Close
[0m00:46:44.681961 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:44.682175 [debug] [MainThread]: On master: BEGIN
[0m00:46:44.682308 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:46:44.682427 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:46.315368 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:46:46.315978 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:46.316427 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:46:46.520295 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m00:46:46.523097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '723f1ca3-bb82-4f92-9f42-9c6bd05c2d86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be813220>]}
[0m00:46:46.523738 [debug] [MainThread]: On master: ROLLBACK
[0m00:46:46.725155 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:46.725761 [debug] [MainThread]: On master: BEGIN
[0m00:46:47.134851 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m00:46:47.135762 [debug] [MainThread]: On master: COMMIT
[0m00:46:47.136373 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:47.136901 [debug] [MainThread]: On master: COMMIT
[0m00:46:47.339423 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:46:47.339943 [debug] [MainThread]: On master: Close
[0m00:46:47.341066 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:46:47.341567 [info ] [MainThread]: 
[0m00:46:47.349889 [debug] [Thread-1  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:46:47.350699 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:46:47.352164 [debug] [Thread-3  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m00:46:47.352965 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:46:47.351347 [info ] [Thread-1  ]: 1 of 5 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m00:46:47.353788 [info ] [Thread-2  ]: 2 of 5 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m00:46:47.354497 [info ] [Thread-3  ]: 3 of 5 START test test_singular_nao_negativo ................................... [RUN]
[0m00:46:47.355232 [info ] [Thread-4  ]: 4 of 5 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m00:46:47.356585 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m00:46:47.357400 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m00:46:47.358449 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m00:46:47.359377 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m00:46:47.359851 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:46:47.360217 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:46:47.360582 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m00:46:47.360981 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:46:47.375893 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:46:47.377614 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:46:47.378875 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m00:46:47.384822 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:46:47.385351 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 00:46:47.371541 => 2023-04-28 00:46:47.385259
[0m00:46:47.385694 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 00:46:47.361250 => 2023-04-28 00:46:47.385632
[0m00:46:47.385935 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:46:47.386122 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 00:46:47.377813 => 2023-04-28 00:46:47.386061
[0m00:46:47.386334 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 00:46:47.379006 => 2023-04-28 00:46:47.386277
[0m00:46:47.386511 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:46:47.396327 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:46:47.396546 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m00:46:47.396732 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:46:47.398579 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:46:47.400596 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m00:46:47.402876 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:46:47.403202 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:46:47.403529 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m00:46:47.403637 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m00:46:47.403777 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:46:47.403915 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:47.404078 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:46:47.404193 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m00:46:47.404313 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m00:46:47.404519 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m00:46:47.404623 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:46:47.404746 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m00:46:47.404889 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m00:46:47.404998 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:47.405096 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m00:46:47.405197 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:47.405382 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:49.182550 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m00:46:49.183255 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m00:46:49.183735 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m00:46:49.184315 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m00:46:49.184636 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m00:46:49.185003 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m00:46:49.185372 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:46:49.185684 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:46:49.185977 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m00:46:49.186378 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:46:49.186934 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:46:49.187429 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select count(*)
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m00:46:49.387461 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m00:46:49.388041 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m00:46:49.388784 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m00:46:49.389189 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m00:46:49.393636 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 00:46:47.398910 => 2023-04-28 00:46:49.393495
[0m00:46:49.396230 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 00:46:47.396858 => 2023-04-28 00:46:49.396118
[0m00:46:49.398899 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 00:46:47.386639 => 2023-04-28 00:46:49.398783
[0m00:46:49.401492 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 00:46:47.400812 => 2023-04-28 00:46:49.401343
[0m00:46:49.402052 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m00:46:49.402598 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m00:46:49.403072 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m00:46:49.403443 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m00:46:49.592637 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m00:46:49.593330 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m00:46:49.594763 [info ] [Thread-4  ]: 4 of 5 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.24s]
[0m00:46:49.595380 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m00:46:49.595913 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m00:46:49.597227 [error] [Thread-3  ]: 3 of 5 FAIL 1 test_singular_nao_negativo ....................................... [[31mFAIL 1[0m in 2.24s]
[0m00:46:49.600697 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m00:46:49.601391 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m00:46:49.603219 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:46:49.602196 [info ] [Thread-2  ]: 2 of 5 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.25s]
[0m00:46:49.602917 [error] [Thread-1  ]: 1 of 5 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.25s]
[0m00:46:49.603768 [info ] [Thread-4  ]: 5 of 5 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m00:46:49.604051 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m00:46:49.604286 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:46:49.604684 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m00:46:49.605038 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:46:49.608028 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:46:49.608409 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 00:46:49.605122 => 2023-04-28 00:46:49.608350
[0m00:46:49.608577 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:46:49.609979 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:46:49.610228 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:46:49.610351 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m00:46:49.610458 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m00:46:49.610558 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:51.639986 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m00:46:51.640498 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m00:46:51.640851 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:46:51.798038 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m00:46:51.799244 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 00:46:49.608658 => 2023-04-28 00:46:51.799178
[0m00:46:51.799466 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m00:46:51.950262 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m00:46:51.951976 [info ] [Thread-4  ]: 5 of 5 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.35s]
[0m00:46:51.952725 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m00:46:51.955265 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:46:51.955523 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:51.955642 [debug] [MainThread]: On master: BEGIN
[0m00:46:51.955752 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:46:51.955860 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m00:46:53.790217 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m00:46:53.790767 [debug] [MainThread]: On master: COMMIT
[0m00:46:53.791156 [debug] [MainThread]: Using redshift connection "master"
[0m00:46:53.791472 [debug] [MainThread]: On master: COMMIT
[0m00:46:53.994971 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m00:46:53.995523 [debug] [MainThread]: On master: Close
[0m00:46:53.996725 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:46:53.997046 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m00:46:53.997253 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m00:46:53.997441 [debug] [MainThread]: Connection 'test.analytics_dbt.test_singular_nao_negativo' was properly closed.
[0m00:46:53.997631 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m00:46:53.997948 [info ] [MainThread]: 
[0m00:46:53.998437 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 11.63 seconds (11.63s).
[0m00:46:53.999626 [debug] [MainThread]: Command end result
[0m00:46:54.006543 [info ] [MainThread]: 
[0m00:46:54.006867 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m00:46:54.007066 [info ] [MainThread]: 
[0m00:46:54.007238 [error] [MainThread]: [31mFailure in test test_singular_nao_negativo (tests/test_singular_nao_negativo.sql)[0m
[0m00:46:54.007406 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:46:54.007562 [info ] [MainThread]: 
[0m00:46:54.007755 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/tests/test_singular_nao_negativo.sql
[0m00:46:54.007906 [info ] [MainThread]: 
[0m00:46:54.008052 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m00:46:54.008191 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:46:54.008314 [info ] [MainThread]: 
[0m00:46:54.008461 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m00:46:54.008610 [info ] [MainThread]: 
[0m00:46:54.008776 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
[0m00:46:54.009045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1bc615b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1be791130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1bc5ef6a0>]}
[0m00:46:54.009258 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 01:00:56.050823 | 22f0e891-a5aa-4fa4-acd3-9e021de2deea ==============================
[0m01:00:56.050823 [info ] [MainThread]: Running with dbt=1.4.6
[0m01:00:56.051724 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m01:00:56.051839 [debug] [MainThread]: Tracking: tracking
[0m01:00:56.058214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d48a3cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d48a3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d48a3f70>]}
[0m01:00:56.070747 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m01:00:56.087672 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
[0m01:00:56.087955 [debug] [MainThread]: Partial parsing: added file: analytics_dbt://macros/test_nao_negativo.sql
[0m01:00:56.088207 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://models/example/schema.yml
[0m01:00:56.088375 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://tests/test_singular_nao_negativo.sql
[0m01:00:56.138459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22f0e891-a5aa-4fa4-acd3-9e021de2deea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d47573a0>]}
[0m01:00:56.144001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22f0e891-a5aa-4fa4-acd3-9e021de2deea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d4743a30>]}
[0m01:00:56.144296 [info ] [MainThread]: Found 5 models, 7 tests, 0 snapshots, 0 analyses, 330 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m01:00:56.144476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f0e891-a5aa-4fa4-acd3-9e021de2deea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d47bf970>]}
[0m01:00:56.145605 [info ] [MainThread]: 
[0m01:00:56.146595 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:00:56.147676 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:00:56.156269 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:00:56.156487 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:00:56.156632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:00:56.156760 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:00:58.054175 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m01:00:58.054719 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:00:58.055075 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m01:00:58.259156 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m01:00:58.262973 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:00:58.463774 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:00:58.476133 [debug] [MainThread]: Using redshift connection "master"
[0m01:00:58.476642 [debug] [MainThread]: On master: BEGIN
[0m01:00:58.476967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:00:58.477238 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:00.102455 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:01:00.102966 [debug] [MainThread]: Using redshift connection "master"
[0m01:01:00.103306 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:01:00.307611 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m01:01:00.310687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22f0e891-a5aa-4fa4-acd3-9e021de2deea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d4792b80>]}
[0m01:01:00.311341 [debug] [MainThread]: On master: ROLLBACK
[0m01:01:00.511728 [debug] [MainThread]: Using redshift connection "master"
[0m01:01:00.512265 [debug] [MainThread]: On master: BEGIN
[0m01:01:00.921988 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m01:01:00.922552 [debug] [MainThread]: On master: COMMIT
[0m01:01:00.922890 [debug] [MainThread]: Using redshift connection "master"
[0m01:01:00.923183 [debug] [MainThread]: On master: COMMIT
[0m01:01:01.126223 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:01:01.126779 [debug] [MainThread]: On master: Close
[0m01:01:01.128050 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:01:01.128569 [info ] [MainThread]: 
[0m01:01:01.135392 [debug] [Thread-1  ]: Began running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:01:01.135797 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:01:01.136180 [debug] [Thread-3  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:01:01.136620 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:01:01.136395 [info ] [Thread-1  ]: 1 of 7 START test nao_negativos_tb_10_compradores_vendas_totais ................ [RUN]
[0m01:01:01.136940 [info ] [Thread-2  ]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m01:01:01.137121 [info ] [Thread-3  ]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m01:01:01.138006 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53'
[0m01:01:01.137405 [info ] [Thread-4  ]: 4 of 7 START test not_null_tb_10_compradores_vendas_totais ..................... [RUN]
[0m01:01:01.138536 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m01:01:01.139102 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m01:01:01.139327 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:01:01.139686 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752'
[0m01:01:01.139885 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:01:01.140033 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:01:01.143201 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:01:01.149456 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:01:01.153013 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:01:01.156667 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:01:01.157246 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53 (compile): 2023-04-28 01:01:01.140144 => 2023-04-28 01:01:01.157166
[0m01:01:01.157642 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 01:01:01.149651 => 2023-04-28 01:01:01.157590
[0m01:01:01.157768 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 01:01:01.143389 => 2023-04-28 01:01:01.157727
[0m01:01:01.158352 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:01:01.158488 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (compile): 2023-04-28 01:01:01.153268 => 2023-04-28 01:01:01.158442
[0m01:01:01.158692 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:01:01.168892 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:01:01.169191 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:01:01.170942 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:01:01.172763 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:01:01.173286 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:01:01.173719 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m01:01:01.173947 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:01:01.174152 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:01:01.174282 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:01:01.174440 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m01:01:01.174559 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:01.174717 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: BEGIN
[0m01:01:01.174905 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m01:01:01.175149 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:01:01.175338 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:01.175560 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:01.176505 [debug] [Thread-1  ]: Compilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)
  'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:01:01.176746 [error] [Thread-1  ]: 1 of 7 ERROR nao_negativos_tb_10_compradores_vendas_totais ..................... [[31mERROR[0m in 0.04s]
[0m01:01:01.177800 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:01:01.178046 [debug] [Thread-1  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m01:01:01.178266 [info ] [Thread-1  ]: 5 of 7 START test test_singular_nao_negativo ................................... [RUN]
[0m01:01:01.178728 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m01:01:01.178925 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m01:01:01.180196 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:01:01.180527 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 01:01:01.179050 => 2023-04-28 01:01:01.180469
[0m01:01:01.180683 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m01:01:01.182094 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:01:01.182342 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:01:01.182450 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m01:01:01.182537 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:01:01.182633 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:02.969520 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:01:02.970080 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:01:02.970495 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:01:02.970811 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:01:02.971205 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:01:02.971763 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:01:02.972316 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:01:02.972728 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:01:02.973184 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:01:02.973830 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:01:02.974225 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select vendas_totais
from "dev"."public"."tb_10_compradores"
where vendas_totais is null



      
    ) dbt_internal_test
[0m01:01:02.974773 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m01:01:03.174063 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:01:03.174819 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:01:03.179675 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 01:01:01.158853 => 2023-04-28 01:01:03.179538
[0m01:01:03.180302 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:01:03.183627 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 01:01:01.180762 => 2023-04-28 01:01:03.183520
[0m01:01:03.184200 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m01:01:03.186710 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 01:01:01.169325 => 2023-04-28 01:01:03.186609
[0m01:01:03.187213 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m01:01:03.187886 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m01:01:03.259722 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:01:03.262557 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (execute): 2023-04-28 01:01:01.171373 => 2023-04-28 01:01:03.262434
[0m01:01:03.262934 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: ROLLBACK
[0m01:01:03.337588 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m01:01:03.339307 [info ] [Thread-3  ]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.20s]
[0m01:01:03.340188 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:01:03.340983 [debug] [Thread-3  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:01:03.341705 [info ] [Thread-3  ]: 6 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m01:01:03.343276 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m01:01:03.343820 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m01:01:03.344267 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m01:01:03.344935 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:01:03.351061 [error] [Thread-2  ]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.21s]
[0m01:01:03.353575 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:01:03.353801 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:01:03.351718 [info ] [Thread-1  ]: 5 of 7 PASS test_singular_nao_negativo ......................................... [[32mPASS[0m in 2.17s]
[0m01:01:03.354189 [debug] [Thread-2  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:01:03.354422 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m01:01:03.354592 [info ] [Thread-2  ]: 7 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m01:01:03.354774 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 01:01:03.345543 => 2023-04-28 01:01:03.354709
[0m01:01:03.355320 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m01:01:03.355510 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:01:03.355662 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:01:03.357672 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:01:03.361806 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:01:03.362310 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 01:01:03.357890 => 2023-04-28 01:01:03.362228
[0m01:01:03.362523 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:01:03.362718 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:01:03.362890 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m01:01:03.364622 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:01:03.364920 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m01:01:03.365149 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:03.365438 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:01:03.365567 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m01:01:03.365675 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m01:01:03.365772 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:03.403135 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: Close
[0m01:01:03.404630 [info ] [Thread-4  ]: 4 of 7 PASS not_null_tb_10_compradores_vendas_totais ........................... [[32mPASS[0m in 2.26s]
[0m01:01:03.405458 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:01:04.812463 [debug] [Thread-2  ]: SQL status: BEGIN in 1 seconds
[0m01:01:04.813011 [debug] [Thread-3  ]: SQL status: BEGIN in 1 seconds
[0m01:01:04.813438 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:01:04.813853 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:01:04.814226 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:01:04.814728 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:01:05.017385 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:01:05.020412 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 01:01:03.355754 => 2023-04-28 01:01:05.020273
[0m01:01:05.020956 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:01:05.021405 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m01:01:05.024123 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 01:01:03.363029 => 2023-04-28 01:01:05.024006
[0m01:01:05.024669 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m01:01:05.222735 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m01:01:05.223223 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m01:01:05.224668 [info ] [Thread-3  ]: 6 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 1.88s]
[0m01:01:05.227226 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:01:05.226177 [info ] [Thread-2  ]: 7 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 1.87s]
[0m01:01:05.228538 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:01:05.231180 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:01:05.231779 [debug] [MainThread]: Using redshift connection "master"
[0m01:01:05.232357 [debug] [MainThread]: On master: BEGIN
[0m01:01:05.232906 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:01:05.233449 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:01:06.908574 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:01:06.908874 [debug] [MainThread]: On master: COMMIT
[0m01:01:06.909034 [debug] [MainThread]: Using redshift connection "master"
[0m01:01:06.909169 [debug] [MainThread]: On master: COMMIT
[0m01:01:07.168569 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:01:07.169125 [debug] [MainThread]: On master: Close
[0m01:01:07.170311 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:01:07.170660 [debug] [MainThread]: Connection 'test.analytics_dbt.test_singular_nao_negativo' was properly closed.
[0m01:01:07.170885 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m01:01:07.171088 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m01:01:07.171285 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752' was properly closed.
[0m01:01:07.171603 [info ] [MainThread]: 
[0m01:01:07.172070 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 11.03 seconds (11.03s).
[0m01:01:07.173278 [debug] [MainThread]: Command end result
[0m01:01:07.185180 [info ] [MainThread]: 
[0m01:01:07.185728 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m01:01:07.186011 [info ] [MainThread]: 
[0m01:01:07.186289 [error] [MainThread]: [33mCompilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)[0m
[0m01:01:07.186582 [error] [MainThread]:   'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:01:07.186847 [info ] [MainThread]: 
[0m01:01:07.187205 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m01:01:07.187450 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m01:01:07.187660 [info ] [MainThread]: 
[0m01:01:07.187893 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m01:01:07.188047 [info ] [MainThread]: 
[0m01:01:07.188184 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=2 SKIP=0 TOTAL=7
[0m01:01:07.188491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d4844070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d0e6b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28d46e5ca0>]}
[0m01:01:07.188707 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 01:02:42.116159 | e2d9ed8f-e65d-4f73-abd1-8d2281c21109 ==============================
[0m01:02:42.116159 [info ] [MainThread]: Running with dbt=1.4.6
[0m01:02:42.117015 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m01:02:42.117138 [debug] [MainThread]: Tracking: tracking
[0m01:02:42.123716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd85c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd85fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd85fa0>]}
[0m01:02:42.135469 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m01:02:42.152211 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:02:42.152417 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:02:42.156919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2d9ed8f-e65d-4f73-abd1-8d2281c21109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bca8dc0>]}
[0m01:02:42.161982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2d9ed8f-e65d-4f73-abd1-8d2281c21109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd686a0>]}
[0m01:02:42.162256 [info ] [MainThread]: Found 5 models, 7 tests, 0 snapshots, 0 analyses, 330 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m01:02:42.162435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2d9ed8f-e65d-4f73-abd1-8d2281c21109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd68970>]}
[0m01:02:42.163645 [info ] [MainThread]: 
[0m01:02:42.164665 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:02:42.165913 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:02:42.174997 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:02:42.175228 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:02:42.175384 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:02:42.175523 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:44.139531 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m01:02:44.140138 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:02:44.140560 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m01:02:44.343875 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m01:02:44.347403 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:02:44.548728 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:02:44.557826 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:44.558004 [debug] [MainThread]: On master: BEGIN
[0m01:02:44.558106 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:02:44.558203 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:46.494157 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:02:46.494688 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:46.495054 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:02:46.699270 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m01:02:46.702248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2d9ed8f-e65d-4f73-abd1-8d2281c21109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865bd68670>]}
[0m01:02:46.702966 [debug] [MainThread]: On master: ROLLBACK
[0m01:02:46.904537 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:46.905068 [debug] [MainThread]: On master: BEGIN
[0m01:02:47.319177 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m01:02:47.319749 [debug] [MainThread]: On master: COMMIT
[0m01:02:47.320130 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:47.320457 [debug] [MainThread]: On master: COMMIT
[0m01:02:47.518152 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:02:47.518782 [debug] [MainThread]: On master: Close
[0m01:02:47.520111 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:02:47.520630 [info ] [MainThread]: 
[0m01:02:47.527917 [debug] [Thread-1  ]: Began running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:02:47.528871 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:02:47.530055 [debug] [Thread-3  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:02:47.531152 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:02:47.530573 [info ] [Thread-1  ]: 1 of 7 START test nao_negativos_tb_10_compradores_vendas_totais ................ [RUN]
[0m01:02:47.531798 [info ] [Thread-2  ]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m01:02:47.532776 [info ] [Thread-3  ]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m01:02:47.533862 [info ] [Thread-4  ]: 4 of 7 START test not_null_tb_10_compradores_vendas_totais ..................... [RUN]
[0m01:02:47.535466 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53'
[0m01:02:47.536508 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m01:02:47.537198 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m01:02:47.537524 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752'
[0m01:02:47.537694 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:02:47.537851 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:02:47.537989 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:02:47.538112 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:02:47.550805 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:02:47.553483 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:02:47.556223 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:02:47.556730 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53 (compile): 2023-04-28 01:02:47.538206 => 2023-04-28 01:02:47.556661
[0m01:02:47.557509 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 01:02:47.544188 => 2023-04-28 01:02:47.557457
[0m01:02:47.557685 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 01:02:47.551024 => 2023-04-28 01:02:47.557637
[0m01:02:47.557855 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:02:47.558009 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (compile): 2023-04-28 01:02:47.553700 => 2023-04-28 01:02:47.557975
[0m01:02:47.558143 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:02:47.568677 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:02:47.569631 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:02:47.571292 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:02:47.572639 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:02:47.573179 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:02:47.573434 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m01:02:47.573556 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m01:02:47.573692 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:47.573818 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:02:47.574222 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m01:02:47.574411 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:02:47.574518 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:02:47.574671 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: BEGIN
[0m01:02:47.574839 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:47.574976 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:02:47.575316 [debug] [Thread-1  ]: Compilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)
  'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:02:47.575427 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:47.575662 [error] [Thread-1  ]: 1 of 7 ERROR nao_negativos_tb_10_compradores_vendas_totais ..................... [[31mERROR[0m in 0.04s]
[0m01:02:47.576866 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:02:47.577098 [debug] [Thread-1  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m01:02:47.577315 [info ] [Thread-1  ]: 5 of 7 START test test_singular_nao_negativo ................................... [RUN]
[0m01:02:47.577762 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m01:02:47.577917 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m01:02:47.578937 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:02:47.579196 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 01:02:47.577990 => 2023-04-28 01:02:47.579150
[0m01:02:47.579333 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m01:02:47.580683 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:02:47.580920 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:02:47.581021 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m01:02:47.581115 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:02:47.581198 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:49.463600 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:02:49.464202 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:02:49.464676 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:02:49.465239 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:02:49.465612 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:02:49.466069 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:02:49.466644 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:02:49.467175 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:02:49.467617 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:02:49.468130 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:02:49.468670 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m01:02:49.469218 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select vendas_totais
from "dev"."public"."tb_10_compradores"
where vendas_totais is null



      
    ) dbt_internal_test
[0m01:02:49.668563 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:02:49.673840 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 01:02:47.579402 => 2023-04-28 01:02:49.673688
[0m01:02:49.674012 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m01:02:49.674152 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:02:49.674299 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:02:49.674433 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:02:49.675397 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 01:02:47.569936 => 2023-04-28 01:02:49.675352
[0m01:02:49.676303 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (execute): 2023-04-28 01:02:47.571495 => 2023-04-28 01:02:49.676260
[0m01:02:49.677090 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 01:02:47.558327 => 2023-04-28 01:02:49.677057
[0m01:02:49.677351 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m01:02:49.677556 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: ROLLBACK
[0m01:02:49.677710 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m01:02:49.873258 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m01:02:49.873804 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: Close
[0m01:02:49.874317 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m01:02:49.875833 [info ] [Thread-1  ]: 5 of 7 PASS test_singular_nao_negativo ......................................... [[32mPASS[0m in 2.30s]
[0m01:02:49.876591 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m01:02:49.877873 [info ] [Thread-4  ]: 4 of 7 PASS not_null_tb_10_compradores_vendas_totais ........................... [[32mPASS[0m in 2.34s]
[0m01:02:49.878887 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m01:02:49.880372 [error] [Thread-2  ]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.34s]
[0m01:02:49.881695 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:02:49.883180 [info ] [Thread-3  ]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.35s]
[0m01:02:49.884302 [debug] [Thread-1  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:02:49.884659 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:02:49.884894 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:02:49.885772 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:02:49.886198 [info ] [Thread-1  ]: 6 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m01:02:49.886620 [info ] [Thread-4  ]: 7 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m01:02:49.887241 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m01:02:49.887621 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m01:02:49.887779 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:02:49.887903 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:02:49.893687 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:02:49.896550 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:02:49.896942 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 01:02:49.887982 => 2023-04-28 01:02:49.896883
[0m01:02:49.897096 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 01:02:49.893982 => 2023-04-28 01:02:49.897060
[0m01:02:49.897227 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:02:49.897354 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:02:49.898718 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:02:49.900056 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:02:49.900366 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:02:49.900498 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:02:49.900584 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m01:02:49.900677 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m01:02:49.900769 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:02:49.900856 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m01:02:49.900947 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:49.901033 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:51.614220 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:02:51.614704 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:02:51.615023 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:02:51.615433 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:02:51.615787 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:02:51.616152 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:02:51.819015 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:02:51.821945 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 01:02:49.897442 => 2023-04-28 01:02:51.821817
[0m01:02:51.822415 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:02:51.822969 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m01:02:51.826138 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 01:02:49.898835 => 2023-04-28 01:02:51.826003
[0m01:02:51.826821 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m01:02:52.023596 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m01:02:52.024096 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m01:02:52.025707 [info ] [Thread-4  ]: 7 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.14s]
[0m01:02:52.028188 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:02:52.027258 [info ] [Thread-1  ]: 6 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.14s]
[0m01:02:52.029310 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:02:52.032099 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:02:52.032661 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:52.033085 [debug] [MainThread]: On master: BEGIN
[0m01:02:52.033273 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:02:52.033399 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:02:53.661959 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:02:53.662511 [debug] [MainThread]: On master: COMMIT
[0m01:02:53.662818 [debug] [MainThread]: Using redshift connection "master"
[0m01:02:53.663083 [debug] [MainThread]: On master: COMMIT
[0m01:02:53.823564 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:02:53.823872 [debug] [MainThread]: On master: Close
[0m01:02:53.824653 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:02:53.824899 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m01:02:53.824992 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m01:02:53.825058 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m01:02:53.825120 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m01:02:53.825247 [info ] [MainThread]: 
[0m01:02:53.825392 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 11.66 seconds (11.66s).
[0m01:02:53.825758 [debug] [MainThread]: Command end result
[0m01:02:53.831072 [info ] [MainThread]: 
[0m01:02:53.831325 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m01:02:53.831465 [info ] [MainThread]: 
[0m01:02:53.831613 [error] [MainThread]: [33mCompilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)[0m
[0m01:02:53.831763 [error] [MainThread]:   'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:02:53.831924 [info ] [MainThread]: 
[0m01:02:53.832099 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m01:02:53.832265 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m01:02:53.832423 [info ] [MainThread]: 
[0m01:02:53.832585 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m01:02:53.832719 [info ] [MainThread]: 
[0m01:02:53.832886 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=2 SKIP=0 TOTAL=7
[0m01:02:53.833117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f865b40cdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86582cb5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86582cb940>]}
[0m01:02:53.833288 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 01:03:37.844834 | c0d4289d-ea93-40db-aaa8-484429532f5b ==============================
[0m01:03:37.844834 [info ] [MainThread]: Running with dbt=1.4.6
[0m01:03:37.845619 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m01:03:37.845740 [debug] [MainThread]: Tracking: tracking
[0m01:03:37.852218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d4e670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d4efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d4efa0>]}
[0m01:03:37.864658 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m01:03:37.880934 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:03:37.881290 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://macros/test_nao_negativo.sql
[0m01:03:37.889192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0d4289d-ea93-40db-aaa8-484429532f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610c7e850>]}
[0m01:03:37.893778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0d4289d-ea93-40db-aaa8-484429532f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d37f70>]}
[0m01:03:37.894027 [info ] [MainThread]: Found 5 models, 7 tests, 0 snapshots, 0 analyses, 330 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m01:03:37.894185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0d4289d-ea93-40db-aaa8-484429532f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d37fa0>]}
[0m01:03:37.895329 [info ] [MainThread]: 
[0m01:03:37.896316 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:03:37.897353 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:03:37.905843 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:03:37.906028 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:03:37.906149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:03:37.906260 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:39.844121 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m01:03:39.844630 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:03:39.844969 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m01:03:40.048657 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m01:03:40.052026 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:03:40.253408 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:03:40.266389 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:40.266834 [debug] [MainThread]: On master: BEGIN
[0m01:03:40.267158 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:03:40.267452 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:42.055786 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:03:42.056341 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:42.056721 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:03:42.257543 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m01:03:42.260305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0d4289d-ea93-40db-aaa8-484429532f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610d37be0>]}
[0m01:03:42.260927 [debug] [MainThread]: On master: ROLLBACK
[0m01:03:42.506345 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:42.506852 [debug] [MainThread]: On master: BEGIN
[0m01:03:42.916226 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m01:03:42.916817 [debug] [MainThread]: On master: COMMIT
[0m01:03:42.917182 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:42.917523 [debug] [MainThread]: On master: COMMIT
[0m01:03:43.121286 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:03:43.121877 [debug] [MainThread]: On master: Close
[0m01:03:43.123204 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:03:43.123702 [info ] [MainThread]: 
[0m01:03:43.131289 [debug] [Thread-1  ]: Began running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:03:43.132355 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:03:43.133313 [debug] [Thread-3  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:03:43.134778 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:03:43.133948 [info ] [Thread-1  ]: 1 of 7 START test nao_negativos_tb_10_compradores_vendas_totais ................ [RUN]
[0m01:03:43.135912 [info ] [Thread-2  ]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m01:03:43.136133 [info ] [Thread-3  ]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m01:03:43.136836 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53'
[0m01:03:43.136420 [info ] [Thread-4  ]: 4 of 7 START test not_null_tb_10_compradores_vendas_totais ..................... [RUN]
[0m01:03:43.137390 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m01:03:43.137790 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m01:03:43.138002 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:03:43.138368 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752'
[0m01:03:43.138514 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:03:43.138658 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:03:43.144990 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:03:43.151675 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:03:43.154555 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:03:43.158232 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:03:43.158841 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53 (compile): 2023-04-28 01:03:43.138760 => 2023-04-28 01:03:43.158758
[0m01:03:43.159822 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 01:03:43.151884 => 2023-04-28 01:03:43.159760
[0m01:03:43.160062 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:03:43.160261 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (compile): 2023-04-28 01:03:43.154804 => 2023-04-28 01:03:43.160199
[0m01:03:43.160464 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 01:03:43.145196 => 2023-04-28 01:03:43.160406
[0m01:03:43.170261 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:03:43.170490 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:03:43.170712 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:03:43.172338 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:03:43.173977 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:03:43.174314 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:03:43.174642 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m01:03:43.174791 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:03:43.174920 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:03:43.175118 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: BEGIN
[0m01:03:43.175337 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:43.175458 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:03:43.175597 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:03:43.175945 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m01:03:43.176125 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:43.176338 [debug] [Thread-1  ]: Compilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)
  'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:03:43.176463 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m01:03:43.176788 [error] [Thread-1  ]: 1 of 7 ERROR nao_negativos_tb_10_compradores_vendas_totais ..................... [[31mERROR[0m in 0.04s]
[0m01:03:43.176974 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:43.177881 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.nao_negativos_tb_10_compradores_vendas_totais.a6f9267c53
[0m01:03:43.178239 [debug] [Thread-1  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m01:03:43.178499 [info ] [Thread-1  ]: 5 of 7 START test test_singular_nao_negativo ................................... [RUN]
[0m01:03:43.178904 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m01:03:43.179077 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m01:03:43.180500 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:03:43.180966 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 01:03:43.179157 => 2023-04-28 01:03:43.180894
[0m01:03:43.181198 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m01:03:43.182802 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:03:43.183162 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:03:43.183287 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m01:03:43.183426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:03:43.183524 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:44.861219 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:03:44.861691 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:03:44.862091 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:03:44.862489 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:03:44.862785 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m01:03:44.863074 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:03:44.863805 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:03:44.864221 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:03:44.864823 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:03:44.865309 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:03:44.865694 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select vendas_totais
from "dev"."public"."tb_10_compradores"
where vendas_totais is null



      
    ) dbt_internal_test
[0m01:03:44.866113 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:03:45.067648 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:03:45.072438 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 01:03:43.160579 => 2023-04-28 01:03:45.072308
[0m01:03:45.072867 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m01:03:45.073341 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:03:45.073970 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:03:45.074471 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:03:45.077051 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 01:03:43.172570 => 2023-04-28 01:03:45.076902
[0m01:03:45.079701 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (execute): 2023-04-28 01:03:43.170968 => 2023-04-28 01:03:45.079596
[0m01:03:45.082125 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 01:03:43.181295 => 2023-04-28 01:03:45.082019
[0m01:03:45.082532 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m01:03:45.083006 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: ROLLBACK
[0m01:03:45.083518 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m01:03:45.272230 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m01:03:45.272896 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m01:03:45.274370 [info ] [Thread-1  ]: 5 of 7 PASS test_singular_nao_negativo ......................................... [[32mPASS[0m in 2.10s]
[0m01:03:45.275005 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m01:03:45.275397 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: Close
[0m01:03:45.277319 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m01:03:45.276745 [info ] [Thread-3  ]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.14s]
[0m01:03:45.279220 [error] [Thread-2  ]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.14s]
[0m01:03:45.280634 [info ] [Thread-4  ]: 4 of 7 PASS not_null_tb_10_compradores_vendas_totais ........................... [[32mPASS[0m in 2.14s]
[0m01:03:45.281524 [debug] [Thread-1  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:03:45.282451 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:03:45.283250 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:03:45.283924 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:03:45.284598 [info ] [Thread-1  ]: 6 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m01:03:45.285610 [debug] [Thread-3  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:03:45.287528 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m01:03:45.288072 [info ] [Thread-3  ]: 7 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m01:03:45.288601 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:03:45.289034 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m01:03:45.294465 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:03:45.294746 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:03:45.298550 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:03:45.298916 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 01:03:45.289173 => 2023-04-28 01:03:45.298846
[0m01:03:45.299123 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:03:45.300735 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:03:45.300931 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 01:03:45.294929 => 2023-04-28 01:03:45.300873
[0m01:03:45.301146 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:03:45.302475 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:03:45.302729 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:03:45.302905 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m01:03:45.303016 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:03:45.303139 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:45.303417 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:03:45.303554 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m01:03:45.303654 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m01:03:45.303750 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:47.100484 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:03:47.101038 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:03:47.101437 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:03:47.101824 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:03:47.102162 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:03:47.102509 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:03:47.318838 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:03:47.321764 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 01:03:45.301237 => 2023-04-28 01:03:47.321629
[0m01:03:47.322223 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m01:03:47.322722 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:03:47.325364 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 01:03:45.299228 => 2023-04-28 01:03:47.325245
[0m01:03:47.325758 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m01:03:47.523893 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m01:03:47.524470 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m01:03:47.526229 [info ] [Thread-1  ]: 6 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.24s]
[0m01:03:47.528467 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:03:47.527820 [info ] [Thread-3  ]: 7 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.24s]
[0m01:03:47.529558 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:03:47.532622 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:03:47.533177 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:47.533534 [debug] [MainThread]: On master: BEGIN
[0m01:03:47.533909 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:03:47.534377 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:03:49.366899 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:03:49.367695 [debug] [MainThread]: On master: COMMIT
[0m01:03:49.368217 [debug] [MainThread]: Using redshift connection "master"
[0m01:03:49.368628 [debug] [MainThread]: On master: COMMIT
[0m01:03:49.508556 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:03:49.509179 [debug] [MainThread]: On master: Close
[0m01:03:49.510459 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:03:49.510838 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m01:03:49.511122 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m01:03:49.511378 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m01:03:49.511626 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752' was properly closed.
[0m01:03:49.512109 [info ] [MainThread]: 
[0m01:03:49.512689 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 11.62 seconds (11.62s).
[0m01:03:49.513979 [debug] [MainThread]: Command end result
[0m01:03:49.522815 [info ] [MainThread]: 
[0m01:03:49.523185 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m01:03:49.523380 [info ] [MainThread]: 
[0m01:03:49.523534 [error] [MainThread]: [33mCompilation Error in test nao_negativos_tb_10_compradores_vendas_totais (models/example/schema.yml)[0m
[0m01:03:49.523679 [error] [MainThread]:   'test_nao_negativos' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m01:03:49.523809 [info ] [MainThread]: 
[0m01:03:49.523971 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m01:03:49.524107 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m01:03:49.524236 [info ] [MainThread]: 
[0m01:03:49.524374 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m01:03:49.524504 [info ] [MainThread]: 
[0m01:03:49.524628 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=2 SKIP=0 TOTAL=7
[0m01:03:49.524833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa61032daf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610cb8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa610cb8be0>]}
[0m01:03:49.525009 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 01:05:35.266173 | eb6079be-fdec-4453-82e2-a647dcdb1e73 ==============================
[0m01:05:35.266173 [info ] [MainThread]: Running with dbt=1.4.6
[0m01:05:35.267046 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m01:05:35.267175 [debug] [MainThread]: Tracking: tracking
[0m01:05:35.273832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7a8d5dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7a8d5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7a8e7100>]}
[0m01:05:35.286379 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m01:05:35.302772 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:05:35.303206 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://models/example/schema.yml
[0m01:05:35.316448 [debug] [MainThread]: 1699: static parser successfully parsed tables/tb_10_compradores.sql
[0m01:05:35.354564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb6079be-fdec-4453-82e2-a647dcdb1e73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e79777a90>]}
[0m01:05:35.359482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb6079be-fdec-4453-82e2-a647dcdb1e73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7974bbe0>]}
[0m01:05:35.359758 [info ] [MainThread]: Found 5 models, 7 tests, 0 snapshots, 0 analyses, 330 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m01:05:35.359935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb6079be-fdec-4453-82e2-a647dcdb1e73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7974bcd0>]}
[0m01:05:35.361125 [info ] [MainThread]: 
[0m01:05:35.362257 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:05:35.363604 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:05:35.372935 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:05:35.373150 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:05:35.373276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:05:35.373389 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:36.885391 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m01:05:36.886010 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:05:36.886449 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m01:05:37.090849 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m01:05:37.094186 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:05:37.294888 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:05:37.308608 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:37.308979 [debug] [MainThread]: On master: BEGIN
[0m01:05:37.309215 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:05:37.309430 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:39.138154 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:05:39.138766 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:39.139237 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:05:39.342989 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m01:05:39.345849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb6079be-fdec-4453-82e2-a647dcdb1e73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7a7f1700>]}
[0m01:05:39.346563 [debug] [MainThread]: On master: ROLLBACK
[0m01:05:39.547998 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:39.548538 [debug] [MainThread]: On master: BEGIN
[0m01:05:39.957264 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m01:05:39.957834 [debug] [MainThread]: On master: COMMIT
[0m01:05:39.958239 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:39.958595 [debug] [MainThread]: On master: COMMIT
[0m01:05:40.162052 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:05:40.162735 [debug] [MainThread]: On master: Close
[0m01:05:40.163641 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:05:40.163843 [info ] [MainThread]: 
[0m01:05:40.166302 [debug] [Thread-1  ]: Began running node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:05:40.166529 [debug] [Thread-2  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:05:40.166785 [debug] [Thread-3  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:05:40.167149 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:05:40.166963 [info ] [Thread-1  ]: 1 of 7 START test nao_negativo_tb_10_compradores_vendas_totais ................. [RUN]
[0m01:05:40.167373 [info ] [Thread-2  ]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m01:05:40.167601 [info ] [Thread-3  ]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m01:05:40.167827 [info ] [Thread-4  ]: 4 of 7 START test not_null_tb_10_compradores_vendas_totais ..................... [RUN]
[0m01:05:40.168276 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea'
[0m01:05:40.168645 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m01:05:40.169096 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m01:05:40.169443 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752'
[0m01:05:40.169624 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:05:40.169800 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:05:40.169953 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:05:40.170086 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:05:40.173268 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:05:40.180732 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:05:40.183619 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:05:40.187603 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:05:40.188221 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea (compile): 2023-04-28 01:05:40.170190 => 2023-04-28 01:05:40.188130
[0m01:05:40.188456 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:05:40.188604 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 01:05:40.180993 => 2023-04-28 01:05:40.188549
[0m01:05:40.193997 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 01:05:40.173487 => 2023-04-28 01:05:40.193897
[0m01:05:40.199601 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:05:40.199825 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:05:40.200008 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (compile): 2023-04-28 01:05:40.183804 => 2023-04-28 01:05:40.199952
[0m01:05:40.200162 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:05:40.201719 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:05:40.201956 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:05:40.203425 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:05:40.203618 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:05:40.205550 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:05:40.205858 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:05:40.206085 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: BEGIN
[0m01:05:40.206353 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m01:05:40.206512 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:05:40.206648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:05:40.206780 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:05:40.206894 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:05:40.207007 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m01:05:40.207137 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:40.207257 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: BEGIN
[0m01:05:40.207357 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:40.207471 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m01:05:40.207691 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:05:40.207909 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:40.208046 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:42.005254 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:05:42.005989 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:05:42.006368 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:05:42.006758 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:05:42.007113 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:05:42.007569 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:05:42.007958 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:05:42.008401 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:05:42.008794 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:05:42.009263 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

    select *
    from "dev"."public"."tb_10_compradores"
    where vendas_totais < 0


      
    ) dbt_internal_test
[0m01:05:42.009712 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:05:42.010045 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select vendas_totais
from "dev"."public"."tb_10_compradores"
where vendas_totais is null



      
    ) dbt_internal_test
[0m01:05:42.210406 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:05:42.215175 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 01:05:40.202075 => 2023-04-28 01:05:42.215029
[0m01:05:42.215684 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:05:42.216101 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m01:05:42.216468 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:05:42.219278 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (execute): 2023-04-28 01:05:40.203932 => 2023-04-28 01:05:42.219172
[0m01:05:42.219615 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:05:42.222379 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 01:05:40.200345 => 2023-04-28 01:05:42.222217
[0m01:05:42.222853 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: ROLLBACK
[0m01:05:42.225526 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea (execute): 2023-04-28 01:05:40.188745 => 2023-04-28 01:05:42.225385
[0m01:05:42.226018 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m01:05:42.226539 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: ROLLBACK
[0m01:05:42.414926 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: Close
[0m01:05:42.415524 [debug] [Thread-2  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m01:05:42.415887 [debug] [Thread-3  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m01:05:42.416274 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: Close
[0m01:05:42.417895 [info ] [Thread-1  ]: 1 of 7 PASS nao_negativo_tb_10_compradores_vendas_totais ....................... [[32mPASS[0m in 2.25s]
[0m01:05:42.423832 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:05:42.419082 [error] [Thread-2  ]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.25s]
[0m01:05:42.424305 [debug] [Thread-1  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m01:05:42.420227 [info ] [Thread-3  ]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.25s]
[0m01:05:42.424721 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:05:42.421758 [info ] [Thread-4  ]: 4 of 7 PASS not_null_tb_10_compradores_vendas_totais ........................... [[32mPASS[0m in 2.25s]
[0m01:05:42.425043 [info ] [Thread-1  ]: 5 of 7 START test test_singular_nao_negativo ................................... [RUN]
[0m01:05:42.425335 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:05:42.425588 [debug] [Thread-2  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:05:42.425852 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:05:42.426342 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m01:05:42.426741 [debug] [Thread-3  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:05:42.427124 [info ] [Thread-2  ]: 6 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m01:05:42.427449 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m01:05:42.427631 [info ] [Thread-3  ]: 7 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m01:05:42.428140 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m01:05:42.429494 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:05:42.429967 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m01:05:42.430169 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:05:42.430438 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:05:42.435465 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:05:42.438626 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:05:42.438942 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 01:05:42.428253 => 2023-04-28 01:05:42.438851
[0m01:05:42.439319 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m01:05:42.442032 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:05:42.442262 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 01:05:42.430589 => 2023-04-28 01:05:42.442206
[0m01:05:42.442553 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:05:42.442689 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 01:05:42.435687 => 2023-04-28 01:05:42.442653
[0m01:05:42.445089 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:05:42.445447 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:05:42.445657 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:05:42.447229 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:05:42.447392 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m01:05:42.447646 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:05:42.447751 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:05:42.447885 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m01:05:42.447998 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:42.448116 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:05:42.448221 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m01:05:42.448421 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m01:05:42.448518 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:42.448615 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m01:05:42.448817 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:44.258230 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:05:44.258834 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:05:44.259605 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:05:44.260087 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:05:44.260561 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:05:44.261013 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m01:05:44.261402 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:05:44.261766 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:05:44.262254 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:05:44.463107 [debug] [Thread-2  ]: SQL status: SELECT in 0 seconds
[0m01:05:44.466001 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 01:05:42.442776 => 2023-04-28 01:05:44.465857
[0m01:05:44.466511 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:05:44.466931 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:05:44.467477 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m01:05:44.470463 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 01:05:42.439468 => 2023-04-28 01:05:44.470269
[0m01:05:44.473284 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 01:05:42.445840 => 2023-04-28 01:05:44.473145
[0m01:05:44.474001 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m01:05:44.474513 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m01:05:44.667425 [debug] [Thread-1  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m01:05:44.667772 [debug] [Thread-3  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m01:05:44.667995 [debug] [Thread-2  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m01:05:44.668612 [info ] [Thread-1  ]: 5 of 7 PASS test_singular_nao_negativo ......................................... [[32mPASS[0m in 2.24s]
[0m01:05:44.669224 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m01:05:44.669925 [info ] [Thread-3  ]: 7 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.24s]
[0m01:05:44.671313 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:05:44.670543 [info ] [Thread-2  ]: 6 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.24s]
[0m01:05:44.671990 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:05:44.673324 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:05:44.673575 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:44.673731 [debug] [MainThread]: On master: BEGIN
[0m01:05:44.673871 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:05:44.674014 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:05:46.408707 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:05:46.409376 [debug] [MainThread]: On master: COMMIT
[0m01:05:46.409926 [debug] [MainThread]: Using redshift connection "master"
[0m01:05:46.410431 [debug] [MainThread]: On master: COMMIT
[0m01:05:46.613463 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:05:46.614075 [debug] [MainThread]: On master: Close
[0m01:05:46.615274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:05:46.615617 [debug] [MainThread]: Connection 'test.analytics_dbt.test_singular_nao_negativo' was properly closed.
[0m01:05:46.615840 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m01:05:46.616043 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m01:05:46.616240 [debug] [MainThread]: Connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752' was properly closed.
[0m01:05:46.616563 [info ] [MainThread]: 
[0m01:05:46.616983 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 11.26 seconds (11.26s).
[0m01:05:46.618127 [debug] [MainThread]: Command end result
[0m01:05:46.623594 [info ] [MainThread]: 
[0m01:05:46.623878 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:05:46.624059 [info ] [MainThread]: 
[0m01:05:46.624248 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m01:05:46.624441 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m01:05:46.624602 [info ] [MainThread]: 
[0m01:05:46.624764 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m01:05:46.624942 [info ] [MainThread]: 
[0m01:05:46.625103 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m01:05:46.625359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e7865d9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e796ff490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e796ff7f0>]}
[0m01:05:46.625552 [debug] [MainThread]: Flushing usage events


============================== 2023-04-28 01:08:48.831924 | 9261766a-d651-4685-afc6-7f215626ceff ==============================
[0m01:08:48.831924 [info ] [MainThread]: Running with dbt=1.4.6
[0m01:08:48.832767 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m01:08:48.832916 [debug] [MainThread]: Tracking: tracking
[0m01:08:48.840026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3acadca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3acadfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3acadf70>]}
[0m01:08:48.853094 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m01:08:48.869458 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:08:48.869884 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://models/example/schema.yml
[0m01:08:48.913531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9261766a-d651-4685-afc6-7f215626ceff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3ab63e80>]}
[0m01:08:48.918900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9261766a-d651-4685-afc6-7f215626ceff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3abb4f40>]}
[0m01:08:48.919226 [info ] [MainThread]: Found 5 models, 11 tests, 0 snapshots, 0 analyses, 330 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m01:08:48.919418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9261766a-d651-4685-afc6-7f215626ceff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3abb4fa0>]}
[0m01:08:48.920782 [info ] [MainThread]: 
[0m01:08:48.921928 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:08:48.922988 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m01:08:48.933107 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:08:48.933315 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m01:08:48.933446 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:08:48.933563 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:50.828985 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m01:08:50.829583 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m01:08:50.830028 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m01:08:51.033406 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m01:08:51.036841 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m01:08:51.238479 [debug] [ThreadPool]: On list_dev_public: Close
[0m01:08:51.251155 [debug] [MainThread]: Using redshift connection "master"
[0m01:08:51.251758 [debug] [MainThread]: On master: BEGIN
[0m01:08:51.252264 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:08:51.252587 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:52.978875 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:08:52.979357 [debug] [MainThread]: Using redshift connection "master"
[0m01:08:52.979748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:08:53.178281 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m01:08:53.181018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9261766a-d651-4685-afc6-7f215626ceff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3ac941f0>]}
[0m01:08:53.181653 [debug] [MainThread]: On master: ROLLBACK
[0m01:08:53.388646 [debug] [MainThread]: Using redshift connection "master"
[0m01:08:53.389246 [debug] [MainThread]: On master: BEGIN
[0m01:08:53.741719 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m01:08:53.742194 [debug] [MainThread]: On master: COMMIT
[0m01:08:53.742509 [debug] [MainThread]: Using redshift connection "master"
[0m01:08:53.742763 [debug] [MainThread]: On master: COMMIT
[0m01:08:53.893219 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:08:53.893735 [debug] [MainThread]: On master: Close
[0m01:08:53.894901 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:08:53.895452 [info ] [MainThread]: 
[0m01:08:53.902829 [debug] [Thread-1  ]: Began running node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:08:53.904065 [debug] [Thread-2  ]: Began running node test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db
[0m01:08:53.904771 [debug] [Thread-3  ]: Began running node test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10
[0m01:08:53.906043 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:08:53.905397 [info ] [Thread-1  ]: 1 of 11 START test nao_negativo_tb_10_compradores_vendas_totais ................ [RUN]
[0m01:08:53.906840 [info ] [Thread-2  ]: 2 of 11 START test nao_negativo_vw_sales_comissao .............................. [RUN]
[0m01:08:53.907608 [info ] [Thread-3  ]: 3 of 11 START test nao_negativo_vw_sales_valor_pago ............................ [RUN]
[0m01:08:53.908311 [info ] [Thread-4  ]: 4 of 11 START test not_null_my_first_dbt_model_id .............................. [RUN]
[0m01:08:53.909784 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea'
[0m01:08:53.910899 [debug] [Thread-2  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db'
[0m01:08:53.911710 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10'
[0m01:08:53.912225 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m01:08:53.912433 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:08:53.912598 [debug] [Thread-2  ]: Began compiling node test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db
[0m01:08:53.912738 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10
[0m01:08:53.912875 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:08:53.916208 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:08:53.919178 [debug] [Thread-2  ]: Writing injected SQL for node "test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db"
[0m01:08:53.921735 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10"
[0m01:08:53.928078 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:08:53.928648 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db (compile): 2023-04-28 01:08:53.916433 => 2023-04-28 01:08:53.928553
[0m01:08:53.928805 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea (compile): 2023-04-28 01:08:53.912988 => 2023-04-28 01:08:53.928772
[0m01:08:53.928962 [debug] [Thread-2  ]: Began executing node test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db
[0m01:08:53.929138 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10 (compile): 2023-04-28 01:08:53.919377 => 2023-04-28 01:08:53.929086
[0m01:08:53.929312 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:08:53.929463 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2023-04-28 01:08:53.921904 => 2023-04-28 01:08:53.929416
[0m01:08:53.939828 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10
[0m01:08:53.939626 [debug] [Thread-2  ]: Writing runtime sql for node "test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db"
[0m01:08:53.942033 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:08:53.942283 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:08:53.943743 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10"
[0m01:08:53.945421 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:08:53.945733 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db"
[0m01:08:53.945963 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:08:53.946113 [debug] [Thread-2  ]: On test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db: BEGIN
[0m01:08:53.946256 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: BEGIN
[0m01:08:53.946407 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10"
[0m01:08:53.946565 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m01:08:53.946690 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:08:53.946822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:08:53.946969 [debug] [Thread-3  ]: On test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10: BEGIN
[0m01:08:53.947077 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:53.947187 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m01:08:53.947300 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:53.947403 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m01:08:53.947596 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m01:08:53.947822 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:53.947950 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:55.538999 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m01:08:55.539449 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:08:55.539898 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m01:08:55.540355 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10"
[0m01:08:55.540802 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:08:55.541194 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"
[0m01:08:55.541582 [debug] [Thread-2  ]: Using redshift connection "test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db"
[0m01:08:55.541947 [debug] [Thread-3  ]: On test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

    select *
    from "dev"."public"."vw_sales"
    where valor_pago < 0


      
    ) dbt_internal_test
[0m01:08:55.542376 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m01:08:55.542785 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

    select *
    from "dev"."public"."tb_10_compradores"
    where vendas_totais < 0


      
    ) dbt_internal_test
[0m01:08:55.543216 [debug] [Thread-2  ]: On test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

    select *
    from "dev"."public"."vw_sales"
    where comissao < 0


      
    ) dbt_internal_test
[0m01:08:55.543835 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:08:55.744014 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:08:55.748978 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2023-04-28 01:08:53.944056 => 2023-04-28 01:08:55.748811
[0m01:08:55.749554 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m01:08:55.749992 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:08:55.753077 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea (execute): 2023-04-28 01:08:53.940022 => 2023-04-28 01:08:55.752953
[0m01:08:55.753460 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: ROLLBACK
[0m01:08:55.948554 [debug] [Thread-1  ]: On test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea: Close
[0m01:08:55.949217 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m01:08:55.951207 [info ] [Thread-1  ]: 1 of 11 PASS nao_negativo_tb_10_compradores_vendas_totais ...................... [[32mPASS[0m in 2.04s]
[0m01:08:55.955473 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.nao_negativo_tb_10_compradores_vendas_totais.9af17926ea
[0m01:08:55.952860 [error] [Thread-4  ]: 4 of 11 FAIL 1 not_null_my_first_dbt_model_id .................................. [[31mFAIL 1[0m in 2.04s]
[0m01:08:55.956500 [debug] [Thread-1  ]: Began running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:08:55.957264 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m01:08:55.957835 [info ] [Thread-1  ]: 5 of 11 START test not_null_my_second_dbt_model_id ............................. [RUN]
[0m01:08:55.958585 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:08:55.959234 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m01:08:55.959502 [info ] [Thread-4  ]: 6 of 11 START test not_null_tb_10_compradores_vendas_totais .................... [RUN]
[0m01:08:55.959743 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:08:55.960254 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752'
[0m01:08:55.963611 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:08:55.963846 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:08:55.966440 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:08:55.966688 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (compile): 2023-04-28 01:08:55.960429 => 2023-04-28 01:08:55.966633
[0m01:08:55.966861 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:08:55.968381 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:08:55.968718 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (compile): 2023-04-28 01:08:55.964001 => 2023-04-28 01:08:55.968646
[0m01:08:55.968954 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:08:55.970565 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:08:55.970780 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:08:55.970912 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m01:08:55.971003 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:08:55.971107 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:55.971318 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:08:55.971435 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: BEGIN
[0m01:08:55.971536 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m01:08:55.971711 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:57.791597 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:08:57.792133 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:08:57.792579 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m01:08:57.793815 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"
[0m01:08:57.794305 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "dev"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m01:08:57.794650 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select vendas_totais
from "dev"."public"."tb_10_compradores"
where vendas_totais is null



      
    ) dbt_internal_test
[0m01:08:57.996457 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:08:57.999138 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752 (execute): 2023-04-28 01:08:55.969062 => 2023-04-28 01:08:57.999014
[0m01:08:57.999541 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: ROLLBACK
[0m01:08:57.999990 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:08:58.002685 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778 (execute): 2023-04-28 01:08:55.966952 => 2023-04-28 01:08:58.002537
[0m01:08:58.003098 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m01:08:58.201625 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752: Close
[0m01:08:58.202168 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m01:08:58.204017 [info ] [Thread-4  ]: 6 of 11 PASS not_null_tb_10_compradores_vendas_totais .......................... [[32mPASS[0m in 2.24s]
[0m01:08:58.206470 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_tb_10_compradores_vendas_totais.ae3fdb0752
[0m01:08:58.205479 [info ] [Thread-1  ]: 5 of 11 PASS not_null_my_second_dbt_model_id ................................... [[32mPASS[0m in 2.25s]
[0m01:08:58.207374 [debug] [Thread-4  ]: Began running node test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab
[0m01:08:58.208094 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m01:08:58.208623 [info ] [Thread-4  ]: 7 of 11 START test not_null_vw_sales_comissao .................................. [RUN]
[0m01:08:58.209469 [debug] [Thread-1  ]: Began running node test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26
[0m01:08:58.210719 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab'
[0m01:08:58.211107 [info ] [Thread-1  ]: 8 of 11 START test not_null_vw_sales_valor_pago ................................ [RUN]
[0m01:08:58.211387 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab
[0m01:08:58.211869 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26'
[0m01:08:58.215403 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab"
[0m01:08:58.215715 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26
[0m01:08:58.218973 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26"
[0m01:08:58.219349 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab (compile): 2023-04-28 01:08:58.212020 => 2023-04-28 01:08:58.219259
[0m01:08:58.219614 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab
[0m01:08:58.219776 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26 (compile): 2023-04-28 01:08:58.215929 => 2023-04-28 01:08:58.219735
[0m01:08:58.222048 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab"
[0m01:08:58.222276 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26
[0m01:08:58.223687 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26"
[0m01:08:58.223907 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26"
[0m01:08:58.224008 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26: BEGIN
[0m01:08:58.224116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:08:58.224207 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:58.224334 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab"
[0m01:08:58.224546 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab: BEGIN
[0m01:08:58.224662 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m01:08:58.224785 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:08:59.942229 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m01:08:59.942763 [debug] [Thread-3  ]: SQL status: SELECT in 4 seconds
[0m01:08:59.943173 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m01:08:59.943574 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26"
[0m01:08:59.946261 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10 (execute): 2023-04-28 01:08:53.942448 => 2023-04-28 01:08:59.946144
[0m01:08:59.946733 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab"
[0m01:08:59.947156 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select valor_pago
from "dev"."public"."vw_sales"
where valor_pago is null



      
    ) dbt_internal_test
[0m01:08:59.947700 [debug] [Thread-3  ]: On test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10: ROLLBACK
[0m01:08:59.948251 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select comissao
from "dev"."public"."vw_sales"
where comissao is null



      
    ) dbt_internal_test
[0m01:09:00.146835 [debug] [Thread-3  ]: On test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10: Close
[0m01:09:00.148356 [info ] [Thread-3  ]: 3 of 11 PASS nao_negativo_vw_sales_valor_pago .................................. [[32mPASS[0m in 6.24s]
[0m01:09:00.149076 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.nao_negativo_vw_sales_valor_pago.7a9d055b10
[0m01:09:00.149662 [debug] [Thread-3  ]: Began running node test.analytics_dbt.test_singular_nao_negativo
[0m01:09:00.150255 [info ] [Thread-3  ]: 9 of 11 START test test_singular_nao_negativo .................................. [RUN]
[0m01:09:00.151538 [debug] [Thread-3  ]: Acquiring new redshift connection 'test.analytics_dbt.test_singular_nao_negativo'
[0m01:09:00.152182 [debug] [Thread-3  ]: Began compiling node test.analytics_dbt.test_singular_nao_negativo
[0m01:09:00.157074 [debug] [Thread-3  ]: Writing injected SQL for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:09:00.157767 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (compile): 2023-04-28 01:09:00.152566 => 2023-04-28 01:09:00.157644
[0m01:09:00.158153 [debug] [Thread-3  ]: Began executing node test.analytics_dbt.test_singular_nao_negativo
[0m01:09:00.160981 [debug] [Thread-3  ]: Writing runtime sql for node "test.analytics_dbt.test_singular_nao_negativo"
[0m01:09:00.161502 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:09:00.161710 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: BEGIN
[0m01:09:00.161861 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m01:09:00.162000 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:09:00.363881 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:09:00.367023 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26 (execute): 2023-04-28 01:08:58.222511 => 2023-04-28 01:09:00.366882
[0m01:09:00.367496 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26: ROLLBACK
[0m01:09:00.367964 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:09:00.370751 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab (execute): 2023-04-28 01:08:58.219859 => 2023-04-28 01:09:00.370585
[0m01:09:00.371251 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab: ROLLBACK
[0m01:09:00.507244 [debug] [Thread-1  ]: On test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26: Close
[0m01:09:00.508777 [info ] [Thread-1  ]: 8 of 11 PASS not_null_vw_sales_valor_pago ...................................... [[32mPASS[0m in 2.30s]
[0m01:09:00.509523 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.not_null_vw_sales_valor_pago.5cd141ad26
[0m01:09:00.510217 [debug] [Thread-1  ]: Began running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:09:00.510906 [info ] [Thread-1  ]: 10 of 11 START test unique_my_first_dbt_model_id ............................... [RUN]
[0m01:09:00.511597 [debug] [Thread-1  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m01:09:00.511751 [debug] [Thread-4  ]: On test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab: Close
[0m01:09:00.511921 [debug] [Thread-1  ]: Began compiling node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:09:00.516802 [debug] [Thread-1  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:09:00.517328 [info ] [Thread-4  ]: 7 of 11 PASS not_null_vw_sales_comissao ........................................ [[32mPASS[0m in 2.31s]
[0m01:09:00.517712 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.not_null_vw_sales_comissao.d9b6c254ab
[0m01:09:00.517934 [debug] [Thread-4  ]: Began running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:09:00.518163 [info ] [Thread-4  ]: 11 of 11 START test unique_my_second_dbt_model_id .............................. [RUN]
[0m01:09:00.518553 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (compile): 2023-04-28 01:09:00.512057 => 2023-04-28 01:09:00.518470
[0m01:09:00.518969 [debug] [Thread-4  ]: Acquiring new redshift connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m01:09:00.519209 [debug] [Thread-1  ]: Began executing node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:09:00.519417 [debug] [Thread-4  ]: Began compiling node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:09:00.521850 [debug] [Thread-1  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:09:00.524664 [debug] [Thread-4  ]: Writing injected SQL for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:09:00.525063 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (compile): 2023-04-28 01:09:00.522026 => 2023-04-28 01:09:00.525002
[0m01:09:00.525261 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:09:00.525448 [debug] [Thread-4  ]: Began executing node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:09:00.525611 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m01:09:00.527399 [debug] [Thread-4  ]: Writing runtime sql for node "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:09:00.527660 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:09:00.527883 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:09:00.528194 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:09:00.528352 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m01:09:00.528508 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m01:09:00.528645 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:09:00.955326 [debug] [Thread-2  ]: SQL status: SELECT in 5 seconds
[0m01:09:00.958160 [debug] [Thread-2  ]: Timing info for test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db (execute): 2023-04-28 01:08:53.929548 => 2023-04-28 01:09:00.958015
[0m01:09:00.958659 [debug] [Thread-2  ]: On test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db: ROLLBACK
[0m01:09:01.112272 [debug] [Thread-2  ]: On test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db: Close
[0m01:09:01.113908 [info ] [Thread-2  ]: 2 of 11 PASS nao_negativo_vw_sales_comissao .................................... [[32mPASS[0m in 7.20s]
[0m01:09:01.114615 [debug] [Thread-2  ]: Finished running node test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db
[0m01:09:01.632988 [debug] [Thread-3  ]: SQL status: BEGIN in 1 seconds
[0m01:09:01.633479 [debug] [Thread-3  ]: Using redshift connection "test.analytics_dbt.test_singular_nao_negativo"
[0m01:09:01.633795 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.test_singular_nao_negativo"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- testar se existe calores menores que 0 (negativos)

select *
    from tb_10_compradores
    where vendas_totais < 0
      
    ) dbt_internal_test
[0m01:09:01.786853 [debug] [Thread-3  ]: SQL status: SELECT in 0 seconds
[0m01:09:01.788977 [debug] [Thread-3  ]: Timing info for test.analytics_dbt.test_singular_nao_negativo (execute): 2023-04-28 01:09:00.158351 => 2023-04-28 01:09:01.788869
[0m01:09:01.789335 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: ROLLBACK
[0m01:09:01.832018 [debug] [Thread-1  ]: SQL status: BEGIN in 1 seconds
[0m01:09:01.832251 [debug] [Thread-1  ]: Using redshift connection "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m01:09:01.832360 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:09:01.989747 [debug] [Thread-4  ]: SQL status: BEGIN in 1 seconds
[0m01:09:01.990284 [debug] [Thread-3  ]: On test.analytics_dbt.test_singular_nao_negativo: Close
[0m01:09:01.990742 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m01:09:01.991077 [debug] [Thread-4  ]: Using redshift connection "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m01:09:01.993879 [debug] [Thread-1  ]: Timing info for test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321 (execute): 2023-04-28 01:09:00.519527 => 2023-04-28 01:09:01.993755
[0m01:09:01.995036 [info ] [Thread-3  ]: 9 of 11 PASS test_singular_nao_negativo ........................................ [[32mPASS[0m in 1.84s]
[0m01:09:01.995452 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "dev"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:09:01.995876 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m01:09:01.996304 [debug] [Thread-3  ]: Finished running node test.analytics_dbt.test_singular_nao_negativo
[0m01:09:02.194799 [debug] [Thread-1  ]: On test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m01:09:02.195330 [debug] [Thread-4  ]: SQL status: SELECT in 0 seconds
[0m01:09:02.199346 [debug] [Thread-4  ]: Timing info for test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493 (execute): 2023-04-28 01:09:00.525731 => 2023-04-28 01:09:02.199152
[0m01:09:02.201430 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m01:09:02.200903 [info ] [Thread-1  ]: 10 of 11 PASS unique_my_first_dbt_model_id ..................................... [[32mPASS[0m in 1.69s]
[0m01:09:02.202510 [debug] [Thread-1  ]: Finished running node test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321
[0m01:09:02.399527 [debug] [Thread-4  ]: On test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m01:09:02.401231 [info ] [Thread-4  ]: 11 of 11 PASS unique_my_second_dbt_model_id .................................... [[32mPASS[0m in 1.88s]
[0m01:09:02.401992 [debug] [Thread-4  ]: Finished running node test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m01:09:02.404889 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m01:09:02.405679 [debug] [MainThread]: Using redshift connection "master"
[0m01:09:02.406215 [debug] [MainThread]: On master: BEGIN
[0m01:09:02.406718 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:09:02.407181 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m01:09:04.246017 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m01:09:04.246556 [debug] [MainThread]: On master: COMMIT
[0m01:09:04.246867 [debug] [MainThread]: Using redshift connection "master"
[0m01:09:04.247131 [debug] [MainThread]: On master: COMMIT
[0m01:09:04.382823 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m01:09:04.383321 [debug] [MainThread]: On master: Close
[0m01:09:04.384396 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:09:04.384726 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m01:09:04.384951 [debug] [MainThread]: Connection 'test.analytics_dbt.nao_negativo_vw_sales_comissao.c9561fd7db' was properly closed.
[0m01:09:04.385197 [debug] [MainThread]: Connection 'test.analytics_dbt.test_singular_nao_negativo' was properly closed.
[0m01:09:04.385403 [debug] [MainThread]: Connection 'test.analytics_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m01:09:04.385810 [info ] [MainThread]: 
[0m01:09:04.386231 [info ] [MainThread]: Finished running 11 tests in 0 hours 0 minutes and 15.46 seconds (15.46s).
[0m01:09:04.387672 [debug] [MainThread]: Command end result
[0m01:09:04.395008 [info ] [MainThread]: 
[0m01:09:04.395269 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:09:04.395424 [info ] [MainThread]: 
[0m01:09:04.395610 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m01:09:04.395800 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m01:09:04.395963 [info ] [MainThread]: 
[0m01:09:04.396142 [info ] [MainThread]:   compiled Code at target/compiled/analytics_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m01:09:04.396289 [info ] [MainThread]: 
[0m01:09:04.396430 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
[0m01:09:04.396672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e38231af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3abb4ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e3abb4f70>]}
[0m01:09:04.396863 [debug] [MainThread]: Flushing usage events

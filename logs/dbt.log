

============================== 2023-04-27 14:20:22.755312 | 021c42db-53c6-4023-845e-12f7a658ee1f ==============================
[0m14:20:22.755312 [info ] [MainThread]: Running with dbt=1.4.6
[0m14:20:22.756064 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m14:20:22.756178 [debug] [MainThread]: Tracking: tracking
[0m14:20:22.762026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456c8760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456c87c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb456bf3a0>]}
[0m14:20:22.855466 [debug] [MainThread]: Executing "git --help"
[0m14:20:22.859670 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:20:22.859976 [debug] [MainThread]: STDERR: "b''"
[0m14:20:22.861211 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m14:20:22.861404 [debug] [MainThread]: Using redshift connection "debug"
[0m14:20:22.861514 [debug] [MainThread]: On debug: select 1 as id
[0m14:20:22.861622 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:20:22.861734 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m14:20:24.756287 [debug] [MainThread]: SQL status: SELECT in 2 seconds
[0m14:20:24.758563 [debug] [MainThread]: On debug: Close
[0m14:20:24.759481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396b280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396b370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4396bc70>]}
[0m14:20:24.760241 [debug] [MainThread]: Flushing usage events
[0m14:20:25.578677 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 15:39:15.176339 | 4979f67a-62bf-4e85-9dfb-a1eee0a87608 ==============================
[0m15:39:15.176339 [info ] [MainThread]: Running with dbt=1.4.6
[0m15:39:15.177238 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m15:39:15.177336 [debug] [MainThread]: Tracking: tracking
[0m15:39:15.184923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cfdaac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76cd0>]}
[0m15:39:15.205666 [debug] [MainThread]: Executing "git --help"
[0m15:39:15.208918 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:39:15.209238 [debug] [MainThread]: STDERR: "b''"
[0m15:39:15.209515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cfdaac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cf76a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51cecd280>]}
[0m15:39:15.209799 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 15:54:31.661747 | 51c7cc85-e2c4-41be-a76f-474783680ae0 ==============================
[0m15:54:31.661747 [info ] [MainThread]: Running with dbt=1.4.6
[0m15:54:31.662680 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m15:54:31.662810 [debug] [MainThread]: Tracking: tracking
[0m15:54:31.670387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6bd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f6bb50>]}
[0m15:54:31.692679 [debug] [MainThread]: Executing "git --help"
[0m15:54:31.698222 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:54:31.698536 [debug] [MainThread]: STDERR: "b''"
[0m15:54:31.698821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d5007400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f9a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6d4f9a4f0>]}
[0m15:54:31.699089 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:20:17.897885 | d4f5cbc9-e604-41be-97ac-67082a04eb1b ==============================
[0m17:20:17.897885 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:20:17.898650 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:20:17.898780 [debug] [MainThread]: Tracking: tracking
[0m17:20:17.905095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e43b50>]}
[0m17:20:17.927073 [debug] [MainThread]: Executing "git --help"
[0m17:20:17.932155 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:20:17.932464 [debug] [MainThread]: STDERR: "b''"
[0m17:20:17.932736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5ee0400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e4deb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac5e4d1f0>]}
[0m17:20:17.932995 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:23:23.707320 | 1f7e2706-d759-4d1b-a6d6-843e8988a2db ==============================
[0m17:23:23.707320 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:23:23.708041 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:23:23.708138 [debug] [MainThread]: Tracking: tracking
[0m17:23:23.714357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef923bb0>]}
[0m17:23:23.717054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fb820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fb4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2fef8fbee0>]}
[0m17:23:23.717396 [debug] [MainThread]: Flushing usage events
[0m17:23:24.568963 [error] [MainThread]: Encountered an error:
Runtime Error
  
  dbt encountered an error while trying to read your profiles.yml file.
  
  Runtime Error
    Syntax error near line 2
    ------------------------------
    1  | analytics_dbt:
    2  | 	company-name:
    3  | 	  target: dev
    4  | 	  outputs:
    5  | 	    dev:
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 2, column 1
  


============================== 2023-04-27 17:26:39.941346 | 3804fab7-1f6b-42c7-920e-3d8d99bd4c2b ==============================
[0m17:26:39.941346 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:26:39.942125 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:26:39.942260 [debug] [MainThread]: Tracking: tracking
[0m17:26:39.948626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183ed30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183e730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab5183e880>]}
[0m17:26:40.042440 [debug] [MainThread]: Executing "git --help"
[0m17:26:40.047104 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:26:40.047482 [debug] [MainThread]: STDERR: "b''"
[0m17:26:40.049090 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:26:40.049374 [debug] [MainThread]: Using redshift connection "debug"
[0m17:26:40.049527 [debug] [MainThread]: On debug: select 1 as id
[0m17:26:40.049724 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:26:40.049877 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:26:50.390719 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:27:00.402903 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:27:00.403386 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:27:00.403826 [debug] [MainThread]: On debug: No close available on handle
[0m17:27:00.404785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf32e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf3d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab4faf38e0>]}
[0m17:27:00.405760 [debug] [MainThread]: Flushing usage events
[0m17:27:01.260457 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:28:37.372815 | 421e8c34-8a73-4881-a311-7f5ff44828a4 ==============================
[0m17:28:37.372815 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:28:37.373548 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:28:37.373651 [debug] [MainThread]: Tracking: tracking
[0m17:28:37.380193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5cbd16880>]}
[0m17:28:37.475958 [debug] [MainThread]: Executing "git --help"
[0m17:28:37.480410 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:28:37.480723 [debug] [MainThread]: STDERR: "b''"
[0m17:28:37.481989 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:28:37.482204 [debug] [MainThread]: Using redshift connection "debug"
[0m17:28:37.482340 [debug] [MainThread]: On debug: select 1 as id
[0m17:28:37.482511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:28:37.482647 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:28:47.506205 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:28:57.523279 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:28:57.523765 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:28:57.524247 [debug] [MainThread]: On debug: No close available on handle
[0m17:28:57.524999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fdea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fded00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5c9fde580>]}
[0m17:28:57.525714 [debug] [MainThread]: Flushing usage events
[0m17:28:58.411557 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:30:43.295927 | 32106c69-73b5-4df2-9551-40fe0e01611e ==============================
[0m17:30:43.295927 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:30:43.296662 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:30:43.296755 [debug] [MainThread]: Tracking: tracking
[0m17:30:43.303010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0849fb50>]}
[0m17:30:43.396799 [debug] [MainThread]: Executing "git --help"
[0m17:30:43.400948 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:30:43.401266 [debug] [MainThread]: STDERR: "b''"
[0m17:30:43.402595 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:30:43.402848 [debug] [MainThread]: Using redshift connection "debug"
[0m17:30:43.402983 [debug] [MainThread]: On debug: select 1 as id
[0m17:30:43.403105 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:30:43.403237 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:30:53.423575 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a redshift connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "redshift-edz-cluster1.c6r9wcxmb6og.us-east-2.redshift.amazonaws.com" (3.12.37.154), port 5432 failed: timeout expired

[0m17:31:03.440926 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:31:03.441468 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:31:03.441989 [debug] [MainThread]: On debug: No close available on handle
[0m17:31:03.442859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676da30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0676d8e0>]}
[0m17:31:03.443705 [debug] [MainThread]: Flushing usage events
[0m17:31:04.114914 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:32:29.586977 | d030800b-829a-43fd-b290-6be646cb1b91 ==============================
[0m17:32:29.586977 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:32:29.587701 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:32:29.587793 [debug] [MainThread]: Tracking: tracking
[0m17:32:29.594117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d84460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d7b7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03d7b8e0>]}
[0m17:32:29.686770 [debug] [MainThread]: Executing "git --help"
[0m17:32:29.690697 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:32:29.691013 [debug] [MainThread]: STDERR: "b''"
[0m17:32:29.692353 [debug] [MainThread]: Acquiring new redshift connection 'debug'
[0m17:32:29.692597 [debug] [MainThread]: Using redshift connection "debug"
[0m17:32:29.692726 [debug] [MainThread]: On debug: select 1 as id
[0m17:32:29.692852 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:32:29.692976 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:32:31.510657 [debug] [MainThread]: SQL status: SELECT in 2 seconds
[0m17:32:31.513089 [debug] [MainThread]: On debug: Close
[0m17:32:31.513977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0201c5e0>]}
[0m17:32:31.514259 [debug] [MainThread]: Flushing usage events
[0m17:32:32.334485 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2023-04-27 17:33:26.838571 | 6d2ceb85-77f5-4616-8594-fb7d6522eea7 ==============================
[0m17:33:26.838571 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:33:26.839408 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:33:26.839534 [debug] [MainThread]: Tracking: tracking
[0m17:33:26.846388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf19d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf19df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf31040>]}
[0m17:33:26.861569 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:33:26.861911 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:33:26.862092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8cf93ee0>]}
[0m17:33:27.292064 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m17:33:27.300820 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m17:33:27.352840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c0470d0>]}
[0m17:33:27.357240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8ce58df0>]}
[0m17:33:27.357502 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:33:27.357660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7fdfc9a0>]}
[0m17:33:27.358597 [info ] [MainThread]: 
[0m17:33:27.359581 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:33:27.360424 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:33:27.370954 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:33:27.371287 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:33:27.371422 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:33:27.371557 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:28.959247 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:33:28.962022 [debug] [ThreadPool]: On list_dev: Close
[0m17:33:28.965181 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:33:28.978998 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:33:28.979403 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:33:28.979675 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:33:28.979927 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:30.802252 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:33:30.803135 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:33:30.803723 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:33:31.006859 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:33:31.009759 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:33:31.211278 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:33:31.224088 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:31.224553 [debug] [MainThread]: On master: BEGIN
[0m17:33:31.224863 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:33:31.225142 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:32.952799 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:33:32.953326 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:32.954703 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:33:33.157296 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:33:33.159462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7fd6e880>]}
[0m17:33:33.160114 [debug] [MainThread]: On master: ROLLBACK
[0m17:33:33.363708 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:33.364217 [debug] [MainThread]: On master: BEGIN
[0m17:33:33.702389 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:33:33.703047 [debug] [MainThread]: On master: COMMIT
[0m17:33:33.703530 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:33.703844 [debug] [MainThread]: On master: COMMIT
[0m17:33:33.874560 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:33:33.875248 [debug] [MainThread]: On master: Close
[0m17:33:33.876576 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:33:33.877125 [info ] [MainThread]: 
[0m17:33:33.887493 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.888119 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:33:33.889132 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:33:33.889491 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.892792 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.893354 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:33:33.889693 => 2023-04-27 17:33:33.893269
[0m17:33:33.893574 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:33:33.927746 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.928177 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:33.928320 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:33.928412 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:33:33.928500 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:35.513029 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:33:35.513522 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:35.513888 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:33:36.024366 [debug] [Thread-1  ]: SQL status: SELECT in 1 seconds
[0m17:33:36.034919 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.035224 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:33:36.229049 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:33:36.253425 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.253621 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.253717 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.536451 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:33:36.537273 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.537620 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:36.741234 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:33:36.752007 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.752447 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:33:36.946579 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:33:36.948455 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:36.948871 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:36.949165 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:33:37.150624 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:33:37.151145 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:33:37.151434 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:33:37.355399 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:33:37.356817 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:33:33.893671 => 2023-04-27 17:33:37.356711
[0m17:33:37.357187 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:33:37.560403 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:33:37.561972 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7f510520>]}
[0m17:33:37.562819 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.67s]
[0m17:33:37.565265 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:33:37.566807 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.567637 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:33:37.569044 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:33:37.569528 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.574700 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.575363 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:33:37.569769 => 2023-04-27 17:33:37.575256
[0m17:33:37.575775 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:33:37.632030 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.632489 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:37.632636 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:37.632753 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:33:37.632860 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:39.265797 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:33:39.266335 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.266771 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:33:39.408454 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:33:39.414037 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.414436 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:33:39.555672 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:33:39.558918 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:39.559328 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.559662 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:39.719930 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:33:39.720809 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.721180 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:39.915584 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:33:39.921536 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:39.921965 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:33:40.060778 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:33:40.062541 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:40.062889 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:40.063156 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:33:40.218416 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:33:40.219085 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:33:40.219437 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:33:40.427538 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:33:40.428749 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:33:37.576010 => 2023-04-27 17:33:40.428655
[0m17:33:40.429082 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:33:40.632657 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:33:40.634210 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2ceb85-77f5-4616-8594-fb7d6522eea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7c45d820>]}
[0m17:33:40.635064 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.07s]
[0m17:33:40.635751 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:33:40.638451 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:33:40.639011 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:40.639348 [debug] [MainThread]: On master: BEGIN
[0m17:33:40.639645 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:33:40.639942 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:33:42.475914 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:33:42.476445 [debug] [MainThread]: On master: COMMIT
[0m17:33:42.476769 [debug] [MainThread]: Using redshift connection "master"
[0m17:33:42.477048 [debug] [MainThread]: On master: COMMIT
[0m17:33:42.680528 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:33:42.681073 [debug] [MainThread]: On master: Close
[0m17:33:42.682234 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:33:42.682592 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m17:33:42.682817 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m17:33:42.683136 [info ] [MainThread]: 
[0m17:33:42.683596 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 15.32 seconds (15.32s).
[0m17:33:42.684274 [debug] [MainThread]: Command end result
[0m17:33:42.695490 [info ] [MainThread]: 
[0m17:33:42.696008 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:33:42.696322 [info ] [MainThread]: 
[0m17:33:42.696592 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:33:42.697037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac7c455c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c038a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fac8c047190>]}
[0m17:33:42.697439 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:57:37.853061 | c2e3be63-a391-430d-b566-d85f613d9fc3 ==============================
[0m17:57:37.853061 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:57:37.854163 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['views/vw_sales.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:57:37.854437 [debug] [MainThread]: Tracking: tracking
[0m17:57:37.861077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae25160>]}
[0m17:57:37.874595 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:57:37.890853 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m17:57:37.891168 [debug] [MainThread]: Partial parsing: added file: analytics_dbt://models/views/vw_sales.sql
[0m17:57:37.904785 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m17:57:37.919555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad0cc10>]}
[0m17:57:37.924392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad79970>]}
[0m17:57:37.924669 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:57:37.924845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2e3be63-a391-430d-b566-d85f613d9fc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad79bb0>]}
[0m17:57:37.925536 [warn ] [MainThread]: The selection criterion 'views/vw_sales.sql' does not match any nodes
[0m17:57:37.926159 [info ] [MainThread]: 
[0m17:57:37.926433 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m17:57:37.926626 [debug] [MainThread]: Command end result
[0m17:57:37.930943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbae0df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad70f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbbad70fa0>]}
[0m17:57:37.931321 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:58:20.358922 | 5a28ecbc-3d07-4248-b10d-a5178776f20d ==============================
[0m17:58:20.358922 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:58:20.359744 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:58:20.359870 [debug] [MainThread]: Tracking: tracking
[0m17:58:20.366786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a066f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a0872e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a087190>]}
[0m17:58:20.381670 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:58:20.397704 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:58:20.397930 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:58:20.402782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0679f77b20>]}
[0m17:58:20.408175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c5b0>]}
[0m17:58:20.408500 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:58:20.408687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c6d0>]}
[0m17:58:20.409756 [info ] [MainThread]: 
[0m17:58:20.410797 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:58:20.411573 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:58:20.420174 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:58:20.420380 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:58:20.420541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:20.420683 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:22.381089 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:58:22.383815 [debug] [ThreadPool]: On list_dev: Close
[0m17:58:22.387225 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:58:22.401406 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:58:22.401759 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:58:22.402028 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:58:22.402263 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:24.007412 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:58:24.007998 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:58:24.008394 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:58:24.224081 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:58:24.226938 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:58:24.428927 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:58:24.441639 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:24.442077 [debug] [MainThread]: On master: BEGIN
[0m17:58:24.442406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:58:24.442677 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:26.067202 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:58:26.067780 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.068135 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:58:26.272739 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:58:26.275343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0679f77e20>]}
[0m17:58:26.275985 [debug] [MainThread]: On master: ROLLBACK
[0m17:58:26.476900 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.477610 [debug] [MainThread]: On master: BEGIN
[0m17:58:26.887187 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:58:26.888104 [debug] [MainThread]: On master: COMMIT
[0m17:58:26.888697 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:26.889096 [debug] [MainThread]: On master: COMMIT
[0m17:58:27.091297 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:58:27.091892 [debug] [MainThread]: On master: Close
[0m17:58:27.093103 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:58:27.093578 [info ] [MainThread]: 
[0m17:58:27.099465 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.099773 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:58:27.100273 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:58:27.100465 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.103310 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.104085 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:58:27.100554 => 2023-04-27 17:58:27.103969
[0m17:58:27.104450 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:58:27.139142 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.139744 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:27.139968 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:27.140072 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:58:27.140165 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:28.934545 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:58:28.935026 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:28.935308 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:58:29.241784 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m17:58:29.254616 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.254965 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:58:29.446604 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:29.451928 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.452237 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:58:29.651610 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:29.680539 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:29.680726 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.680815 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:29.857157 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:58:29.858039 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:29.858452 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:30.061894 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:58:30.073255 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.073676 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:58:30.227975 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:58:30.229642 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:30.230019 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.230286 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:58:30.470535 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:58:30.471120 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:58:30.471449 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:58:30.678454 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:58:30.679916 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:58:27.104604 => 2023-04-27 17:58:30.679804
[0m17:58:30.680312 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:58:30.883181 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:58:30.884902 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06796f9820>]}
[0m17:58:30.885940 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.78s]
[0m17:58:30.889089 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:58:30.891002 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.891801 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:58:30.893129 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:58:30.893585 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.898745 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.899447 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:58:30.893827 => 2023-04-27 17:58:30.899328
[0m17:58:30.899817 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:58:30.916798 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.917173 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:30.917313 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:30.917412 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:58:30.917507 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:32.723987 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:58:32.724534 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:32.724848 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:58:32.928028 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:58:32.933532 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:32.933920 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:58:33.133289 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:58:33.135312 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.135558 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.135752 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.337777 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:58:33.338902 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.339462 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:33.542641 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:58:33.547044 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.547431 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:58:33.747550 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:58:33.749156 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.749492 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.749729 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:58:33.956068 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:58:33.956774 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:58:33.957214 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:58:34.156775 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:58:34.158087 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:58:30.899980 => 2023-04-27 17:58:34.157981
[0m17:58:34.158476 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:58:34.361621 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:58:34.363216 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a28ecbc-3d07-4248-b10d-a5178776f20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06796f9670>]}
[0m17:58:34.364022 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.47s]
[0m17:58:34.364633 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:58:34.367313 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:58:34.367941 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:34.368345 [debug] [MainThread]: On master: BEGIN
[0m17:58:34.368707 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:58:34.369071 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:58:36.205151 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:58:36.205774 [debug] [MainThread]: On master: COMMIT
[0m17:58:36.206173 [debug] [MainThread]: Using redshift connection "master"
[0m17:58:36.206550 [debug] [MainThread]: On master: COMMIT
[0m17:58:36.410523 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:58:36.411184 [debug] [MainThread]: On master: Close
[0m17:58:36.412430 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:36.412844 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m17:58:36.413236 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m17:58:36.413743 [info ] [MainThread]: 
[0m17:58:36.414407 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.00 seconds (16.00s).
[0m17:58:36.415463 [debug] [MainThread]: Command end result
[0m17:58:36.427697 [info ] [MainThread]: 
[0m17:58:36.428141 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:58:36.428440 [info ] [MainThread]: 
[0m17:58:36.428788 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:58:36.429271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a0e7b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06797396a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f067a05c460>]}
[0m17:58:36.429722 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 17:59:45.433573 | 3689fd6f-e47b-46d9-8e41-8d8765e929c9 ==============================
[0m17:59:45.433573 [info ] [MainThread]: Running with dbt=1.4.6
[0m17:59:45.434362 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:59:45.434475 [debug] [MainThread]: Tracking: tracking
[0m17:59:45.441144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531a7d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531a7dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531bf070>]}
[0m17:59:45.453847 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m17:59:45.469352 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:59:45.469569 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:59:45.473614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f530b0a00>]}
[0m17:59:45.478787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f53191490>]}
[0m17:59:45.479113 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:59:45.479276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531915b0>]}
[0m17:59:45.480217 [info ] [MainThread]: 
[0m17:59:45.481195 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:59:45.482008 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m17:59:45.490506 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m17:59:45.490705 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m17:59:45.490830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:45.490941 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:47.373882 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m17:59:47.376936 [debug] [ThreadPool]: On list_dev: Close
[0m17:59:47.379045 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m17:59:47.386742 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:59:47.386884 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m17:59:47.386983 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:59:47.387144 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:49.217377 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m17:59:49.217909 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m17:59:49.218287 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m17:59:49.421504 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m17:59:49.424406 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m17:59:49.626512 [debug] [ThreadPool]: On list_dev_public: Close
[0m17:59:49.639354 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:49.639826 [debug] [MainThread]: On master: BEGIN
[0m17:59:49.640153 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:59:49.640447 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:51.469772 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m17:59:51.470352 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:51.470822 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:59:51.674538 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m17:59:51.678669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5310fdf0>]}
[0m17:59:51.679338 [debug] [MainThread]: On master: ROLLBACK
[0m17:59:51.879407 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:51.879960 [debug] [MainThread]: On master: BEGIN
[0m17:59:52.288881 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m17:59:52.289412 [debug] [MainThread]: On master: COMMIT
[0m17:59:52.289739 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:52.290021 [debug] [MainThread]: On master: COMMIT
[0m17:59:52.493835 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m17:59:52.494462 [debug] [MainThread]: On master: Close
[0m17:59:52.495742 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:59:52.496273 [info ] [MainThread]: 
[0m17:59:52.503603 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.504479 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m17:59:52.505065 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m17:59:52.505221 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.507240 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.507662 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 17:59:52.505303 => 2023-04-27 17:59:52.507581
[0m17:59:52.507860 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m17:59:52.540260 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.540622 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:52.540766 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:52.540881 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:59:52.540986 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:54.336758 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m17:59:54.337258 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.337576 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:59:54.548703 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m17:59:54.562525 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.562963 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:59:54.746959 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:54.753059 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.753526 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:59:54.951522 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:54.969152 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:54.969318 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:54.969427 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.258581 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:59:55.259468 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.259852 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:55.463543 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:59:55.470539 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.470669 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m17:59:55.668435 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m17:59:55.670520 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.670992 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.671389 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m17:59:55.874117 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m17:59:55.874739 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m17:59:55.875113 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m17:59:56.077454 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m17:59:56.079112 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 17:59:52.507955 => 2023-04-27 17:59:56.078988
[0m17:59:56.079579 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m17:59:56.283543 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m17:59:56.285250 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f52832700>]}
[0m17:59:56.286143 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.78s]
[0m17:59:56.288188 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m17:59:56.288848 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.289064 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m17:59:56.289470 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m17:59:56.289617 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.292688 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.293631 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 17:59:56.289696 => 2023-04-27 17:59:56.293424
[0m17:59:56.294164 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m17:59:56.310260 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.310662 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:56.310817 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:56.310987 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:59:56.311112 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m17:59:58.125537 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m17:59:58.126070 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.126497 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m17:59:58.330428 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m17:59:58.335774 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.335882 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:59:58.535527 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m17:59:58.539006 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:58.539385 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.539678 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:58.740646 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:59:58.741500 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.741848 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:58.945430 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:59:58.949906 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:58.950325 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m17:59:59.102693 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m17:59:59.104661 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:59.105064 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:59.105375 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m17:59:59.457232 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m17:59:59.457804 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m17:59:59.458135 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m17:59:59.661885 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m17:59:59.663356 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 17:59:56.294392 => 2023-04-27 17:59:59.663246
[0m17:59:59.663733 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m17:59:59.866416 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m17:59:59.867942 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3689fd6f-e47b-46d9-8e41-8d8765e929c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f52887250>]}
[0m17:59:59.868856 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.58s]
[0m17:59:59.869657 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m17:59:59.873018 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m17:59:59.873568 [debug] [MainThread]: Using redshift connection "master"
[0m17:59:59.873929 [debug] [MainThread]: On master: BEGIN
[0m17:59:59.874276 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:59:59.874665 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:00:01.813179 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:00:01.813750 [debug] [MainThread]: On master: COMMIT
[0m18:00:01.814162 [debug] [MainThread]: Using redshift connection "master"
[0m18:00:01.814532 [debug] [MainThread]: On master: COMMIT
[0m18:00:01.955250 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:00:01.955781 [debug] [MainThread]: On master: Close
[0m18:00:01.956964 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:00:01.957302 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:00:01.957571 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:00:01.957902 [info ] [MainThread]: 
[0m18:00:01.958327 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.48 seconds (16.48s).
[0m18:00:01.959079 [debug] [MainThread]: Command end result
[0m18:00:01.975388 [info ] [MainThread]: 
[0m18:00:01.975892 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:00:01.976213 [info ] [MainThread]: 
[0m18:00:01.976500 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:00:01.976901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5288e100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f5285b700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f531bf910>]}
[0m18:00:01.977163 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:02:58.049672 | e3e2cf48-ba4e-49d2-9976-c7d95369db1e ==============================
[0m18:02:58.049672 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:02:58.050502 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:02:58.050640 [debug] [MainThread]: Tracking: tracking
[0m18:02:58.057064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317cfcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c2b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c2b190>]}
[0m18:02:58.069398 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:02:58.084667 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:02:58.084846 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:02:58.089036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317b1bb20>]}
[0m18:02:58.095148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc5b0>]}
[0m18:02:58.095486 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:02:58.095671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc6d0>]}
[0m18:02:58.096604 [info ] [MainThread]: 
[0m18:02:58.097576 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:02:58.098356 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:02:58.106892 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:02:58.107070 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:02:58.107180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:02:58.107293 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:02:59.989478 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:02:59.992228 [debug] [ThreadPool]: On list_dev: Close
[0m18:02:59.993675 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:03:00.001076 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:03:00.001228 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:03:00.001328 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:03:00.001423 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:01.832933 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:03:01.833517 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:03:01.833896 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:03:02.037486 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:03:02.040413 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:03:02.242703 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:03:02.255858 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:02.256305 [debug] [MainThread]: On master: BEGIN
[0m18:03:02.256652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:02.256971 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:03.928801 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:03:03.929448 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:03.929874 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:03:04.188540 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:03:04.191522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c8d970>]}
[0m18:03:04.192216 [debug] [MainThread]: On master: ROLLBACK
[0m18:03:04.376104 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:04.376700 [debug] [MainThread]: On master: BEGIN
[0m18:03:04.749001 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:03:04.749693 [debug] [MainThread]: On master: COMMIT
[0m18:03:04.750177 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:04.750593 [debug] [MainThread]: On master: COMMIT
[0m18:03:04.905854 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:03:04.906495 [debug] [MainThread]: On master: Close
[0m18:03:04.908008 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:03:04.908525 [info ] [MainThread]: 
[0m18:03:04.915636 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.916406 [info ] [Thread-1  ]: 1 of 2 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:03:04.917558 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:03:04.918000 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.923705 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.924563 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:03:04.918257 => 2023-04-27 18:03:04.924391
[0m18:03:04.925023 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:03:04.962910 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.963370 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:04.963575 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:04.963678 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:03:04.963768 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:06.748961 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:03:06.749516 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:06.749855 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:03:07.055343 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:03:07.063080 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.063219 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:03:07.260151 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:07.266266 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.266701 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:03:07.465602 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:07.496323 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:07.496486 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.496570 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:07.772376 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:03:07.773263 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.773628 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:07.977880 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:03:07.984917 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:07.985039 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:03:08.182288 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:03:08.184139 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:08.184511 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:08.184791 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:03:08.488875 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:03:08.489411 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:03:08.489749 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:03:08.693824 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:03:08.695404 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:03:04.925256 => 2023-04-27 18:03:08.695280
[0m18:03:08.695791 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:03:08.898908 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:03:08.900578 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f831729c820>]}
[0m18:03:08.901434 [info ] [Thread-1  ]: 1 of 2 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 3.98s]
[0m18:03:08.904186 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:03:08.904989 [debug] [Thread-3  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.905265 [info ] [Thread-3  ]: 2 of 2 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:03:08.905705 [debug] [Thread-3  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:03:08.905852 [debug] [Thread-3  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.911094 [debug] [Thread-3  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.911966 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:03:08.905928 => 2023-04-27 18:03:08.911831
[0m18:03:08.912379 [debug] [Thread-3  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:03:08.928306 [debug] [Thread-3  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.928665 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:08.928820 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:08.928918 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:03:08.929009 [debug] [Thread-3  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:10.742600 [debug] [Thread-3  ]: SQL status: BEGIN in 2 seconds
[0m18:03:10.743125 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:10.743487 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:03:11.048760 [debug] [Thread-3  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:03:11.054021 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.054143 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:03:11.253890 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:03:11.257400 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.257776 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.258076 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.458184 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m18:03:11.459004 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.459315 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:11.663352 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m18:03:11.667206 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.667312 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:03:11.868063 [debug] [Thread-3  ]: SQL status: DROP VIEW in 0 seconds
[0m18:03:11.869988 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:11.870386 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:11.870696 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:03:12.072643 [debug] [Thread-3  ]: SQL status: COMMIT in 0 seconds
[0m18:03:12.073154 [debug] [Thread-3  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:03:12.073489 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:03:12.277395 [debug] [Thread-3  ]: SQL status: BEGIN in 0 seconds
[0m18:03:12.278823 [debug] [Thread-3  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:03:08.912633 => 2023-04-27 18:03:12.278715
[0m18:03:12.279222 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:03:12.482912 [debug] [Thread-3  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:03:12.484599 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e3e2cf48-ba4e-49d2-9976-c7d95369db1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317c8d9a0>]}
[0m18:03:12.485467 [info ] [Thread-3  ]: 2 of 2 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.58s]
[0m18:03:12.486173 [debug] [Thread-3  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:03:12.488998 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:03:12.489566 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:12.489983 [debug] [MainThread]: On master: BEGIN
[0m18:03:12.490402 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:03:12.490819 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:03:14.220648 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:03:14.221271 [debug] [MainThread]: On master: COMMIT
[0m18:03:14.221689 [debug] [MainThread]: Using redshift connection "master"
[0m18:03:14.222064 [debug] [MainThread]: On master: COMMIT
[0m18:03:14.370989 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:03:14.371588 [debug] [MainThread]: On master: Close
[0m18:03:14.372760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:03:14.373088 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:03:14.373355 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:03:14.373720 [info ] [MainThread]: 
[0m18:03:14.374140 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 16.28 seconds (16.28s).
[0m18:03:14.374969 [debug] [MainThread]: Command end result
[0m18:03:14.383334 [info ] [MainThread]: 
[0m18:03:14.383780 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:03:14.384025 [info ] [MainThread]: 
[0m18:03:14.384228 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:03:14.384552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8317bfc670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83172cc6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83172cc670>]}
[0m18:03:14.384791 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:06:53.584481 | 36aec465-99df-41c8-b1ef-6dd35efad6a4 ==============================
[0m18:06:53.584481 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:06:53.585275 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:06:53.585390 [debug] [MainThread]: Tracking: tracking
[0m18:06:53.591896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777bd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876775e1f0>]}
[0m18:06:53.604572 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:06:53.610744 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m18:06:53.611042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777d700>]}
[0m18:06:54.011258 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m18:06:54.019632 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m18:06:54.021790 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m18:06:54.068152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87677359a0>]}
[0m18:06:54.072097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f876777d430>]}
[0m18:06:54.072326 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:06:54.072489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87666741c0>]}
[0m18:06:54.073412 [info ] [MainThread]: 
[0m18:06:54.074399 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:06:54.075290 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:06:54.084153 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:06:54.084374 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:06:54.084495 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:06:54.084605 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:55.763542 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:06:55.766365 [debug] [ThreadPool]: On list_dev: Close
[0m18:06:55.767640 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:06:55.774403 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:06:55.774567 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:06:55.774708 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:06:55.774826 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:57.661801 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:06:57.662377 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:06:57.662734 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:06:57.867424 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:06:57.870443 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:06:58.071481 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:06:58.084287 [debug] [MainThread]: Using redshift connection "master"
[0m18:06:58.084836 [debug] [MainThread]: On master: BEGIN
[0m18:06:58.085206 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:06:58.085544 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:06:59.914820 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:06:59.915415 [debug] [MainThread]: Using redshift connection "master"
[0m18:06:59.915796 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:07:00.119533 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:07:00.122180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8767735ee0>]}
[0m18:07:00.122839 [debug] [MainThread]: On master: ROLLBACK
[0m18:07:00.267957 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:00.268577 [debug] [MainThread]: On master: BEGIN
[0m18:07:00.631350 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:07:00.631924 [debug] [MainThread]: On master: COMMIT
[0m18:07:00.632291 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:00.632628 [debug] [MainThread]: On master: COMMIT
[0m18:07:00.837501 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:07:00.838090 [debug] [MainThread]: On master: Close
[0m18:07:00.839401 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:07:00.839907 [info ] [MainThread]: 
[0m18:07:00.847790 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.849297 [debug] [Thread-2  ]: Began running node model.analytics_dbt.vw_sales
[0m18:07:00.848596 [info ] [Thread-1  ]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:07:00.850367 [info ] [Thread-2  ]: 2 of 3 START sql view model public.vw_sales .................................... [RUN]
[0m18:07:00.851995 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:07:00.854829 [debug] [Thread-2  ]: Acquiring new redshift connection 'model.analytics_dbt.vw_sales'
[0m18:07:00.855514 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.856027 [debug] [Thread-2  ]: Began compiling node model.analytics_dbt.vw_sales
[0m18:07:00.898469 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.899572 [debug] [Thread-2  ]: Writing injected SQL for node "model.analytics_dbt.vw_sales"
[0m18:07:00.900072 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (compile): 2023-04-27 18:07:00.898705 => 2023-04-27 18:07:00.900018
[0m18:07:00.900239 [debug] [Thread-2  ]: Began executing node model.analytics_dbt.vw_sales
[0m18:07:00.905586 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:07:00.856446 => 2023-04-27 18:07:00.905514
[0m18:07:00.910925 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:07:00.935297 [debug] [Thread-2  ]: Writing runtime sql for node "model.analytics_dbt.vw_sales"
[0m18:07:00.943749 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.944064 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:00.944195 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:00.944314 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:07:00.944445 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:00.944773 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:00.944908 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:00.944999 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:07:00.945091 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:02.781671 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:07:02.782263 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m18:07:02.782830 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:02.783338 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:02.783922 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:07:02.784480 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */


  create view "dev"."public"."vw_sales__dbt_tmp" as (
    with source_sales as (
    select *
    from sales
),

renamed as (
    select 
        SALESID AS ID_VENDA,
        SELLERID AS ID_LISTA,
        BUYERID AS ID_COMPRADOR,
        EVENTID AS ID_EVENTO,
        DATEID AS ID_DATE,
        QTYSOLD AS QUANTIDADE_VENDIDA,
        PRICEPAID AS VALOR_PAGO,
        COMMISSION AS COMISSÃO,
        SALETIME AS DATA_VENDA
    from source_sales
)

select * from renamed
  ) ;

[0m18:07:02.987621 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:07:02.993418 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:07:03.001270 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.001416 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales__dbt_tmp" rename to "vw_sales"
[0m18:07:03.002928 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.003546 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:07:03.191369 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.197869 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.213783 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.219292 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:07:03.226371 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.226508 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.226598 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.384193 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:03.401058 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:03.401382 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:03.401619 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:03.403013 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:07:03.403416 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.403602 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:03.601048 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:07:03.602008 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:07:03.608739 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.608859 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
drop view if exists "dev"."public"."vw_sales__dbt_backup" cascade
[0m18:07:03.805843 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0 seconds
[0m18:07:03.807706 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:03.808093 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:03.808378 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:07:04.012332 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:07:04.012862 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:07:04.013201 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:07:04.216591 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:07:04.218047 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (execute): 2023-04-27 18:07:00.900314 => 2023-04-27 18:07:04.217936
[0m18:07:04.218471 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: ROLLBACK
[0m18:07:04.218962 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.219401 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:04.393073 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: Close
[0m18:07:04.393765 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:07:04.395323 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765dab190>]}
[0m18:07:04.400007 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.400553 [info ] [Thread-2  ]: 2 of 3 OK created sql view model public.vw_sales ............................... [[32mCREATE VIEW[0m in 3.54s]
[0m18:07:04.400796 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:07:04.401634 [debug] [Thread-2  ]: Finished running node model.analytics_dbt.vw_sales
[0m18:07:04.625133 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:07:04.627006 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:04.627380 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.627667 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:07:04.786624 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:07:04.787219 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:07:04.787557 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:07:05.034841 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:07:05.036348 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:07:00.916234 => 2023-04-27 18:07:05.036207
[0m18:07:05.036775 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:07:05.175997 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:07:05.177603 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8766649e50>]}
[0m18:07:05.178483 [info ] [Thread-1  ]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 4.33s]
[0m18:07:05.179206 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:07:05.180769 [debug] [Thread-4  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.181460 [info ] [Thread-4  ]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:07:05.182815 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:07:05.183279 [debug] [Thread-4  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.186899 [debug] [Thread-4  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.187243 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:07:05.183519 => 2023-04-27 18:07:05.187185
[0m18:07:05.187451 [debug] [Thread-4  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:07:05.190574 [debug] [Thread-4  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.190984 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:05.191122 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:05.191214 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:07:05.191307 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:06.980984 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m18:07:06.981535 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:06.981905 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:07:07.185098 [debug] [Thread-4  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:07:07.190527 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.190652 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:07:07.389945 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:07:07.393358 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:07.393727 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.394031 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:07.594931 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:07:07.595767 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.596111 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:07.799822 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:07:07.804759 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:07.804954 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:07:08.004746 [debug] [Thread-4  ]: SQL status: DROP VIEW in 0 seconds
[0m18:07:08.006654 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:08.007061 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:08.007399 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:07:08.209214 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:07:08.209765 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:07:08.210095 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:07:08.414163 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:07:08.415816 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:07:05.187552 => 2023-04-27 18:07:08.415695
[0m18:07:08.416906 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:07:08.721353 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:07:08.722909 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36aec465-99df-41c8-b1ef-6dd35efad6a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765d5bf40>]}
[0m18:07:08.723702 [info ] [Thread-4  ]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.54s]
[0m18:07:08.724311 [debug] [Thread-4  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:07:08.725976 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:07:08.726170 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:08.726278 [debug] [MainThread]: On master: BEGIN
[0m18:07:08.726390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:07:08.726492 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:07:10.564856 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:07:10.565422 [debug] [MainThread]: On master: COMMIT
[0m18:07:10.565803 [debug] [MainThread]: Using redshift connection "master"
[0m18:07:10.566160 [debug] [MainThread]: On master: COMMIT
[0m18:07:10.769594 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:07:10.770214 [debug] [MainThread]: On master: Close
[0m18:07:10.771507 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:07:10.771849 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:07:10.772101 [debug] [MainThread]: Connection 'model.analytics_dbt.vw_sales' was properly closed.
[0m18:07:10.772348 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:07:10.772739 [info ] [MainThread]: 
[0m18:07:10.773168 [info ] [MainThread]: Finished running 2 view models, 1 table model in 0 hours 0 minutes and 16.70 seconds (16.70s).
[0m18:07:10.774025 [debug] [MainThread]: Command end result
[0m18:07:10.788104 [info ] [MainThread]: 
[0m18:07:10.788555 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:07:10.788839 [info ] [MainThread]: 
[0m18:07:10.789148 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:07:10.789657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8765dab190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8764522100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8764522bb0>]}
[0m18:07:10.790109 [debug] [MainThread]: Flushing usage events


============================== 2023-04-27 18:18:47.764862 | f3b2e508-3306-46c2-a902-558e02dee631 ==============================
[0m18:18:47.764862 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:18:47.765712 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'select': ['/models/views/vw_sales.sql'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:18:47.765830 [debug] [MainThread]: Tracking: tracking
[0m18:18:47.772450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524e8f70>]}
[0m18:18:47.786143 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:18:47.803031 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:18:47.803429 [debug] [MainThread]: Partial parsing: updated file: analytics_dbt://models/views/vw_sales.sql
[0m18:18:47.817602 [debug] [MainThread]: 1699: static parser successfully parsed views/vw_sales.sql
[0m18:18:47.833469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b523feee0>]}
[0m18:18:47.837990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459d30>]}
[0m18:18:47.838267 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:18:47.838454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3b2e508-3306-46c2-a902-558e02dee631', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52444250>]}
[0m18:18:47.838878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b52459910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b524598e0>]}
[0m18:18:47.839080 [debug] [MainThread]: Flushing usage events
[0m18:18:48.736698 [error] [MainThread]: Encountered an error:
Non-relative patterns are unsupported
[0m18:18:48.740971 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 136, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 206, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/dist-packages/dbt/main.py", line 253, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 454, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 169, in _runtime_initialize
    self.job_queue = self.get_graph_queue()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 162, in get_graph_queue
    return selector.get_graph_queue(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 295, in get_graph_queue
    selected_nodes = self.get_selected(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 286, in get_selected
    selected_nodes, indirect_only = self.select_nodes(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 153, in select_nodes
    direct_nodes, indirect_nodes = self.select_nodes_recursively(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in select_nodes_recursively
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 125, in <listcomp>
    bundles = [self.select_nodes_recursively(component) for component in spec]
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 123, in select_nodes_recursively
    direct_nodes, indirect_nodes = self.get_nodes_from_criteria(spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 80, in get_nodes_from_criteria
    collected = self.select_included(nodes, spec)
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector.py", line 66, in select_included
    return set(method.search(included_nodes, spec.value))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in search
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/local/lib/python3.8/dist-packages/dbt/graph/selector_methods.py", line 278, in <genexpr>
    paths = set(p.relative_to(root) for p in root.glob(selector))
  File "/usr/lib/python3.8/pathlib.py", line 1138, in glob
    raise NotImplementedError("Non-relative patterns are unsupported")
NotImplementedError: Non-relative patterns are unsupported



============================== 2023-04-27 18:19:36.195245 | 04b26429-e16b-4cf3-9815-bb1a9098ad2a ==============================
[0m18:19:36.195245 [info ] [MainThread]: Running with dbt=1.4.6
[0m18:19:36.196075 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/root/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:19:36.196228 [debug] [MainThread]: Tracking: tracking
[0m18:19:36.202818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424562af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424570ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424572100>]}
[0m18:19:36.215971 [debug] [MainThread]: checksum: 0325e47f1211ebbdb24627f81d8289d705fdb573380364d07ab35982cb3d57cd, vars: {}, profile: None, target: None, version: 1.4.6
[0m18:19:36.232202 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:19:36.232523 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:19:36.238007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424465b80>]}
[0m18:19:36.242606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d6a0>]}
[0m18:19:36.242902 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 329 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:19:36.243102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d790>]}
[0m18:19:36.244095 [info ] [MainThread]: 
[0m18:19:36.245094 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:19:36.245957 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:19:36.256284 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:19:36.256516 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
[0m18:19:36.256661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:19:36.256787 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:38.193941 [debug] [ThreadPool]: SQL status: SELECT in 2 seconds
[0m18:19:38.196744 [debug] [ThreadPool]: On list_dev: Close
[0m18:19:38.200045 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev_public'
[0m18:19:38.214722 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:19:38.215182 [debug] [ThreadPool]: On list_dev_public: BEGIN
[0m18:19:38.215529 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:19:38.215805 [debug] [ThreadPool]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:40.036760 [debug] [ThreadPool]: SQL status: BEGIN in 2 seconds
[0m18:19:40.037342 [debug] [ThreadPool]: Using redshift connection "list_dev_public"
[0m18:19:40.039375 [debug] [ThreadPool]: On list_dev_public: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "list_dev_public"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
[0m18:19:40.241712 [debug] [ThreadPool]: SQL status: SELECT in 0 seconds
[0m18:19:40.244518 [debug] [ThreadPool]: On list_dev_public: ROLLBACK
[0m18:19:40.446451 [debug] [ThreadPool]: On list_dev_public: Close
[0m18:19:40.458605 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:40.458965 [debug] [MainThread]: On master: BEGIN
[0m18:19:40.459384 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:19:40.459700 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:42.187316 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:19:42.187829 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:42.188177 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:19:42.392343 [debug] [MainThread]: SQL status: SELECT in 0 seconds
[0m18:19:42.395342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f242453d3a0>]}
[0m18:19:42.396200 [debug] [MainThread]: On master: ROLLBACK
[0m18:19:42.596989 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:42.597618 [debug] [MainThread]: On master: BEGIN
[0m18:19:43.006619 [debug] [MainThread]: SQL status: BEGIN in 0 seconds
[0m18:19:43.007167 [debug] [MainThread]: On master: COMMIT
[0m18:19:43.007530 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:43.007838 [debug] [MainThread]: On master: COMMIT
[0m18:19:43.212090 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:19:43.212641 [debug] [MainThread]: On master: Close
[0m18:19:43.213828 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:19:43.214384 [info ] [MainThread]: 
[0m18:19:43.221653 [debug] [Thread-1  ]: Began running node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.222457 [info ] [Thread-1  ]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:19:43.223372 [debug] [Thread-2  ]: Began running node model.analytics_dbt.vw_sales
[0m18:19:43.224751 [debug] [Thread-1  ]: Acquiring new redshift connection 'model.analytics_dbt.my_first_dbt_model'
[0m18:19:43.225473 [info ] [Thread-2  ]: 2 of 3 START sql view model public.vw_sales .................................... [RUN]
[0m18:19:43.225858 [debug] [Thread-1  ]: Began compiling node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.226500 [debug] [Thread-2  ]: Acquiring new redshift connection 'model.analytics_dbt.vw_sales'
[0m18:19:43.228801 [debug] [Thread-1  ]: Writing injected SQL for node "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.229209 [debug] [Thread-2  ]: Began compiling node model.analytics_dbt.vw_sales
[0m18:19:43.231577 [debug] [Thread-2  ]: Writing injected SQL for node "model.analytics_dbt.vw_sales"
[0m18:19:43.232137 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (compile): 2023-04-27 18:19:43.226725 => 2023-04-27 18:19:43.232020
[0m18:19:43.232467 [debug] [Thread-1  ]: Began executing node model.analytics_dbt.my_first_dbt_model
[0m18:19:43.232615 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (compile): 2023-04-27 18:19:43.229536 => 2023-04-27 18:19:43.232564
[0m18:19:43.242998 [debug] [Thread-2  ]: Began executing node model.analytics_dbt.vw_sales
[0m18:19:43.303419 [debug] [Thread-2  ]: Writing runtime sql for node "model.analytics_dbt.vw_sales"
[0m18:19:43.304756 [debug] [Thread-1  ]: Writing runtime sql for node "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.305194 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:43.305346 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:43.305472 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:43.305589 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:43.305697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:19:43.305800 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:19:43.305903 [debug] [Thread-1  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:43.306000 [debug] [Thread-2  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:45.054527 [debug] [Thread-2  ]: SQL status: BEGIN in 2 seconds
[0m18:19:45.055009 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.055297 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */


  create view "dev"."public"."vw_sales__dbt_tmp" as (
    with source_sales as (
    select *
    from sales
),

renamed as (
    select 
        SALESID AS ID_VENDA,
        SELLERID AS ID_LISTA,
        BUYERID AS ID_COMPRADOR,
        EVENTID AS ID_EVENTO,
        DATEID AS ID_DATE,
        QTYSOLD AS QUANTIDADE_VENDIDA,
        PRICEPAID AS VALOR_PAGO,
        COMMISSION AS COMISSÃO,
        TO_CHAR(SALETIME, 'dd/mm/yyyy HH24:MI:SS') AS DATA_HORA_VENDA,
        TO_CHAR(SALETIME, 'HH24:MI:SS') AS HORA_VENDA,
        cast(SALETIME as date) AS DATA_VENDA
    from source_sales
)

select * from renamed
  ) ;

[0m18:19:45.055699 [debug] [Thread-1  ]: SQL status: BEGIN in 2 seconds
[0m18:19:45.056074 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.056351 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */

  
    

  create  table
    "dev"."public"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:19:45.259428 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:19:45.270273 [debug] [Thread-1  ]: SQL status: SELECT in 0 seconds
[0m18:19:45.278936 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.279396 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales" rename to "vw_sales__dbt_backup"
[0m18:19:45.284046 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.284521 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:19:45.463940 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.464526 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.470740 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.476143 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.476626 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
alter table "dev"."public"."vw_sales__dbt_tmp" rename to "vw_sales"
[0m18:19:45.477048 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
alter table "dev"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:19:45.668909 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.669442 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:45.724986 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:45.725219 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:45.725344 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:45.726724 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:45.726903 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.727032 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:45.976296 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:19:45.976780 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:19:45.977629 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:45.978495 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:46.180826 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:19:46.192550 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.192993 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.vw_sales"} */
drop view if exists "dev"."public"."vw_sales__dbt_backup" cascade
[0m18:19:46.385539 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0 seconds
[0m18:19:46.387273 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:46.387674 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.387940 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: COMMIT
[0m18:19:46.551632 [debug] [Thread-2  ]: SQL status: COMMIT in 0 seconds
[0m18:19:46.552134 [debug] [Thread-2  ]: Using redshift connection "model.analytics_dbt.vw_sales"
[0m18:19:46.552418 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: BEGIN
[0m18:19:46.795370 [debug] [Thread-2  ]: SQL status: BEGIN in 0 seconds
[0m18:19:46.797260 [debug] [Thread-2  ]: Timing info for model.analytics_dbt.vw_sales (execute): 2023-04-27 18:19:43.248976 => 2023-04-27 18:19:46.797139
[0m18:19:46.797659 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: ROLLBACK
[0m18:19:46.798069 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:46.798840 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:47.000713 [debug] [Thread-2  ]: On model.analytics_dbt.vw_sales: Close
[0m18:19:47.001283 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:19:47.005890 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.006457 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_first_dbt_model"} */
drop table if exists "dev"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:19:47.007659 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2423be6d60>]}
[0m18:19:47.008471 [info ] [Thread-2  ]: 2 of 3 OK created sql view model public.vw_sales ............................... [[32mCREATE VIEW[0m in 3.78s]
[0m18:19:47.010992 [debug] [Thread-2  ]: Finished running node model.analytics_dbt.vw_sales
[0m18:19:47.164352 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0 seconds
[0m18:19:47.166485 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:47.166888 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.167164 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: COMMIT
[0m18:19:47.409446 [debug] [Thread-1  ]: SQL status: COMMIT in 0 seconds
[0m18:19:47.409918 [debug] [Thread-1  ]: Using redshift connection "model.analytics_dbt.my_first_dbt_model"
[0m18:19:47.410180 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: BEGIN
[0m18:19:47.614244 [debug] [Thread-1  ]: SQL status: BEGIN in 0 seconds
[0m18:19:47.615682 [debug] [Thread-1  ]: Timing info for model.analytics_dbt.my_first_dbt_model (execute): 2023-04-27 18:19:43.232723 => 2023-04-27 18:19:47.615571
[0m18:19:47.616114 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: ROLLBACK
[0m18:19:47.819144 [debug] [Thread-1  ]: On model.analytics_dbt.my_first_dbt_model: Close
[0m18:19:47.820691 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2420bafe80>]}
[0m18:19:47.821475 [info ] [Thread-1  ]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT[0m in 4.60s]
[0m18:19:47.822072 [debug] [Thread-1  ]: Finished running node model.analytics_dbt.my_first_dbt_model
[0m18:19:47.823609 [debug] [Thread-4  ]: Began running node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.824275 [info ] [Thread-4  ]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:19:47.825572 [debug] [Thread-4  ]: Acquiring new redshift connection 'model.analytics_dbt.my_second_dbt_model'
[0m18:19:47.826000 [debug] [Thread-4  ]: Began compiling node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.831844 [debug] [Thread-4  ]: Writing injected SQL for node "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.832783 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (compile): 2023-04-27 18:19:47.826220 => 2023-04-27 18:19:47.832634
[0m18:19:47.833411 [debug] [Thread-4  ]: Began executing node model.analytics_dbt.my_second_dbt_model
[0m18:19:47.841025 [debug] [Thread-4  ]: Writing runtime sql for node "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.841476 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:47.841663 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:47.841812 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:19:47.841945 [debug] [Thread-4  ]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:49.662314 [debug] [Thread-4  ]: SQL status: BEGIN in 2 seconds
[0m18:19:49.662791 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:49.663083 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */


  create view "dev"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."public"."my_first_dbt_model"
where id = 1
  ) ;

[0m18:19:49.867088 [debug] [Thread-4  ]: SQL status: CREATE VIEW in 0 seconds
[0m18:19:49.875246 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:49.875567 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
alter table "dev"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:19:50.072710 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0 seconds
[0m18:19:50.076100 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.076499 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.076785 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.276922 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:19:50.277716 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.278046 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:50.481502 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:19:50.486039 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.486472 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.6", "profile_name": "analytics_dbt", "target_name": "dev", "node_id": "model.analytics_dbt.my_second_dbt_model"} */
drop view if exists "dev"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:19:50.686570 [debug] [Thread-4  ]: SQL status: DROP VIEW in 0 seconds
[0m18:19:50.688347 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.688687 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.688944 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: COMMIT
[0m18:19:50.891213 [debug] [Thread-4  ]: SQL status: COMMIT in 0 seconds
[0m18:19:50.891713 [debug] [Thread-4  ]: Using redshift connection "model.analytics_dbt.my_second_dbt_model"
[0m18:19:50.891992 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: BEGIN
[0m18:19:51.068460 [debug] [Thread-4  ]: SQL status: BEGIN in 0 seconds
[0m18:19:51.069804 [debug] [Thread-4  ]: Timing info for model.analytics_dbt.my_second_dbt_model (execute): 2023-04-27 18:19:47.833814 => 2023-04-27 18:19:51.069703
[0m18:19:51.070173 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: ROLLBACK
[0m18:19:51.301028 [debug] [Thread-4  ]: On model.analytics_dbt.my_second_dbt_model: Close
[0m18:19:51.302602 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04b26429-e16b-4cf3-9815-bb1a9098ad2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2423be6df0>]}
[0m18:19:51.303397 [info ] [Thread-4  ]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 3.48s]
[0m18:19:51.304061 [debug] [Thread-4  ]: Finished running node model.analytics_dbt.my_second_dbt_model
[0m18:19:51.306653 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:19:51.307154 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:51.307504 [debug] [MainThread]: On master: BEGIN
[0m18:19:51.307792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:19:51.308076 [debug] [MainThread]: Redshift adapter: Connecting to Redshift using 'database' credentials
[0m18:19:52.985779 [debug] [MainThread]: SQL status: BEGIN in 2 seconds
[0m18:19:52.986266 [debug] [MainThread]: On master: COMMIT
[0m18:19:52.986649 [debug] [MainThread]: Using redshift connection "master"
[0m18:19:52.986933 [debug] [MainThread]: On master: COMMIT
[0m18:19:53.246835 [debug] [MainThread]: SQL status: COMMIT in 0 seconds
[0m18:19:53.247506 [debug] [MainThread]: On master: Close
[0m18:19:53.248924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:19:53.249270 [debug] [MainThread]: Connection 'model.analytics_dbt.my_first_dbt_model' was properly closed.
[0m18:19:53.249519 [debug] [MainThread]: Connection 'model.analytics_dbt.vw_sales' was properly closed.
[0m18:19:53.249737 [debug] [MainThread]: Connection 'model.analytics_dbt.my_second_dbt_model' was properly closed.
[0m18:19:53.250114 [info ] [MainThread]: 
[0m18:19:53.250619 [info ] [MainThread]: Finished running 2 view models, 1 table model in 0 hours 0 minutes and 17.01 seconds (17.01s).
[0m18:19:53.251579 [debug] [MainThread]: Command end result
[0m18:19:53.259977 [info ] [MainThread]: 
[0m18:19:53.260376 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:19:53.260577 [info ] [MainThread]: 
[0m18:19:53.260745 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:19:53.261063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424473910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2424562af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2420ad6400>]}
[0m18:19:53.261390 [debug] [MainThread]: Flushing usage events
